{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from util import load_external_labels\n",
    "\n",
    "# %time load_external_labels(session, Spouse, annotator_name='gold')\n",
    "\n",
    "from snorkel.annotations import load_gold_labels\n",
    "from snorkel import SnorkelSession\n",
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Spouse = candidate_subclass('Spouse', ['person1', 'person2'])\n",
    "\n",
    "session = SnorkelSession()\n",
    "dev_cands = session.query(Spouse).filter(Spouse.split == 1).all()\n",
    "test_cands = session.query(Spouse).filter(Spouse.split == 2).all()\n",
    "\n",
    "#L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, zero_one=True)\n",
    "#L_gold_test = load_gold_labels(session, annotator_name='gold', split=2, zero_one=True)\n",
    "\n",
    "# L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2, zero_one=True)\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, zero_one=True)\n",
    "# gold_labels_dev = [L[0,0] if L[0,0]==1 else -1 for L in L_gold_dev]\n",
    "gold_labels_dev = [L[0,0] for L in L_gold_dev]\n",
    "gold_labels_test = [L[0,0] for L in L_gold_test]\n",
    "\n",
    "from snorkel.learning.utils import MentionScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 2625\n",
      "218 2484\n",
      "2814 2702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gold_labels_dev = [x[0,0] for x in L_gold_dev.todense()]\n",
    "#for i,L in enumerate(gold_labels_dev):\n",
    "#    print(i,gold_labels_dev[i])\n",
    "\n",
    "# gold_labels_dev = []\n",
    "# for i,L in enumerate(L_gold_dev):\n",
    "#     gold_labels_dev.append(L[0,0])\n",
    "    \n",
    "# gold_labels_test = []\n",
    "# for i,L in enumerate(L_gold_test):\n",
    "#     gold_labels_test.append(L[0,0])\n",
    "    \n",
    "# print(len(gold_labels_dev),len(gold_labels_test))\n",
    "# print(gold_labels_dev.count(1),gold_labels_dev.count(-1))\n",
    "# print(len(gold_labels_dev))\n",
    "\n",
    "print(gold_labels_dev.count(1),gold_labels_dev.count(0))\n",
    "print(gold_labels_test.count(1),gold_labels_test.count(0))\n",
    "print(len(gold_labels_dev),len(gold_labels_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import gensim.matutils as gm\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# Load pretrained model (since intermediate data is not included, the model cannot be refined with additional data)\n",
    "model = KeyedVectors.load_word2vec_format('../../../snorkel/tutorials/glove_w2v.txt', binary=False)  # C binary format\n",
    "\n",
    "\n",
    "wordvec_unavailable= set()\n",
    "def write_to_file(wordvec_unavailable):\n",
    "    with open(\"wordvec_unavailable.txt\",\"w\") as f:\n",
    "        for word in wordvec_unavailable:\n",
    "            f.write(word+\"\\n\")\n",
    "\n",
    "def preprocess(tokens):\n",
    "    btw_words = [word for word in tokens if word not in STOPWORDS]\n",
    "    btw_words = [word for word in btw_words if word.isalpha()]\n",
    "    return btw_words\n",
    "\n",
    "def get_word_vectors(btw_words): # returns vector of embeddings of words\n",
    "    word_vectors= []\n",
    "    for word in btw_words:\n",
    "        try:\n",
    "            word_v = np.array(model[word])\n",
    "            word_v = word_v.reshape(len(word_v),1)\n",
    "            #print(word_v.shape)\n",
    "            word_vectors.append(model[word])\n",
    "        except:\n",
    "            wordvec_unavailable.add(word)\n",
    "    return word_vectors\n",
    "\n",
    "def get_similarity(word_vectors,target_word): # sent(list of word vecs) to word similarity\n",
    "    similarity = 0\n",
    "    target_word_vector = 0\n",
    "    try:\n",
    "        target_word_vector = model[target_word]\n",
    "    except:\n",
    "        wordvec_unavailable.add(target_word+\" t\")\n",
    "        return similarity\n",
    "    target_word_sparse = gm.any2sparse(target_word_vector,eps=1e-09)\n",
    "    for wv in word_vectors:\n",
    "        wv_sparse = gm.any2sparse(wv, eps=1e-09)\n",
    "        similarity = max(similarity,gm.cossim(wv_sparse,target_word_sparse))\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Discrete ##########\n",
    "\n",
    "# spouses = {'spouse', 'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "# family = {'father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "#               'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin'}\n",
    "# family = family | {f + '-in-law' for f in family}\n",
    "# other = {'boyfriend', 'girlfriend' 'boss', 'employee', 'secretary', 'co-worker'}\n",
    "\n",
    "# # Helper function to get last name\n",
    "# def last_name(s):\n",
    "#     name_parts = s.split(' ')\n",
    "#     return name_parts[-1] if len(name_parts) > 1 else None    \n",
    "\n",
    "# def LF_husband_wife(c):\n",
    "#     return (1,1) if len(spouses.intersection(get_between_tokens(c))) > 0 else (0,0)\n",
    "\n",
    "# def LF_husband_wife_left_window(c):\n",
    "#     if len(spouses.intersection(get_left_tokens(c[0], window=2))) > 0:\n",
    "#         return (1,1)\n",
    "#     elif len(spouses.intersection(get_left_tokens(c[1], window=2))) > 0:\n",
    "#         return (1,1)\n",
    "#     else:\n",
    "#         return (0,0)\n",
    "    \n",
    "# def LF_same_last_name(c):\n",
    "#     p1_last_name = last_name(c.person1.get_span())\n",
    "#     p2_last_name = last_name(c.person2.get_span())\n",
    "#     if p1_last_name and p2_last_name and p1_last_name == p2_last_name:\n",
    "#         if c.person1.get_span() != c.person2.get_span():\n",
    "#             return (1,1)\n",
    "#     return (0,0)\n",
    "\n",
    "# def LF_no_spouse_in_sentence(c):\n",
    "#     return (-1,1) if np.random.rand() < 0.75 and len(spouses.intersection(c.get_parent().words)) == 0 else (0,0)\n",
    "\n",
    "# def LF_and_married(c):\n",
    "#     return (1,1) if 'and' in get_between_tokens(c) and 'married' in get_right_tokens(c) else (0,0)\n",
    "    \n",
    "# def LF_familial_relationship(c):\n",
    "#     return (-1,1) if len(family.intersection(get_between_tokens(c))) > 0 else (0,0)\n",
    "\n",
    "# def LF_family_left_window(c):\n",
    "#     if len(family.intersection(get_left_tokens(c[0], window=2))) > 0:\n",
    "#         return (-1,1)\n",
    "#     elif len(family.intersection(get_left_tokens(c[1], window=2))) > 0:\n",
    "#         return (-1,1)\n",
    "#     else:\n",
    "#         return (0,0)\n",
    "\n",
    "# def LF_other_relationship(c):\n",
    "#     return (-1,1) if len(other.intersection(get_between_tokens(c))) > 0 else (0,0)\n",
    "\n",
    "\n",
    "# import bz2\n",
    "\n",
    "# # Function to remove special characters from text\n",
    "# def strip_special(s):\n",
    "#     return ''.join(c for c in s if ord(c) < 128)\n",
    "\n",
    "# # Read in known spouse pairs and save as set of tuples\n",
    "# with bz2.BZ2File('data/spouses_dbpedia.csv.bz2', 'rb') as f:\n",
    "#     known_spouses = set(\n",
    "#         tuple(strip_special(x.decode('utf-8')).strip().split(',')) for x in f.readlines()\n",
    "#     )\n",
    "# # Last name pairs for known spouses\n",
    "# last_names = set([(last_name(x), last_name(y)) for x, y in known_spouses if last_name(x) and last_name(y)])\n",
    "    \n",
    "# def LF_distant_supervision(c):\n",
    "#     p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "#     return (1,1) if (p1, p2) in known_spouses or (p2, p1) in known_spouses else (0,0)\n",
    "\n",
    "# def LF_distant_supervision_last_names(c):\n",
    "#     p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "#     p1n, p2n = last_name(p1), last_name(p2)\n",
    "#     return (1,1) if (p1 != p2) and ((p1n, p2n) in last_names or (p2n, p1n) in last_names) else (0,0)\n",
    "\n",
    "\n",
    "# LFs = [\n",
    "#     LF_distant_supervision, LF_distant_supervision_last_names, \n",
    "#     LF_husband_wife, LF_husband_wife_left_window, LF_same_last_name,\n",
    "#     LF_no_spouse_in_sentence, LF_and_married, LF_familial_relationship, \n",
    "#     LF_family_left_window, LF_other_relationship\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Continuous ################\n",
    "\n",
    "\n",
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "\n",
    "spouses = {'spouse', 'wife', 'husband', 'ex-wife', 'ex-husband'}\n",
    "family = {'father', 'mother', 'sister', 'brother', 'son', 'daughter',\n",
    "              'grandfather', 'grandmother', 'uncle', 'aunt', 'cousin'}\n",
    "family = family | {f + '-in-law' for f in family}\n",
    "other = {'boyfriend', 'girlfriend' 'boss', 'employee', 'secretary', 'co-worker'}\n",
    "\n",
    "# Helper function to get last name\n",
    "def last_name(s):\n",
    "    name_parts = s.split(' ')\n",
    "    return name_parts[-1] if len(name_parts) > 1 else None    \n",
    "\n",
    "def LF_husband_wife(c):\n",
    "    global LF_Threshold\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_between_tokens(c)))\n",
    "    for sw in spouses:\n",
    "        sc=max(sc,get_similarity(word_vectors,sw))\n",
    "    return (1,sc)\n",
    "\n",
    "def LF_husband_wife_left_window(c):\n",
    "    global LF_Threshold\n",
    "    sc_1 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[0])))\n",
    "    for sw in spouses:\n",
    "        sc_1=max(sc_1,get_similarity(word_vectors,sw))\n",
    "        \n",
    "    sc_2 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[1])))\n",
    "    for sw in spouses:\n",
    "        sc_2=max(sc_2,get_similarity(word_vectors,sw))\n",
    "    return(1,max(sc_1,sc_2))\n",
    "    \n",
    "def LF_same_last_name(c):\n",
    "    p1_last_name = last_name(c.person1.get_span())\n",
    "    p2_last_name = last_name(c.person2.get_span())\n",
    "    if p1_last_name and p2_last_name and p1_last_name == p2_last_name:\n",
    "        if c.person1.get_span() != c.person2.get_span():\n",
    "            return (1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_no_spouse_in_sentence(c):\n",
    "    return (-1,0.75) if np.random.rand() < 0.75 and len(spouses.intersection(c.get_parent().words)) == 0 else (0,0)\n",
    "\n",
    "def LF_and_married(c):\n",
    "    global LF_Threshold\n",
    "    word_vectors = get_word_vectors(preprocess(get_right_tokens(c)))\n",
    "    sc = get_similarity(word_vectors,'married')\n",
    "    \n",
    "    if 'and' in get_between_tokens(c):\n",
    "        return (1,sc)\n",
    "    else:\n",
    "        return (0,0)\n",
    "\n",
    "def LF_familial_relationship(c):\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_between_tokens(c)))\n",
    "    for fw in family:\n",
    "        sc=max(sc,get_similarity(word_vectors,fw))\n",
    "        \n",
    "    return (-1,sc) \n",
    "\n",
    "def LF_family_left_window(c):\n",
    "    sc_1 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[0])))\n",
    "    for fw in family:\n",
    "        sc_1=max(sc_1,get_similarity(word_vectors,fw))\n",
    "        \n",
    "    sc_2 = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_left_tokens(c[1])))\n",
    "    for fw in family:\n",
    "        sc_2=max(sc_2,get_similarity(word_vectors,fw))\n",
    "        \n",
    "    return (-1,max(sc_1,sc_2))\n",
    "\n",
    "def LF_other_relationship(c):\n",
    "    sc = 0\n",
    "    word_vectors = get_word_vectors(preprocess(get_between_tokens(c)))\n",
    "    for ow in other:\n",
    "        sc=max(sc,get_similarity(word_vectors,ow))\n",
    "        \n",
    "    return (-1,sc) \n",
    "\n",
    "# def LF_other_relationship_left_window(c):\n",
    "#     sc = 0\n",
    "#     word_vectors = get_word_vectors(preprocess(get_left_tokens(c)))\n",
    "#     for ow in other:\n",
    "#         sc=max(sc,get_similarity(word_vectors,ow))\n",
    "#     return (-1,sc) \n",
    "\n",
    "import bz2\n",
    "\n",
    "# Function to remove special characters from text\n",
    "def strip_special(s):\n",
    "    s = s.decode(\"utf-8\") \n",
    "    return ''.join(c for c in s if (ord(c) < 128))\n",
    "\n",
    "\n",
    "# Read in known spouse pairs and save as set of tuples\n",
    "with bz2.BZ2File('data/spouses_dbpedia.csv.bz2', 'r') as f:\n",
    "    known_spouses = set(\n",
    "        tuple(strip_special(x).strip().split(',')) for x in f.readlines()\n",
    "    )\n",
    "# Last name pairs for known spouses\n",
    "last_names = set([(last_name(x), last_name(y)) for x, y in known_spouses if last_name(x) and last_name(y)])\n",
    "    \n",
    "def LF_distant_supervision(c):\n",
    "    p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "    return (1,1) if (p1, p2) in known_spouses or (p2, p1) in known_spouses else (0,0)\n",
    "\n",
    "def LF_distant_supervision_last_names(c):\n",
    "    p1, p2 = c.person1.get_span(), c.person2.get_span()\n",
    "    p1n, p2n = last_name(p1), last_name(p2)\n",
    "    return (1,1) if (p1 != p2) and ((p1n, p2n) in last_names or (p2n, p1n) in last_names) else (0,1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# def LF_Three_Lists_Left_Window(c):\n",
    "#     global softmax_Threshold\n",
    "#     c1,s1 = LF_husband_wife_left_window(c)\n",
    "#     c2,s2 = LF_family_left_window(c)\n",
    "#     c3,s3 = LF_other_relationship_left_window(c)\n",
    "#     sc = np.array([s1,s2,s3])\n",
    "#     c = [c1,c2,c3]\n",
    "#     sharp_param = 1.5\n",
    "#     prob_sc = np.exp(sc * sharp_param - np.max(sc))\n",
    "#     prob_sc = prob_sc / np.sum(prob_sc)\n",
    "#     #print 'Left:',s1,s2,s3,prob_sc\n",
    "    \n",
    "#     if s1==s2 or s3==s1:\n",
    "#         return (0,0)\n",
    "#     return c[np.argmax(prob_sc)],1\n",
    "\n",
    "# def LF_Three_Lists_Between_Words(c):\n",
    "#     global softmax_Threshold\n",
    "#     c1,s1 = LF_husband_wife(c)\n",
    "#     c2,s2 = LF_familial_relationship(c)\n",
    "#     c3,s3 = LF_other_relationship(c)\n",
    "#     sc = np.array([s1,s2,s3])\n",
    "#     c = [c1,c2,c3]\n",
    "#     sharp_param = 1.5\n",
    "    \n",
    "#     prob_sc = np.exp(sc * sharp_param - np.max(sc))\n",
    "#     prob_sc = prob_sc / np.sum(prob_sc)\n",
    "#     #print 'BW:',s1,s2,s3,prob_sc\n",
    "#     if s1==s2 or s3==s1:\n",
    "#         return (0,0)\n",
    "#     return c[np.argmax(prob_sc)],1\n",
    "    \n",
    "LFs = [\n",
    "    LF_distant_supervision, LF_distant_supervision_last_names, \n",
    "    LF_husband_wife, LF_husband_wife_left_window, LF_same_last_name,\n",
    "    LF_no_spouse_in_sentence, LF_and_married, LF_familial_relationship, \n",
    "    LF_family_left_window, LF_other_relationship\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' output:\n",
    "\n",
    "    [[[L_x1],[S_x1]],\n",
    "     [[L_x2],[S_x2]],\n",
    "     ......\n",
    "     ......\n",
    "    ]\n",
    "\n",
    "'''\n",
    "def get_L_S_Tensor(cands): \n",
    "    \n",
    "    L_S = []\n",
    "    for i,ci in enumerate(cands):\n",
    "        L_S_ci=[]\n",
    "        L=[]\n",
    "        S=[]\n",
    "        for LF in LFs:\n",
    "            #print LF.__name__\n",
    "            l,s = LF(ci)\n",
    "            L.append(l)\n",
    "            S.append((s+1)/2)  #to scale scores in [0,1] \n",
    "        L_S_ci.append(L)\n",
    "        L_S_ci.append(S)\n",
    "        L_S.append(L_S_ci) \n",
    "        if(i%500==0 and i!=0):\n",
    "            print(str(i)+'data points labelled in',(time.time() - start_time)/60,'mins')\n",
    "    return L_S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started at: 12-6-2018, 16:40:41\n",
      "500data points labelled in 0.6098895152409871 mins\n",
      "1000data points labelled in 1.2040858785311381 mins\n",
      "1500data points labelled in 1.808166233698527 mins\n",
      "2000data points labelled in 2.4930141886075337 mins\n",
      "2500data points labelled in 3.091664159297943 mins\n",
      "--- 203.35997462272644 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "start_time = time.time()\n",
    "\n",
    "lt = time.localtime()\n",
    "\n",
    "print(\"started at: {}-{}-{}, {}:{}:{}\".format(lt.tm_mday,lt.tm_mon,lt.tm_year,lt.tm_hour,lt.tm_min,lt.tm_sec))\n",
    "\n",
    "# dev_L_S = get_L_S_Tensor(dev_cands)\n",
    "\n",
    "# np.save(\"dev_L_S_smooth\",np.array(dev_L_S))\n",
    "\n",
    "# train_L_S = get_L_S_Tensor(train_cands)\n",
    "# np.save(\"train_L_S_smooth\",np.array(train_L_S))\n",
    "\n",
    "\n",
    "test_L_S = get_L_S_Tensor(test_cands)\n",
    "np.save(\"test_L_S_smooth\",np.array(test_L_S))\n",
    "\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def draw2DArray(a):\n",
    "    fig = plt.figure(figsize=(6, 3.2))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('colorMap')\n",
    "    plt.imshow(np.array(a))\n",
    "    ax.set_aspect('equal')\n",
    "    cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
    "    cax.get_xaxis().set_visible(False)\n",
    "    cax.get_yaxis().set_visible(False)\n",
    "    cax.patch.set_alpha(0)\n",
    "    cax.set_frame_on(False)\n",
    "    plt.colorbar(orientation='vertical')\n",
    "    plt.show()\n",
    "    \n",
    "      \n",
    "def report2dict(cr):\n",
    "    # Parse rows\n",
    "    tmp = list()\n",
    "    for row in cr.split(\"\\n\"):\n",
    "        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n",
    "        if len(parsed_row) > 0:\n",
    "            tmp.append(parsed_row)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    measures = tmp[0]\n",
    "\n",
    "    D_class_data = defaultdict(dict)\n",
    "    for row in tmp[1:]:\n",
    "        class_label = row[0]\n",
    "        for j, m in enumerate(measures):\n",
    "            D_class_data[class_label][m.strip()] = float(row[j + 1].strip())\n",
    "    return pd.DataFrame(D_class_data).T\n",
    "\n",
    "def predictAndPrint(pl):\n",
    "    print(\"acc\",accuracy_score(gold_labels_dev,pl))\n",
    "    print(\"acc test\",accuracy_score(gold_labels_dev,pl))\n",
    "#     print(\"dev\",precision_recall_fscore_support(gold_labels_dev,pl,average='binary'))\n",
    "    print(\"test\",precision_recall_fscore_support(gold_labels_test,pl,average='binary'))\n",
    "#     print(confusion_matrix(gold_labels_dev,pl))\n",
    "#     draw2DArray(confusion_matrix(gold_labels_dev,pl))\n",
    "#     return report2dict(classification_report(gold_labels_dev, pl))# target_names=class_names))\n",
    "    \n",
    "\n",
    "\n",
    "def drawPRcurve(y_test,y_score,it_no):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    splt = fig.add_subplot(111)\n",
    "    \n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score,pos_label=1)\n",
    "\n",
    "    splt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    splt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    average_precision = average_precision_score(y_test, y_score)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.title('{0:d} Precision-Recall curve: AP={1:0.2f}'.format(it_no,\n",
    "              average_precision))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2702, 2, 10) (2814, 2, 10) (22276, 2, 10)\n"
     ]
    }
   ],
   "source": [
    "LF_l = [\n",
    "    1,1,1,1,1,-1,1,-1,-1,-1\n",
    "]\n",
    "import numpy as np\n",
    "dev_L_S = np.load(\"dev_L_S_smooth.npy\")\n",
    "test_L_S = np.load(\"test_L_S_smooth.npy\")\n",
    "train_L_S = np.load(\"train_L_S_smooth.npy\")\n",
    "\n",
    "# dev_L_S = np.load(\"dev_L_S_discrete.npy\")\n",
    "# train_L_S = np.load(\"train_L_S_discrete.npy\")\n",
    "\n",
    "print(test_L_S.shape,dev_L_S.shape,train_L_S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call this only once for a kernel startup\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "# BATCH_SIZE = 32\n",
    "seed = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "(2814, 2, 20) (22276, 2, 20)\n"
     ]
    }
   ],
   "source": [
    "LF_l = [\n",
    "    1,1,1,1,1,-1,1,-1,-1,-1\n",
    "]\n",
    "\n",
    "def merge(a,b):\n",
    "    c = []\n",
    "    for i in range(len(a)):\n",
    "        ci = []\n",
    "        ci_l = a[i,0,:].tolist()+b[i,0,:].tolist()\n",
    "        ci_s = a[i,1,:].tolist()+b[i,1,:].tolist()\n",
    "        ci.append(ci_l)\n",
    "        ci.append(ci_s)\n",
    "        c.append(ci)\n",
    "    return c\n",
    "import numpy as np\n",
    "dev_L_S_s = np.load(\"dev_L_S_smooth.npy\")\n",
    "train_L_S_s = np.load(\"train_L_S_smooth.npy\")\n",
    "\n",
    "dev_L_S_d = np.load(\"dev_L_S_discrete.npy\")\n",
    "train_L_S_d = np.load(\"train_L_S_discrete.npy\")\n",
    "\n",
    "dev_L_S = np.array(merge(dev_L_S_d,dev_L_S_s))\n",
    "train_L_S = np.array(merge(train_L_S_d,train_L_S_s))\n",
    "\n",
    "LF_l = LF_l + LF_l\n",
    "print(len(LF_l))\n",
    "\n",
    "\n",
    "print(dev_L_S.shape,train_L_S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "NoOfLFs= len(LF_l)\n",
    "NoOfClasses = 2\n",
    "print(len(LF_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-46-d34e68709997>, line 226)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-46-d34e68709997>\"\u001b[0;36m, line \u001b[0;32m226\u001b[0m\n\u001b[0;31m    return pl\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "## normalized model with smooth LFs + penalties\n",
    "\n",
    "class model:\n",
    "    \n",
    "    ## lr : learning rate\n",
    "    ## ep : no of epochs\n",
    "    ## th : thetas initializer\n",
    "    ## af : alphas initializer\n",
    "    ## penalty : {1,2,3} use one of the three penalties, 0: no-penalty\n",
    "    ## p3k : parameter for penalty-3 \n",
    "    ## smooth : flag if smooth lfs are used \n",
    "    ## make sure smooth/discrete LF data is loaded into train_L_S and test_L_S\n",
    "    ## pcl : all possible class labels  = [-1,1] for binary, \n",
    "    ##       np.arange(0,NoOfClasses) for multiclass\n",
    "    ## alp : alpha parameter (to set a max value for alpha)\n",
    "    ## norm : use normalization or not\n",
    "    \n",
    "    def __init__(self,NoOfLFs,pcl=np.array([-1,1],dtype=np.float64),norm=True,smooth=True,penalty=0,p3k=3,alp=0.99):\n",
    "        self.NoOfLFs = NoOfLFs\n",
    "        self.norm = norm\n",
    "        self.smooth = smooth\n",
    "        self.p3k = p3k\n",
    "        self.alp = alp\n",
    "        self.pcl = pcl\n",
    "        self.penalty = penalty\n",
    "        self.seed = 12\n",
    "        \n",
    "    def build_graph(self):\n",
    "        tf.set_random_seed(self.seed)\n",
    "        \n",
    "    \n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices(dev_L_S).batch(len(dev_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "#         print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],\\\n",
    "                                 initializer=af,\\\n",
    "                                 dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],\\\n",
    "                                initializer=th,\\\n",
    "                        dtype=tf.float64)\n",
    "\n",
    "#         print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "#         print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "#         print(alphas)\n",
    "        print(s)\n",
    "        print(\"l\",l)\n",
    "#         print(s.graph)\n",
    "        \n",
    "        s_ = tf.maximum(tf.subtract(s,tf.minimum(alphas,alp)), 0)\n",
    "        print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),-tf.ones_like(v))\n",
    "            print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        if(smooth):\n",
    "            pout = tf.map_fn(lambda c: l*c*s_ ,pcl,name=\"pout\")\n",
    "        else:\n",
    "            pout = tf.map_fn(lambda c: l*c ,pcl,name=\"pout\")\n",
    "\n",
    "        print(\"pout\",pout)    \n",
    "\n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,\\\n",
    "                           name=\"t_pout\")\n",
    "    \n",
    "        print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "        print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "            print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "            print(\"intsy\",out1)\n",
    "            return out1\n",
    "                \n",
    "\n",
    "        if(smooth):\n",
    "            #smooth normalizer\n",
    "            zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "                           pcl,name=\"zy\")\n",
    "        else:\n",
    "            #discrete normalizer\n",
    "            zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),\\\n",
    "                           pcl,name=\"zy\")\n",
    "\n",
    "    \n",
    "# \n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "#                        np.array(NoOfClasses,dtype=np.float64))\n",
    "        \n",
    "        print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        \n",
    "        print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "        print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "        \n",
    "        if(not norm):\n",
    "            print(\"unnormlized loss\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  ))\n",
    "        elif(penalty == 1):\n",
    "            print(\"penalty1\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                      +tf.reduce_sum(tf.maximum(tf.zeros_like(thetas),-thetas))\n",
    "        elif(penalty == 2):\n",
    "            print(\"penalty2\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     -tf.minimum( tf.reduce_min(thetas),0.0)\n",
    "        elif(penalty == 3):\n",
    "            print(\"penalty3\")\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     +tf.reduce_sum(tf.log(1+tf.exp(-thetas-pk)))\n",
    "        else:\n",
    "            loss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "            \n",
    "        print(\"loss\",loss)\n",
    "        tf.summary.scalar('un-normloss', loss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "#         print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "        print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(loss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',\n",
    "                                      tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        \n",
    "        # ep : epochs\n",
    "        # \n",
    "        def train(lr,ep,th,af,pcl=np.array([-1,1],dtype=np.float64),alp=0.99):\n",
    "            \n",
    "            with tf.Session() as sess:\n",
    "                sess.run(init_g)\n",
    "                sess.run(init_l)\n",
    "\n",
    "                # Initialize an iterator over the training dataset.\n",
    "                for en in range(ep):\n",
    "                    sess.run(train_init_op)\n",
    "                    tl = 0\n",
    "                    try:\n",
    "                        it = 0\n",
    "                        while True:\n",
    "                            sm,_,ls,t = sess.run([summary_merged,train_step,loss,thetas])\n",
    "    #                         print(t)\n",
    "    #                         print(tl)\n",
    "                            train_writer.add_summary(sm, it)\n",
    "    #                         if(ls<1e-5):\n",
    "    #                             break\n",
    "                            tl = tl + ls\n",
    "                            it = it + 1\n",
    "\n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                        pass\n",
    "                    print(en,\"loss\",tl)\n",
    "\n",
    "                    sess.run(dev_init_op)\n",
    "                    sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                    test_writer.add_summary(sm, en)\n",
    "                    print(a)\n",
    "                    print(t)\n",
    "                    unique, counts = np.unique(pl, return_counts=True)\n",
    "                    print(dict(zip(unique, counts)))\n",
    "                    print(\"acc\",accuracy_score(true_labels,pl))\n",
    "                    print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "                    print()\n",
    "\n",
    "                # Initialize an iterator over the validation dataset.\n",
    "                sess.run(dev_init_op)\n",
    "                a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "                print(a)\n",
    "                print(t)\n",
    "\n",
    "                unique, counts = np.unique(pl, return_counts=True)\n",
    "                print(dict(zip(unique, counts)))\n",
    "\n",
    "                print(\"acc\",accuracy_score(true_labels,pl))\n",
    "\n",
    "                predictAndPrint(pl)\n",
    "                print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "\n",
    "    #             cf = confusion_matrix(true_labels,pl)\n",
    "    #             print(cf)\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha-mean 0.0\n",
      "Tensor(\"unstack:1\", shape=(?, 20), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 20), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 20), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 20), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(20,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(20,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 316296.1427546758\n",
      "[ 0.00217267 -0.00087164  0.00096919  0.00090097  0.00204377 -0.00045195\n",
      "  0.00269119 -0.00046518  0.00067272 -0.00029975  0.00083276  0.00165394\n",
      "  0.00071775  0.00168156  0.0013875  -0.00044222 -0.00064075 -0.00164881\n",
      " -0.00024811 -0.00248627]\n",
      "[[1.11655159 0.81325374 1.0088643  0.9998848  1.10543027 1.04214755\n",
      "  1.1682078  1.03175196 1.14686665 1.0654861  0.98257832 1.06564649\n",
      "  0.98154307 1.07773224 1.03986736 1.04304946 0.85251199 0.9207007\n",
      "  1.06039125 0.83720317]]\n",
      "{0: 2468, 1: 346}\n",
      "acc 0.8909026297085999\n",
      "(0.32947976878612717, 0.6031746031746031, 0.4261682242990654, None)\n",
      "\n",
      "1 loss 315886.56546810875\n",
      "[ 0.00316983  0.00011441  0.00184244  0.00179561  0.0030236  -0.00131799\n",
      "  0.00369029 -0.00124127 -0.00011607 -0.00124924  0.00182974  0.00264162\n",
      "  0.00161336  0.00257899  0.00236669 -0.00130714  0.00018521 -0.00249869\n",
      " -0.00109417 -0.00333844]\n",
      "[[1.11555871 0.81229353 1.0081708  0.99914697 1.10448311 1.04295745\n",
      "  1.16720965 1.03229432 1.14739558 1.06625102 0.98158617 1.06467936\n",
      "  0.98070245 1.07688126 1.03892271 1.04386325 0.85168261 0.92146877\n",
      "  1.06115923 0.8379924 ]]\n",
      "{0: 2471, 1: 343}\n",
      "acc 0.8919687277896233\n",
      "(0.3323615160349854, 0.6031746031746031, 0.42857142857142855, None)\n",
      "\n",
      "2 loss 315478.70063556015\n",
      "[ 0.00416696  0.00110029  0.00271479  0.00268941  0.00400318 -0.00218335\n",
      "  0.00468938 -0.00201503 -0.00090229 -0.00219774  0.00282668  0.00362916\n",
      "  0.00250916  0.0034766   0.00334564 -0.00217138  0.00101028 -0.00334894\n",
      " -0.0019406  -0.00419096]\n",
      "[[1.1145659  0.81133375 1.00747864 0.99841057 1.10353647 1.0437668\n",
      "  1.16621152 1.03283383 1.14792087 1.06701124 0.98059411 1.06371257\n",
      "  0.97986145 1.07602995 1.03797862 1.04467642 0.85085394 0.92223756\n",
      "  1.06192787 0.83878225]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "3 loss 315072.6061528803\n",
      "[ 0.00516405  0.002086    0.00358623  0.00358236  0.00498253 -0.00304799\n",
      "  0.00568845 -0.00278637 -0.00168584 -0.00314519  0.00382358  0.00461655\n",
      "  0.00340514  0.0043744   0.00432433 -0.00303492  0.00183443 -0.00419952\n",
      " -0.00278736 -0.00504383]\n",
      "[[1.11357318 0.81037441 1.00678785 0.99767565 1.10259038 1.04457558\n",
      "  1.16521342 1.0333704  1.14844239 1.06776652 0.97960214 1.06274612\n",
      "  0.97902009 1.07517833 1.03703511 1.04548897 0.850026   0.92300707\n",
      "  1.06269717 0.83957271]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8930348258706468\n",
      "(0.3352941176470588, 0.6031746031746031, 0.4310018903591682, None)\n",
      "\n",
      "4 loss 314668.3227732771\n",
      "[ 0.0061611   0.00307153  0.00445672  0.00447442  0.00596162 -0.0039119\n",
      "  0.0066875  -0.00355519 -0.00246661 -0.00409154  0.00482044  0.00560378\n",
      "  0.0043013   0.00527236  0.00530276 -0.00389774  0.00265765 -0.00505044\n",
      " -0.00363446 -0.00589704]\n",
      "[[1.11258054 0.80941552 1.00609848 0.99694226 1.10164485 1.04538377\n",
      "  1.16421535 1.03390394 1.14896004 1.06851663 0.97861026 1.06178002\n",
      "  0.97817836 1.07432639 1.0360922  1.04630088 0.84919881 0.92377727\n",
      "  1.0634671  0.84036377]]\n",
      "{0: 2480, 1: 334}\n",
      "acc 0.8951670220326937\n",
      "(0.3413173652694611, 0.6031746031746031, 0.4359464627151052, None)\n",
      "\n",
      "[ 0.0061611   0.00307153  0.00445672  0.00447442  0.00596162 -0.0039119\n",
      "  0.0066875  -0.00355519 -0.00246661 -0.00409154  0.00482044  0.00560378\n",
      "  0.0043013   0.00527236  0.00530276 -0.00389774  0.00265765 -0.00505044\n",
      " -0.00363446 -0.00589704]\n",
      "[[1.11258054 0.80941552 1.00609848 0.99694226 1.10164485 1.04538377\n",
      "  1.16421535 1.03390394 1.14896004 1.06851663 0.97861026 1.06178002\n",
      "  0.97817836 1.07432639 1.0360922  1.04630088 0.84919881 0.92377727\n",
      "  1.0634671  0.84036377]]\n",
      "{0: 2480, 1: 334}\n",
      "acc 0.8951670220326937\n",
      "acc 0.8951670220326937\n",
      "[[2405  220]\n",
      " [  75  114]]\n",
      "(0.3413173652694611, 0.6031746031746031, 0.4359464627151052, None)\n",
      "alpha-mean 0.1\n",
      "Tensor(\"unstack:1\", shape=(?, 20), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 20), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 20), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 20), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(20,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(20,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 311650.0323628715\n",
      "[0.10217149 0.09912221 0.10092488 0.10086138 0.10203561 0.09956663\n",
      " 0.10269093 0.09960161 0.10074482 0.09973232 0.10083147 0.10164874\n",
      " 0.10070373 0.10166776 0.10137899 0.09957675 0.09932769 0.09836902\n",
      " 0.09977001 0.0975314 ]\n",
      "[[1.11655474 0.81327086 1.00894626 0.9999631  1.10545118 1.04213525\n",
      "  1.16820843 1.03169249 1.14679684 1.06538572 0.98258185 1.06566039\n",
      "  0.98156559 1.07775337 1.03988933 1.04303611 0.85252863 0.92067702\n",
      "  1.06036782 0.83718299]]\n",
      "{0: 2471, 1: 343}\n",
      "acc 0.8919687277896233\n",
      "(0.3323615160349854, 0.6031746031746031, 0.42857142857142855, None)\n",
      "\n",
      "1 loss 311318.3278124663\n",
      "[0.10316744 0.10010196 0.10175294 0.10171564 0.10300714 0.09871929\n",
      " 0.10368975 0.09889344 0.10002951 0.09881479 0.10182713 0.10263107\n",
      " 0.10158535 0.10255142 0.10234954 0.09873094 0.1001219  0.09753699\n",
      " 0.09894208 0.09669691]\n",
      "[[1.11556511 0.81232822 1.00833581 0.99930475 1.10452521 1.04293281\n",
      "  1.16721093 1.03217474 1.14725524 1.06604722 0.98159335 1.0647075\n",
      "  0.9807475  1.07692359 1.03896697 1.04383648 0.85171612 0.9214214\n",
      "  1.0611123  0.83795208]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "2 loss 310988.2558934505\n",
      "[0.10416332 0.1010814  0.10257952 0.10256847 0.10397828 0.09787281\n",
      " 0.10468855 0.09818871 0.09931813 0.09789936 0.10282272 0.10361317\n",
      " 0.10246719 0.10343527 0.10331967 0.09788598 0.10091497 0.09670456\n",
      " 0.09811377 0.09586203]\n",
      "[[1.11457562 0.8113863  1.00772729 0.99864854 1.10360012 1.04372976\n",
      "  1.16621348 1.03265365 1.14770932 1.06670102 0.980605   1.06375518\n",
      "  0.97992901 1.07609347 1.03804553 1.04463615 0.85090455 0.92216657\n",
      "  1.06185749 0.83872183]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8930348258706468\n",
      "(0.3352941176470588, 0.6031746031746031, 0.4310018903591682, None)\n",
      "\n",
      "3 loss 310659.85874508397\n",
      "[0.10515915 0.10206054 0.10340456 0.10341985 0.104949   0.09702721\n",
      " 0.10568733 0.09748751 0.09861084 0.09698613 0.10381824 0.10459501\n",
      " 0.10334922 0.10431933 0.10428937 0.09704189 0.10170687 0.09587177\n",
      " 0.09728509 0.09502678]\n",
      "[[1.11358627 0.81044514 1.00712075 0.99799451 1.10267592 1.04452608\n",
      "  1.16521607 1.03312914 1.14815899 1.06734681 0.97961682 1.06280344\n",
      "  0.97911014 1.07526303 1.03712504 1.04543513 0.85009392 0.9229125\n",
      "  1.06260337 0.83949222]]\n",
      "{0: 2477, 1: 337}\n",
      "acc 0.8941009239516702\n",
      "(0.33827893175074186, 0.6031746031746031, 0.4334600760456274, None)\n",
      "\n",
      "4 loss 310333.1635468749\n",
      "[0.10615491 0.10303936 0.10422803 0.10426973 0.1059193  0.09618252\n",
      " 0.10668608 0.09678996 0.09790775 0.09607522 0.10481369 0.10557659\n",
      " 0.10423145 0.10520358 0.10525862 0.09619869 0.10249756 0.09503861\n",
      " 0.09645605 0.09419116]\n",
      "[[1.11259706 0.80950476 1.00651624 0.99734272 1.10175264 1.04532176\n",
      "  1.1642187  1.03360113 1.14860416 1.06798424 0.97862881 1.0618523\n",
      "  0.97829089 1.07443226 1.03620554 1.04623337 0.84928426 0.92365919\n",
      "  1.06334994 0.84026323]]\n",
      "{0: 2484, 1: 330}\n",
      "acc 0.896588486140725\n",
      "(0.34545454545454546, 0.6031746031746031, 0.4393063583815029, None)\n",
      "\n",
      "[0.10615491 0.10303936 0.10422803 0.10426973 0.1059193  0.09618252\n",
      " 0.10668608 0.09678996 0.09790775 0.09607522 0.10481369 0.10557659\n",
      " 0.10423145 0.10520358 0.10525862 0.09619869 0.10249756 0.09503861\n",
      " 0.09645605 0.09419116]\n",
      "[[1.11259706 0.80950476 1.00651624 0.99734272 1.10175264 1.04532176\n",
      "  1.1642187  1.03360113 1.14860416 1.06798424 0.97862881 1.0618523\n",
      "  0.97829089 1.07443226 1.03620554 1.04623337 0.84928426 0.92365919\n",
      "  1.06334994 0.84026323]]\n",
      "{0: 2484, 1: 330}\n",
      "acc 0.896588486140725\n",
      "acc 0.896588486140725\n",
      "[[2409  216]\n",
      " [  75  114]]\n",
      "(0.34545454545454546, 0.6031746031746031, 0.4393063583815029, None)\n",
      "alpha-mean 0.2\n",
      "Tensor(\"unstack:1\", shape=(?, 20), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 20), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 20), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 20), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(20,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(20,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 308259.399476211\n",
      "[0.20216933 0.19911087 0.20085377 0.20079613 0.20202091 0.19958776\n",
      " 0.20269049 0.19968894 0.20084305 0.19979596 0.20082911 0.2016392\n",
      " 0.20068622 0.20165043 0.20136364 0.19959857 0.19928748 0.19838969\n",
      " 0.19979093 0.19755191]\n",
      "[[1.11656052 0.81330086 1.00905562 1.00007129 1.10548674 1.04212231\n",
      "  1.16820953 1.03162946 1.14672255 1.06523777 0.98258835 1.06568484\n",
      "  0.9815963  1.07778253 1.03992662 1.04302145 0.85254743 0.92064571\n",
      "  1.06033652 0.83715631]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.892679459843639\n",
      "(0.3343108504398827, 0.6031746031746031, 0.430188679245283, None)\n",
      "\n",
      "1 loss 308000.25505498523\n",
      "[0.20316304 0.20007896 0.20160944 0.20158389 0.2029775  0.19876162\n",
      " 0.20368885 0.19906925 0.20022738 0.19894285 0.20182231 0.20261175\n",
      " 0.20155042 0.20251684 0.2023186  0.19877465 0.2000414  0.19757824\n",
      " 0.19898385 0.19673786]\n",
      "[[1.11557688 0.812389   1.00855543 0.99952231 1.10459681 1.04290696\n",
      "  1.16721318 1.03204841 1.14710641 1.06574658 0.98160658 1.06475702\n",
      "  0.98080893 1.07698199 1.03904204 1.04380716 0.85175398 0.92135887\n",
      "  1.06104971 0.83789886]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8930348258706468\n",
      "(0.3352941176470588, 0.6031746031746031, 0.4310018903591682, None)\n",
      "\n",
      "2 loss 307742.4479271092\n",
      "[0.20415664 0.20104651 0.20236284 0.20236939 0.20393341 0.19793643\n",
      " 0.20468718 0.19845395 0.199617   0.19809415 0.2028154  0.20358387\n",
      " 0.2024149  0.20338353 0.20327283 0.19795167 0.20079401 0.19676628\n",
      " 0.19817626 0.1959233 ]\n",
      "[[1.11459349 0.81147839 1.00805761 0.99897607 1.10370828 1.04369101\n",
      "  1.1662169  1.03246393 1.14748581 1.06624445 0.9806251  1.06383015\n",
      "  0.98002109 1.07618105 1.03815895 1.04459218 0.85096165 0.92207298\n",
      "  1.06176377 0.8386422 ]]\n",
      "{0: 2477, 1: 337}\n",
      "acc 0.8941009239516702\n",
      "(0.33827893175074186, 0.6031746031746031, 0.4334600760456274, None)\n",
      "\n",
      "3 loss 307486.00405823626\n",
      "[0.20515014 0.2020135  0.20311391 0.20315261 0.20488861 0.19711222\n",
      " 0.20568549 0.19784317 0.19901205 0.19725011 0.20380836 0.20455554\n",
      " 0.20327968 0.2042505  0.20422631 0.19712964 0.20154529 0.19595381\n",
      " 0.19736816 0.19510823]\n",
      "[[1.11361034 0.81056905 1.00756219 0.99843261 1.10282118 1.04447446\n",
      "  1.16522068 1.03287596 1.14786069 1.06673101 0.97964392 1.06290428\n",
      "  0.97923279 1.07537973 1.03727738 1.04537649 0.85017044 0.92278802\n",
      "  1.06247868 0.83938631]]\n",
      "{0: 2484, 1: 330}\n",
      "acc 0.896588486140725\n",
      "(0.34545454545454546, 0.6031746031746031, 0.4393063583815029, None)\n",
      "\n",
      "4 loss 307230.9369266149\n",
      "[0.20614352 0.20297992 0.20386261 0.20393347 0.20584308 0.196289\n",
      " 0.20668376 0.19723701 0.19841266 0.19641095 0.2048012  0.20552674\n",
      " 0.20414475 0.20511776 0.20517902 0.19630858 0.20229522 0.19514085\n",
      " 0.19655958 0.19429267]\n",
      "[[1.11262746 0.80966103 1.0070692  0.99789197 1.10193557 1.04525729\n",
      "  1.16422453 1.03328445 1.14823098 1.06720589 0.97866303 1.06197942\n",
      "  0.97844402 1.07457802 1.03639738 1.04616009 0.84938039 0.923504\n",
      "  1.06319444 0.84013119]]\n",
      "{0: 2484, 1: 330}\n",
      "acc 0.896588486140725\n",
      "(0.34545454545454546, 0.6031746031746031, 0.4393063583815029, None)\n",
      "\n",
      "[0.20614352 0.20297992 0.20386261 0.20393347 0.20584308 0.196289\n",
      " 0.20668376 0.19723701 0.19841266 0.19641095 0.2048012  0.20552674\n",
      " 0.20414475 0.20511776 0.20517902 0.19630858 0.20229522 0.19514085\n",
      " 0.19655958 0.19429267]\n",
      "[[1.11262746 0.80966103 1.0070692  0.99789197 1.10193557 1.04525729\n",
      "  1.16422453 1.03328445 1.14823098 1.06720589 0.97866303 1.06197942\n",
      "  0.97844402 1.07457802 1.03639738 1.04616009 0.84938039 0.923504\n",
      "  1.06319444 0.84013119]]\n",
      "{0: 2484, 1: 330}\n",
      "acc 0.896588486140725\n",
      "acc 0.896588486140725\n",
      "[[2409  216]\n",
      " [  75  114]]\n",
      "(0.34545454545454546, 0.6031746031746031, 0.4393063583815029, None)\n",
      "alpha-mean 0.30000000000000004\n",
      "Tensor(\"unstack:1\", shape=(?, 20), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 20), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 20), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 20), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(20,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(20,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 306118.8933977565\n",
      "[0.30216502 0.29908866 0.30074376 0.30069151 0.30199315 0.29961008\n",
      " 0.30268969 0.29979029 0.30096053 0.29992109 0.30082435 0.30162066\n",
      " 0.30066509 0.30162941 0.30133465 0.29962204 0.29923934 0.2984126\n",
      " 0.29981399 0.29757474]\n",
      "[[1.11657187 0.81335433 1.00918906 1.00020829 1.10554755 1.04210968\n",
      "  1.16821161 1.03157037 1.14665347 1.06505435 0.98260113 1.06572898\n",
      "  0.98163964 1.0778244  1.03999005 1.04300628 0.85256596 0.92060304\n",
      "  1.06029314 0.83711957]]\n",
      "{0: 2475, 1: 339}\n",
      "acc 0.8933901918976546\n",
      "(0.336283185840708, 0.6031746031746031, 0.4318181818181818, None)\n",
      "\n",
      "1 loss 305923.81715354376\n",
      "[0.30315425 0.30003392 0.30138795 0.30137301 0.30292158 0.2988062\n",
      " 0.30368721 0.29927254 0.3004631  0.29919631 0.30181261 0.30257419\n",
      " 0.30150831 0.30247495 0.30226018 0.29882153 0.29994523 0.29762387\n",
      " 0.29902978 0.29678333]\n",
      "[[1.1156     0.81249732 1.00882256 0.9997969  1.10471914 1.04288182\n",
      "  1.16721745 1.03193041 1.14696863 1.06537518 0.98163265 1.06484638\n",
      "  0.98089564 1.07706586 1.03916965 1.04377692 0.85179136 0.92127368\n",
      "  1.06096304 0.83782568]]\n",
      "{0: 2480, 1: 334}\n",
      "acc 0.8951670220326937\n",
      "(0.3413173652694611, 0.6031746031746031, 0.4359464627151052, None)\n",
      "\n",
      "2 loss 305729.6335456576\n",
      "[0.30414327 0.3009782  0.30202913 0.30205138 0.30384882 0.29800324\n",
      " 0.30468468 0.29875954 0.29997155 0.29848015 0.30280065 0.30352694\n",
      " 0.30235201 0.30332096 0.30318445 0.29802191 0.30064984 0.29683436\n",
      " 0.29824479 0.29599114]\n",
      "[[1.1146286  0.81164232 1.00845837 0.99938839 1.10389285 1.04365346\n",
      "  1.16622339 1.03228742 1.14727981 1.06568369 0.98066469 1.06396536\n",
      "  0.98015103 1.07630681 1.03835149 1.04454697 0.851018   0.9219456\n",
      "  1.06163414 0.83853285]]\n",
      "{0: 2484, 1: 330}\n",
      "acc 0.896588486140725\n",
      "(0.34545454545454546, 0.6031746031746031, 0.4393063583815029, None)\n",
      "\n",
      "3 loss 305536.35600284213\n",
      "[0.3051321  0.30192146 0.30266726 0.30272655 0.30477483 0.29720121\n",
      " 0.30568211 0.29825137 0.29948599 0.29777299 0.30378845 0.30447887\n",
      " 0.30319621 0.30416745 0.30410744 0.2972232  0.30135317 0.29604408\n",
      " 0.29745901 0.29519817]\n",
      "[[1.11365765 0.81078939 1.00809652 0.9989828  1.10306873 1.04442461\n",
      "  1.16522943 1.03264135 1.14758699 1.06597968 0.97969729 1.06308596\n",
      "  0.97940581 1.07554723 1.03753562 1.04531643 0.8502459  0.92261879\n",
      "  1.06230642 0.83924107]]\n",
      "{0: 2484, 1: 330}\n",
      "acc 0.896588486140725\n",
      "(0.34545454545454546, 0.6031746031746031, 0.4393063583815029, None)\n",
      "\n",
      "4 loss 305343.9880643581\n",
      "[0.30612072 0.30286367 0.30330229 0.30339849 0.30569959 0.29640013\n",
      " 0.30667949 0.29774809 0.29900651 0.29707526 0.30477602 0.30542998\n",
      " 0.30404089 0.30501441 0.30502909 0.2964254  0.3020552  0.29525302\n",
      " 0.29667246 0.29440444]\n",
      "[[1.11268719 0.80993858 1.00773701 0.99858014 1.10224685 1.04519525\n",
      "  1.16423557 1.03299218 1.14789014 1.06626291 0.97873043 1.06220821\n",
      "  0.97865998 1.07478715 1.0367221  1.04608528 0.84947507 0.92329323\n",
      "  1.06297988 0.83995033]]\n",
      "{0: 2486, 1: 328}\n",
      "acc 0.896588486140725\n",
      "(0.3445121951219512, 0.5978835978835979, 0.437137330754352, None)\n",
      "\n",
      "[0.30612072 0.30286367 0.30330229 0.30339849 0.30569959 0.29640013\n",
      " 0.30667949 0.29774809 0.29900651 0.29707526 0.30477602 0.30542998\n",
      " 0.30404089 0.30501441 0.30502909 0.2964254  0.3020552  0.29525302\n",
      " 0.29667246 0.29440444]\n",
      "[[1.11268719 0.80993858 1.00773701 0.99858014 1.10224685 1.04519525\n",
      "  1.16423557 1.03299218 1.14789014 1.06626291 0.97873043 1.06220821\n",
      "  0.97865998 1.07478715 1.0367221  1.04608528 0.84947507 0.92329323\n",
      "  1.06297988 0.83995033]]\n",
      "{0: 2486, 1: 328}\n",
      "acc 0.896588486140725\n",
      "acc 0.896588486140725\n",
      "[[2410  215]\n",
      " [  76  113]]\n",
      "(0.3445121951219512, 0.5978835978835979, 0.437137330754352, None)\n",
      "alpha-mean 0.4\n",
      "Tensor(\"unstack:1\", shape=(?, 20), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 20), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 20), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 20), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(20,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(20,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 305126.7774691526\n",
      "[0.40215556 0.39904328 0.40058909 0.40053792 0.40193926 0.39963171\n",
      " 0.40268801 0.3998897  0.40107677 0.40013373 0.40081385 0.40158283\n",
      " 0.40064018 0.40160452 0.40127845 0.39964553 0.3991862  0.39843731\n",
      " 0.39983868 0.39759947]\n",
      "[[1.11659559 0.81344711 1.00933322 1.00036122 1.10564767 1.04209813\n",
      "  1.16821597 1.03152278 1.14659919 1.06488103 0.98262783 1.06580789\n",
      "  0.98170531 1.07788983 1.04009349 1.04299123 0.85258029 0.92054079\n",
      "  1.06022785 0.83706358]]\n",
      "{0: 2481, 1: 333}\n",
      "acc 0.8955223880597015\n",
      "(0.34234234234234234, 0.6031746031746031, 0.4367816091954023, None)\n",
      "\n",
      "1 loss 304985.3672102577\n",
      "[0.40313494 0.39994194 0.40107772 0.40106451 0.40281312 0.39884927\n",
      " 0.40368378 0.39947106 0.40069514 0.3996277  0.40179117 0.40249757\n",
      " 0.40145874 0.40242541 0.40214706 0.39886831 0.3998393  0.39767296\n",
      " 0.39907881 0.39683246]\n",
      "[[1.11564838 0.81268512 1.00911011 1.0001023  1.10492024 1.04285892\n",
      "  1.16722635 1.03183581 1.14686089 1.06502667 0.98168712 1.06500603\n",
      "  0.98102714 1.07719704 1.03937745 1.04374701 0.8518207  0.92114945\n",
      "  1.06083264 0.8377142 ]]\n",
      "{0: 2484, 1: 330}\n",
      "acc 0.896588486140725\n",
      "(0.34545454545454546, 0.6031746031746031, 0.4393063583815029, None)\n",
      "\n",
      "2 loss 304844.36797987355\n",
      "[0.40411393 0.40083882 0.40156319 0.40158755 0.40368501 0.39806756\n",
      " 0.40467946 0.3990566  0.40031878 0.39913468 0.40276804 0.4034109\n",
      " 0.40227811 0.40324709 0.40301359 0.39809179 0.40049144 0.39690741\n",
      " 0.39831773 0.39606426]\n",
      "[[1.11470203 0.81192606 1.0088887  0.99984575 1.10419566 1.04361939\n",
      "  1.1662369  1.03214653 1.14711957 1.06516192 0.98074741 1.06420656\n",
      "  0.98034818 1.07650358 1.03866436 1.0445024  0.8510625  0.92175987\n",
      "  1.06143916 0.83836636]]\n",
      "{0: 2485, 1: 329}\n",
      "acc 0.8962331201137171\n",
      "(0.3434650455927052, 0.5978835978835979, 0.4362934362934363, None)\n",
      "\n",
      "3 loss 304703.7859918385\n",
      "[0.40509252 0.40173389 0.40204547 0.40210701 0.40455488 0.39728661\n",
      " 0.40567507 0.39864637 0.39994772 0.39865501 0.40374445 0.40432279\n",
      " 0.4030983  0.40406957 0.403878   0.39731595 0.40114262 0.39614066\n",
      " 0.39755543 0.39529486]\n",
      "[[1.11375655 0.81116999 1.00866897 0.99959158 1.10347398 1.04437955\n",
      "  1.16524762 1.03245495 1.1473752  1.06528676 0.97980872 1.0634095\n",
      "  0.97966844 1.07580945 1.03795429 1.04525741 0.85030568 0.92237206\n",
      "  1.06204741 0.83902004]]\n",
      "{0: 2487, 1: 327}\n",
      "acc 0.8969438521677328\n",
      "(0.345565749235474, 0.5978835978835979, 0.437984496124031, None)\n",
      "\n",
      "4 loss 304563.62001383246\n",
      "[0.40607069 0.4026271  0.40252455 0.40262285 0.40542267 0.3965064\n",
      " 0.4066706  0.39824038 0.399582   0.39818908 0.40472039 0.4052332\n",
      " 0.40391929 0.40489284 0.40474021 0.39654082 0.40179284 0.39537271\n",
      " 0.39679193 0.39452427]\n",
      "[[1.11281197 0.81041694 1.00845093 0.99933978 1.10275524 1.04513939\n",
      "  1.16425852 1.03276104 1.14762779 1.06540116 0.97887106 1.0626149\n",
      "  0.97898792 1.07511466 1.03724728 1.04601201 0.84955026 0.92298602\n",
      "  1.06265739 0.83967525]]\n",
      "{0: 2488, 1: 326}\n",
      "acc 0.8972992181947406\n",
      "(0.34662576687116564, 0.5978835978835979, 0.4388349514563107, None)\n",
      "\n",
      "[0.40607069 0.4026271  0.40252455 0.40262285 0.40542267 0.3965064\n",
      " 0.4066706  0.39824038 0.399582   0.39818908 0.40472039 0.4052332\n",
      " 0.40391929 0.40489284 0.40474021 0.39654082 0.40179284 0.39537271\n",
      " 0.39679193 0.39452427]\n",
      "[[1.11281197 0.81041694 1.00845093 0.99933978 1.10275524 1.04513939\n",
      "  1.16425852 1.03276104 1.14762779 1.06540116 0.97887106 1.0626149\n",
      "  0.97898792 1.07511466 1.03724728 1.04601201 0.84955026 0.92298602\n",
      "  1.06265739 0.83967525]]\n",
      "{0: 2488, 1: 326}\n",
      "acc 0.8972992181947406\n",
      "acc 0.8972992181947406\n",
      "[[2412  213]\n",
      " [  76  113]]\n",
      "(0.34662576687116564, 0.5978835978835979, 0.4388349514563107, None)\n",
      "alpha-mean 0.5\n",
      "Tensor(\"unstack:1\", shape=(?, 20), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 20), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 20), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 20), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(20,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(20,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 305090.774872005\n",
      "[0.50213279 0.49895102 0.50040386 0.50034588 0.50183695 0.49965142\n",
      " 0.50268397 0.4999695  0.50116853 0.50038908 0.50078847 0.50150468\n",
      " 0.50057891 0.50156661 0.50117244 0.49966818 0.49913279 0.49846481\n",
      " 0.49987376 0.49762711]\n",
      "[[1.11664714 0.81359262 1.00946942 1.00050936 1.10579587 1.04208754\n",
      "  1.16822606 1.03149112 1.14656445 1.06474781 0.98268531 1.06593866\n",
      "  0.9818169  1.07800782 1.04024435 1.04297542 0.85260774 0.920441\n",
      "  1.06011701 0.83696076]]\n",
      "{0: 2474, 1: 340}\n",
      "acc 0.8930348258706468\n",
      "(0.3352941176470588, 0.6031746031746031, 0.4310018903591682, None)\n",
      "\n",
      "1 loss 304994.2942344216\n",
      "[0.50308845 0.49975516 0.50070781 0.5006805  0.50260754 0.49888836\n",
      " 0.50367553 0.49962969 0.50087733 0.50014271 0.50173933 0.50233942\n",
      " 0.50132936 0.5023501  0.50193403 0.49891331 0.49973303 0.49772758\n",
      " 0.49914076 0.49688736]\n",
      "[[1.11575358 0.81297943 1.00938108 1.00039726 1.10521748 1.042838\n",
      "  1.16724686 1.03177326 1.14679285 1.06477451 0.98180443 1.06527044\n",
      "  0.9812507  1.07743395 1.03968001 1.0437161  0.85187845 0.92095007\n",
      "  1.06061114 0.83750929]]\n",
      "{0: 2478, 1: 336}\n",
      "acc 0.8937455579246624\n",
      "(0.33630952380952384, 0.5978835978835979, 0.4304761904761905, None)\n",
      "\n",
      "2 loss 304897.93737386283\n",
      "[0.50404329 0.50055642 0.50100937 0.50101215 0.50337525 0.49812575\n",
      " 0.50466695 0.49929286 0.5005899  0.49990874 0.50268924 0.50317182\n",
      " 0.50208081 0.50313475 0.5026926  0.4981588  0.50030652 0.49698864\n",
      " 0.49840603 0.49614591]\n",
      "[[1.11486158 0.81236968 1.00929351 1.0002866  1.10464213 1.04358836\n",
      "  1.16626797 1.03205395 1.14701928 1.0647944  0.98092536 1.06460519\n",
      "  0.98068355 1.0768595  1.03911878 1.04445666 0.85115158 0.9214615\n",
      "  1.06110767 0.83806009]]\n",
      "{0: 2480, 1: 334}\n",
      "acc 0.894456289978678\n",
      "(0.3383233532934132, 0.5978835978835979, 0.4321223709369025, None)\n",
      "\n",
      "3 loss 304802.3817881797\n",
      "[0.50499728 0.50135476 0.50130853 0.5013408  0.50414001 0.49736361\n",
      " 0.50565822 0.49895903 0.50030625 0.49968724 0.50363819 0.50400185\n",
      " 0.50283324 0.50392043 0.50344811 0.49740466 0.50086589 0.49624803\n",
      " 0.49766962 0.4954028 ]\n",
      "[[1.11397118 0.81176339 1.00920673 1.00017739 1.10406985 1.04433862\n",
      "  1.16528939 1.03233318 1.14724375 1.06480751 0.98004812 1.06394296\n",
      "  0.98011549 1.07628451 1.03856069 1.04519708 0.85042679 0.92197527\n",
      "  1.06160658 0.83861311]]\n",
      "{0: 2481, 1: 333}\n",
      "acc 0.8948116560056859\n",
      "(0.33933933933933935, 0.5978835978835979, 0.4329501915708812, None)\n",
      "\n",
      "4 loss 304706.9680261733\n",
      "[0.50595041 0.50215012 0.50160529 0.50166645 0.50490179 0.49660193\n",
      " 0.50664933 0.49862819 0.5000264  0.49947826 0.50458614 0.50482946\n",
      " 0.50358664 0.50470718 0.50420051 0.4966509  0.50142395 0.49550576\n",
      " 0.49693153 0.49465805]\n",
      "[[1.11308241 0.81116061 1.00912074 1.00006963 1.10350066 1.04508878\n",
      "  1.16431114 1.03261095 1.14746627 1.06481388 0.97917273 1.06328377\n",
      "  0.97954653 1.07570899 1.03800577 1.04593736 0.84970407 0.92249137\n",
      "  1.06210787 0.83916836]]\n",
      "{0: 2481, 1: 333}\n",
      "acc 0.8948116560056859\n",
      "(0.33933933933933935, 0.5978835978835979, 0.4329501915708812, None)\n",
      "\n",
      "[0.50595041 0.50215012 0.50160529 0.50166645 0.50490179 0.49660193\n",
      " 0.50664933 0.49862819 0.5000264  0.49947826 0.50458614 0.50482946\n",
      " 0.50358664 0.50470718 0.50420051 0.4966509  0.50142395 0.49550576\n",
      " 0.49693153 0.49465805]\n",
      "[[1.11308241 0.81116061 1.00912074 1.00006963 1.10350066 1.04508878\n",
      "  1.16431114 1.03261095 1.14746627 1.06481388 0.97917273 1.06328377\n",
      "  0.97954653 1.07570899 1.03800577 1.04593736 0.84970407 0.92249137\n",
      "  1.06210787 0.83916836]]\n",
      "{0: 2481, 1: 333}\n",
      "acc 0.8948116560056859\n",
      "acc 0.8948116560056859\n",
      "[[2405  220]\n",
      " [  76  113]]\n",
      "(0.33933933933933935, 0.5978835978835979, 0.4329501915708812, None)\n",
      "alpha-mean 0.6000000000000001\n",
      "Tensor(\"unstack:1\", shape=(?, 20), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 20), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 20), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 20), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(20,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(20,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 305843.5936084057\n",
      "[0.60207473 0.59878245 0.60020856 0.60014407 0.60166222 0.59967006\n",
      " 0.60267382 0.60002202 0.60122543 0.60059253 0.60072412 0.60135456\n",
      " 0.60049595 0.60145869 0.60099395 0.59969246 0.599      0.59858187\n",
      " 0.59997064 0.59775948]\n",
      "[[1.11675496 0.81378185 1.00959404 1.00064028 1.10598165 1.04207601\n",
      "  1.16824893 1.03147388 1.14654893 1.06468959 0.98280236 1.06612269\n",
      "  0.98199962 1.07823646 1.04043002 1.04295652 0.85261936 0.92029834\n",
      "  1.05992644 0.83677718]]\n",
      "{0: 2462, 1: 352}\n",
      "acc 0.8873489694385217\n",
      "(0.3181818181818182, 0.5925925925925926, 0.4140480591497227, None)\n",
      "\n",
      "1 loss 305789.3398542951\n",
      "[0.60296987 0.59941425 0.60031903 0.60027856 0.60225709 0.59892531\n",
      " 0.60365479 0.59973353 0.60098916 0.60053555 0.60160786 0.60203589\n",
      " 0.60117    0.6021328  0.60157604 0.59896109 0.59946449 0.59796153\n",
      " 0.59934108 0.59715148]\n",
      "[[1.11597358 0.81336212 1.0096289  1.00065752 1.10558978 1.04281515\n",
      "  1.16729354 1.03173932 1.14676264 1.06465988 0.9820433  1.06564259\n",
      "  0.98161736 1.07789288 1.04005204 1.04367854 0.85190776 0.92066427\n",
      "  1.06022977 0.83714246]]\n",
      "{0: 2465, 1: 349}\n",
      "acc 0.8884150675195451\n",
      "(0.3209169054441261, 0.5925925925925926, 0.4163568773234201, None)\n",
      "\n",
      "2 loss 305734.97207654966\n",
      "[0.60386333 0.60004252 0.60042826 0.60041125 0.60284879 0.59818071\n",
      " 0.60463545 0.59944673 0.60075506 0.60048606 0.60248972 0.60271416\n",
      " 0.60184494 0.60280748 0.60215489 0.59822974 0.59992691 0.59733901\n",
      " 0.59870711 0.59654013]\n",
      "[[1.11519467 0.81294527 1.00966391 1.0006754  1.1052002  1.0435544\n",
      "  1.16633875 1.03200405 1.14697531 1.06462657 0.98128696 1.06516522\n",
      "  0.98123465 1.07754955 1.03967637 1.04440069 0.85119863 0.92103252\n",
      "  1.06053543 0.83751024]]\n",
      "{0: 2467, 1: 347}\n",
      "acc 0.8891257995735607\n",
      "(0.3227665706051873, 0.5925925925925926, 0.417910447761194, None)\n",
      "\n",
      "3 loss 305680.47589528846\n",
      "[0.6047551  0.60066723 0.60053626 0.60054217 0.60343731 0.59743626\n",
      " 0.60561578 0.59916161 0.60052311 0.600444   0.60336965 0.60338932\n",
      " 0.6025209  0.60348171 0.60273048 0.59749843 0.60038741 0.59671423\n",
      " 0.5980699  0.59592632]\n",
      "[[1.11441826 0.8125313  1.00969905 1.00069394 1.10481292 1.04429376\n",
      "  1.16538459 1.03226804 1.14718693 1.06458969 0.98053336 1.06469058\n",
      "  0.9808515  1.0772065  1.039303   1.04512295 0.850492   0.9214031\n",
      "  1.06084344 0.83788054]]\n",
      "{0: 2469, 1: 345}\n",
      "acc 0.8898365316275764\n",
      "(0.32463768115942027, 0.5925925925925926, 0.4194756554307116, None)\n",
      "\n",
      "4 loss 305625.8951642269\n",
      "[0.60564514 0.60128836 0.60064303 0.60067131 0.60402261 0.59669196\n",
      " 0.60659578 0.59887818 0.60029331 0.60040934 0.60424763 0.60406136\n",
      " 0.60319782 0.60415616 0.60330279 0.59676716 0.60084549 0.59608742\n",
      " 0.59742998 0.59531015]\n",
      "[[1.11364436 0.8121202  1.0097343  1.00071311 1.10442794 1.04503322\n",
      "  1.16443106 1.03253131 1.14739752 1.06454926 0.97978253 1.06421867\n",
      "  0.9804679  1.07686372 1.03893193 1.04584532 0.8497879  0.921776\n",
      "  1.06115381 0.83825336]]\n",
      "{0: 2469, 1: 345}\n",
      "acc 0.8898365316275764\n",
      "(0.32463768115942027, 0.5925925925925926, 0.4194756554307116, None)\n",
      "\n",
      "[0.60564514 0.60128836 0.60064303 0.60067131 0.60402261 0.59669196\n",
      " 0.60659578 0.59887818 0.60029331 0.60040934 0.60424763 0.60406136\n",
      " 0.60319782 0.60415616 0.60330279 0.59676716 0.60084549 0.59608742\n",
      " 0.59742998 0.59531015]\n",
      "[[1.11364436 0.8121202  1.0097343  1.00071311 1.10442794 1.04503322\n",
      "  1.16443106 1.03253131 1.14739752 1.06454926 0.97978253 1.06421867\n",
      "  0.9804679  1.07686372 1.03893193 1.04584532 0.8497879  0.921776\n",
      "  1.06115381 0.83825336]]\n",
      "{0: 2469, 1: 345}\n",
      "acc 0.8898365316275764\n",
      "acc 0.8898365316275764\n",
      "[[2392  233]\n",
      " [  77  112]]\n",
      "(0.32463768115942027, 0.5925925925925926, 0.4194756554307116, None)\n",
      "alpha-mean 0.7000000000000001\n",
      "Tensor(\"unstack:1\", shape=(?, 20), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 20), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 20), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 20), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(20,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(20,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 306938.190421794\n",
      "[0.70193314 0.69854422 0.70003742 0.69997189 0.70142824 0.69969353\n",
      " 0.70264554 0.70005013 0.70124993 0.70068222 0.70057171 0.7011228\n",
      " 0.70019828 0.70109722 0.70075992 0.69972581 0.69899965 0.69887203\n",
      " 0.7003602  0.69810625]\n",
      "[[1.1169454  0.81397442 1.00969856 1.00074402 1.1061685  1.04205744\n",
      "  1.16830177 1.03146615 1.14654705 1.06467719 0.98299965 1.06632653\n",
      "  0.98224914 1.0784792  1.04061349 1.04292452 0.85264672 0.92013426\n",
      "  1.05976695 0.8364785 ]]\n",
      "{0: 2470, 1: 344}\n",
      "acc 0.8901918976545842\n",
      "(0.32558139534883723, 0.5925925925925926, 0.4202626641651032, None)\n",
      "\n",
      "1 loss 306919.3611049616\n",
      "[0.70268078 0.69893261 0.69997846 0.69993623 0.70178823 0.69897219\n",
      " 0.70359667 0.69978901 0.70103703 0.7007127  0.7012967  0.70156733\n",
      " 0.70057215 0.70140726 0.70110712 0.69902779 0.69944984 0.6985436\n",
      " 0.70012385 0.69784725]\n",
      "[[1.1163621  0.81375152 1.00983715 1.0008638  1.10596421 1.04277795\n",
      "  1.16740247 1.03172406 1.14675936 1.06463697 0.98244566 1.06605498\n",
      "  0.9821171  1.07837783 1.04041968 1.04361444 0.85196765 0.92033443\n",
      "  1.05990946 0.83654276]]\n",
      "{0: 2470, 1: 344}\n",
      "acc 0.8901918976545842\n",
      "(0.32558139534883723, 0.5925925925925926, 0.4202626641651032, None)\n",
      "\n",
      "2 loss 306900.54733400565\n",
      "[0.70342582 0.69931845 0.69991891 0.69989973 0.70214611 0.69825085\n",
      " 0.70454712 0.69952861 0.70082505 0.70074626 0.70201891 0.70200937\n",
      " 0.70094466 0.70171712 0.7014522  0.69832968 0.69989652 0.69821406\n",
      " 0.69988685 0.69758713]\n",
      "[[1.11578147 0.81353015 1.00997583 1.00098387 1.10576107 1.04349862\n",
      "  1.16650422 1.0319817  1.14697126 1.06459533 0.98189442 1.06578502\n",
      "  0.981985   1.07827651 1.04022699 1.04430451 0.85129059 0.92053537\n",
      "  1.0600524  0.83660751]]\n",
      "{0: 2470, 1: 344}\n",
      "acc 0.8901918976545842\n",
      "(0.32558139534883723, 0.5925925925925926, 0.4202626641651032, None)\n",
      "\n",
      "3 loss 306881.7358747794\n",
      "[0.70416824 0.69970172 0.69985878 0.69986239 0.70250186 0.69752949\n",
      " 0.70549688 0.69926891 0.70061398 0.70078288 0.70273833 0.70244891\n",
      " 0.70131581 0.70202599 0.70179517 0.69763149 0.70034168 0.69788277\n",
      " 0.69964889 0.69732556]\n",
      "[[1.11520353 0.8133103  1.01011459 1.00110424 1.10555906 1.04421944\n",
      "  1.16560706 1.03223907 1.14718273 1.06455228 0.98134591 1.06551666\n",
      "  0.98185284 1.07817526 1.04003541 1.04499471 0.85061556 0.92073706\n",
      "  1.06019576 0.83667277]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.8905472636815921\n",
      "(0.3255131964809384, 0.5873015873015873, 0.41886792452830185, None)\n",
      "\n",
      "4 loss 306862.93268730154\n",
      "[0.70490803 0.70008244 0.69979807 0.69982423 0.7028555  0.69680813\n",
      " 0.70644592 0.69900993 0.70040382 0.70082252 0.70345493 0.70288595\n",
      " 0.70168675 0.70233357 0.70213602 0.69693321 0.70078375 0.69755014\n",
      " 0.69940972 0.69706293]\n",
      "[[1.11462826 0.81309196 1.01025344 1.00122489 1.10535818 1.04494041\n",
      "  1.16471099 1.03249616 1.14739379 1.06450783 0.98080014 1.06524988\n",
      "  0.98172062 1.07807406 1.03984494 1.04568506 0.84994256 0.92093953\n",
      "  1.06033953 0.83673855]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.8905472636815921\n",
      "(0.3255131964809384, 0.5873015873015873, 0.41886792452830185, None)\n",
      "\n",
      "[0.70490803 0.70008244 0.69979807 0.69982423 0.7028555  0.69680813\n",
      " 0.70644592 0.69900993 0.70040382 0.70082252 0.70345493 0.70288595\n",
      " 0.70168675 0.70233357 0.70213602 0.69693321 0.70078375 0.69755014\n",
      " 0.69940972 0.69706293]\n",
      "[[1.11462826 0.81309196 1.01025344 1.00122489 1.10535818 1.04494041\n",
      "  1.16471099 1.03249616 1.14739379 1.06450783 0.98080014 1.06524988\n",
      "  0.98172062 1.07807406 1.03984494 1.04568506 0.84994256 0.92093953\n",
      "  1.06033953 0.83673855]]\n",
      "{0: 2473, 1: 341}\n",
      "acc 0.8905472636815921\n",
      "acc 0.8905472636815921\n",
      "[[2395  230]\n",
      " [  78  111]]\n",
      "(0.3255131964809384, 0.5873015873015873, 0.41886792452830185, None)\n",
      "alpha-mean 0.8\n",
      "Tensor(\"unstack:1\", shape=(?, 20), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 20), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 20), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 20), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(20,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(20,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 307815.0377999555\n",
      "[0.80167306 0.79832024 0.79991254 0.79985193 0.80120918 0.79972719\n",
      " 0.80256402 0.80006093 0.80125139 0.80069675 0.80030709 0.80088257\n",
      " 0.79995765 0.80090911 0.80054531 0.79977795 0.79902152 0.7991108\n",
      " 0.80054094 0.79848578]\n",
      "[[1.11718978 0.81412149 1.00977697 1.00081565 1.10631474 1.04202674\n",
      "  1.16841866 1.03146377 1.14655374 1.06469528 0.98323973 1.06649325\n",
      "  0.98244979 1.07865203 1.04075518 1.04286477 0.85269284 0.92008617\n",
      "  1.05975174 0.83640978]]\n",
      "{0: 2464, 1: 350}\n",
      "acc 0.8887704335465529\n",
      "(0.32285714285714284, 0.5978835978835979, 0.41929499072356213, None)\n",
      "\n",
      "1 loss 307807.2649205786\n",
      "[0.80214939 0.79847945 0.79973003 0.79969794 0.80134914 0.79903948\n",
      " 0.80342825 0.79981031 0.80103946 0.80073997 0.80075631 0.80108105\n",
      " 0.80009131 0.80103181 0.80067701 0.79913204 0.79946897 0.79902205\n",
      " 0.8004854  0.79860728]\n",
      "[[1.11685999 0.8140489  1.00999334 1.00100619 1.10625737 1.04271653\n",
      "  1.16764421 1.0317193  1.14677289 1.0646746  0.98293429 1.06639233\n",
      "  0.98251777 1.07872264 1.04070368 1.04349499 0.85206166 0.92023782\n",
      "  1.05987886 0.83640668]]\n",
      "{0: 2464, 1: 350}\n",
      "acc 0.8887704335465529\n",
      "(0.32285714285714284, 0.5978835978835979, 0.41929499072356213, None)\n",
      "\n",
      "2 loss 307799.4681896273\n",
      "[0.80262353 0.79863777 0.79954735 0.79954372 0.80148845 0.79835137\n",
      " 0.80429119 0.79955992 0.80082784 0.8007841  0.80120337 0.80127857\n",
      " 0.80022515 0.80115458 0.80080806 0.79848557 0.7999137  0.7989329\n",
      " 0.8004296  0.79872887]\n",
      "[[1.11653182 0.81397672 1.01020975 1.00119681 1.10620024 1.04340679\n",
      "  1.1668712  1.03197475 1.1469919  1.06465354 0.98263038 1.06629188\n",
      "  0.98258577 1.07879335 1.04065241 1.04412584 0.85143131 0.92038968\n",
      "  1.0600061  0.83640357]]\n",
      "{0: 2464, 1: 350}\n",
      "acc 0.8887704335465529\n",
      "(0.32285714285714284, 0.5978835978835979, 0.41929499072356213, None)\n",
      "\n",
      "3 loss 307791.6466431162\n",
      "[0.80309546 0.79879519 0.7993645  0.79938927 0.80162711 0.79766287\n",
      " 0.80515283 0.79930976 0.80061652 0.80082913 0.80164828 0.80147514\n",
      " 0.80035917 0.80127742 0.80093847 0.79783853 0.80035572 0.79884334\n",
      " 0.80037354 0.79885055]\n",
      "[[1.11620527 0.81390495 1.01042618 1.0013875  1.10614333 1.04409752\n",
      "  1.16609965 1.03223014 1.14721077 1.06463209 0.98232801 1.06619191\n",
      "  0.98265379 1.07886416 1.04060135 1.04475731 0.85080179 0.92054174\n",
      "  1.06013346 0.83640045]]\n",
      "{0: 2464, 1: 350}\n",
      "acc 0.8887704335465529\n",
      "(0.32285714285714284, 0.5978835978835979, 0.41929499072356213, None)\n",
      "\n",
      "4 loss 307783.80008805916\n",
      "[0.8035652  0.79895174 0.79918149 0.79923459 0.80176511 0.79697397\n",
      " 0.80601315 0.79905981 0.80040551 0.80087507 0.80209105 0.80167076\n",
      " 0.80049337 0.80140034 0.80106825 0.79719094 0.80079504 0.79875339\n",
      " 0.80031723 0.7989723 ]\n",
      "[[1.11588033 0.8138336  1.01064266 1.00157826 1.10608665 1.04478872\n",
      "  1.16532959 1.03248546 1.14742951 1.06461026 0.98202715 1.0660924\n",
      "  0.98272184 1.07893507 1.0405505  1.0453894  0.85017312 0.92069401\n",
      "  1.06026095 0.83639732]]\n",
      "{0: 2464, 1: 350}\n",
      "acc 0.8887704335465529\n",
      "(0.32285714285714284, 0.5978835978835979, 0.41929499072356213, None)\n",
      "\n",
      "[0.8035652  0.79895174 0.79918149 0.79923459 0.80176511 0.79697397\n",
      " 0.80601315 0.79905981 0.80040551 0.80087507 0.80209105 0.80167076\n",
      " 0.80049337 0.80140034 0.80106825 0.79719094 0.80079504 0.79875339\n",
      " 0.80031723 0.7989723 ]\n",
      "[[1.11588033 0.8138336  1.01064266 1.00157826 1.10608665 1.04478872\n",
      "  1.16532959 1.03248546 1.14742951 1.06461026 0.98202715 1.0660924\n",
      "  0.98272184 1.07893507 1.0405505  1.0453894  0.85017312 0.92069401\n",
      "  1.06026095 0.83639732]]\n",
      "{0: 2464, 1: 350}\n",
      "acc 0.8887704335465529\n",
      "acc 0.8887704335465529\n",
      "[[2388  237]\n",
      " [  76  113]]\n",
      "(0.32285714285714284, 0.5978835978835979, 0.41929499072356213, None)\n",
      "alpha-mean 0.9\n",
      "Tensor(\"unstack:1\", shape=(?, 20), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 20), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 20), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 20), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(20,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(20,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 308498.75513996807\n",
      "[0.90137856 0.89817271 0.89984995 0.89978559 0.90106209 0.89979917\n",
      " 0.90233867 0.90005409 0.90123757 0.9006622  0.90002403 0.90071179\n",
      " 0.89972842 0.90068173 0.90040338 0.90142143 0.8991288  0.89908445\n",
      " 0.90049377 0.89833274]\n",
      "[[1.11741029 0.81421228 1.00981571 1.00085619 1.10640759 1.04195562\n",
      "  1.16867    1.03147059 1.14656636 1.06473188 0.98344728 1.06660153\n",
      "  0.98261769 1.07880266 1.04084426 1.04123749 0.85286    0.92016814\n",
      "  1.05983818 0.83644846]]\n",
      "{0: 2465, 1: 349}\n",
      "acc 0.8869936034115139\n",
      "(0.3151862464183381, 0.582010582010582, 0.40892193308550184, None)\n",
      "\n",
      "1 loss 308496.65513632074\n",
      "[0.90155285 0.89818158 0.89960558 0.89956616 0.90105408 0.89918378\n",
      " 0.90296555 0.89979672 0.90101187 0.90066915 0.90018377 0.90073595\n",
      " 0.8996335  0.90057806 0.90039232 0.90242041 0.89970355 0.89896971\n",
      " 0.90039127 0.89829516]\n",
      "[[1.11730351 0.81423211 1.01007043 1.00108676 1.10644365 1.04257391\n",
      "  1.16815581 1.03173274 1.14679793 1.06474905 0.98335116 1.06661096\n",
      "  0.98285228 1.07902252 1.0408824  1.04023898 0.85240044 0.92040119\n",
      "  1.06005127 0.83648806]]\n",
      "{0: 2465, 1: 349}\n",
      "acc 0.8869936034115139\n",
      "(0.3151862464183381, 0.582010582010582, 0.40892193308550184, None)\n",
      "\n",
      "2 loss 308494.5469097717\n",
      "[0.90172651 0.89819045 0.89936126 0.89934678 0.90104616 0.89856751\n",
      " 0.90359079 0.89953939 0.90078625 0.90067609 0.90034296 0.90076009\n",
      " 0.8995387  0.90047445 0.90038135 0.90341938 0.90027711 0.89885481\n",
      " 0.90028866 0.89825762]\n",
      "[[1.11719713 0.81425189 1.01032511 1.00131729 1.10647959 1.04319312\n",
      "  1.16764298 1.03199488 1.14702946 1.06476624 0.98325539 1.06662035\n",
      "  0.98308674 1.07924228 1.0409204  1.03924049 0.85194177 0.92063417\n",
      "  1.06026428 0.83652764]]\n",
      "{0: 2465, 1: 349}\n",
      "acc 0.8869936034115139\n",
      "(0.3151862464183381, 0.582010582010582, 0.40892193308550184, None)\n",
      "\n",
      "3 loss 308492.4300603962\n",
      "[0.90189955 0.89819931 0.89911699 0.89912743 0.90103832 0.89795036\n",
      " 0.9042144  0.8992821  0.90056071 0.90068302 0.9005016  0.90078421\n",
      " 0.89944401 0.90037092 0.90037046 0.90441834 0.90084947 0.89873976\n",
      " 0.90018595 0.89822011]\n",
      "[[1.11709116 0.81427164 1.01057976 1.0015478  1.1065154  1.04381323\n",
      "  1.16713151 1.032257   1.14726095 1.06478347 0.98315996 1.06662973\n",
      "  0.98332107 1.07946192 1.04095828 1.03824202 0.85148397 0.92086709\n",
      "  1.06047721 0.8365672 ]]\n",
      "{0: 2465, 1: 349}\n",
      "acc 0.8869936034115139\n",
      "(0.3151862464183381, 0.582010582010582, 0.40892193308550184, None)\n",
      "\n",
      "4 loss 308490.3045243897\n",
      "[0.90207196 0.89820816 0.89887277 0.89890813 0.90103056 0.89733236\n",
      " 0.90483638 0.89902486 0.90033525 0.90068994 0.9006597  0.9008083\n",
      " 0.89934944 0.90026746 0.90035966 0.90541729 0.90142063 0.89862455\n",
      " 0.90008312 0.89818264]\n",
      "[[1.11698559 0.81429134 1.01083437 1.00177827 1.10655108 1.04443424\n",
      "  1.1666214  1.03251912 1.14749239 1.06480074 0.98306489 1.06663907\n",
      "  0.98355528 1.07968145 1.04099603 1.03724356 0.85102704 0.92109994\n",
      "  1.06069006 0.83660676]]\n",
      "{0: 2465, 1: 349}\n",
      "acc 0.8869936034115139\n",
      "(0.3151862464183381, 0.582010582010582, 0.40892193308550184, None)\n",
      "\n",
      "[0.90207196 0.89820816 0.89887277 0.89890813 0.90103056 0.89733236\n",
      " 0.90483638 0.89902486 0.90033525 0.90068994 0.9006597  0.9008083\n",
      " 0.89934944 0.90026746 0.90035966 0.90541729 0.90142063 0.89862455\n",
      " 0.90008312 0.89818264]\n",
      "[[1.11698559 0.81429134 1.01083437 1.00177827 1.10655108 1.04443424\n",
      "  1.1666214  1.03251912 1.14749239 1.06480074 0.98306489 1.06663907\n",
      "  0.98355528 1.07968145 1.04099603 1.03724356 0.85102704 0.92109994\n",
      "  1.06069006 0.83660676]]\n",
      "{0: 2465, 1: 349}\n",
      "acc 0.8869936034115139\n",
      "acc 0.8869936034115139\n",
      "[[2386  239]\n",
      " [  79  110]]\n",
      "(0.3151862464183381, 0.582010582010582, 0.40892193308550184, None)\n",
      "alpha-mean 1.0\n",
      "Tensor(\"unstack:1\", shape=(?, 20), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 20), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 20), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 20), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(20,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(20,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(20,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "loss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 308807.12709821516\n",
      "[1.00221159 0.99905532 1.00080532 1.00000666 1.00210085 1.00143343\n",
      " 1.00272318 1.0013104  1.00249675 1.00168313 0.99996378 1.00170231\n",
      " 0.99996266 1.00182356 1.0014268  1.00144357 0.99940606 0.99984425\n",
      " 1.00163059 0.99925723]\n",
      "[[1.11757299 0.81428305 1.00983324 1.00087513 1.10646289 1.0419455\n",
      "  1.16922037 1.03148157 1.14658069 1.0647978  0.98359863 1.0666835\n",
      "  0.98265543 1.07883839 1.04089745 1.04225355 0.85335451 0.92020826\n",
      "  1.05987747 0.83649039]]\n",
      "{0: 2455, 1: 359}\n",
      "acc 0.8848614072494669\n",
      "(0.31197771587743733, 0.5925925925925926, 0.4087591240875913, None)\n",
      "\n",
      "1 loss 308807.12429145875\n",
      "[1.00324078 0.99976664 1.0018491  1.00000666 1.003131   1.00247055\n",
      " 1.00374855 1.00234891 1.00352377 1.00271741 0.99998288 1.00273632\n",
      " 0.99998256 1.00285634 1.00246385 1.00248051 0.9998967  0.99995588\n",
      " 1.00266545 0.99984776]\n",
      "[[1.11760074 0.81435166 1.01010515 1.00112429 1.10654809 1.04255247\n",
      "  1.16923658 1.03175448 1.14682625 1.06487547 0.98362616 1.06675217\n",
      "  0.98292734 1.07909359 1.0409826  1.0423756  0.85336782 0.92048116\n",
      "  1.06012946 0.83656798]]\n",
      "{0: 2455, 1: 359}\n",
      "acc 0.8848614072494669\n",
      "(0.31197771587743733, 0.5925925925925926, 0.4087591240875913, None)\n",
      "\n",
      "2 loss 308807.12108178803\n",
      "[1.0042627  0.9999488  1.00288059 1.00000589 1.00415348 1.00349702\n",
      " 1.00476823 1.0033762  1.00454446 1.00374225 0.99999046 1.00376098\n",
      " 0.99999033 1.00388032 1.00349024 1.00350688 0.99996777 0.99997204\n",
      " 1.00369063 0.99994781]\n",
      "[[1.11762885 0.81442027 1.01037708 1.00137344 1.10663341 1.04315953\n",
      "  1.1692565  1.03202741 1.14707187 1.06495331 0.98365369 1.06682095\n",
      "  0.98319925 1.07934884 1.04106782 1.04269928 0.85338113 0.92075406\n",
      "  1.06038148 0.83664556]]\n",
      "{0: 2455, 1: 359}\n",
      "acc 0.8848614072494669\n",
      "(0.31197771587743733, 0.5925925925925926, 0.4087591240875913, None)\n",
      "\n",
      "3 loss 308807.11728776066\n",
      "[1.00528025 0.9999786  1.00390395 1.00000437 1.00517138 1.00451745\n",
      " 1.0057843  1.00439712 1.00556123 1.00476166 0.99999473 1.00478026\n",
      " 0.99999467 1.00489918 1.00451058 1.00452726 0.9999849  0.99997584\n",
      " 1.00471025 0.99996404]\n",
      "[[1.11765756 0.81448887 1.01064905 1.0016226  1.10671894 1.04376668\n",
      "  1.16928238 1.0323004  1.1473176  1.06503147 0.98368122 1.06688994\n",
      "  0.98347116 1.07960417 1.04115317 1.04323714 0.85339443 0.92102697\n",
      "  1.06063357 0.83672315]]\n",
      "{0: 2455, 1: 359}\n",
      "acc 0.8848614072494669\n",
      "(0.31197771587743733, 0.5925925925925926, 0.4087591240875913, None)\n",
      "\n",
      "4 loss 308807.112735164\n",
      "[1.00629488 0.99998974 1.00492245 1.0000026  1.00618626 1.00553408\n",
      " 1.00679789 1.00541405 1.00657533 1.00577758 0.99999735 1.00579607\n",
      " 0.99999732 1.00591471 1.00552712 1.00554386 0.99999256 0.99997483\n",
      " 1.00572632 0.999967  ]\n",
      "[[1.11768722 0.81455747 1.01092109 1.00187176 1.10680481 1.04437395\n",
      "  1.169317   1.03257348 1.14756348 1.06511013 0.98370875 1.06695926\n",
      "  0.98374307 1.07985962 1.04123877 1.04393806 0.85340773 0.92129988\n",
      "  1.06088576 0.83680073]]\n",
      "{0: 2455, 1: 359}\n",
      "acc 0.8848614072494669\n",
      "(0.31197771587743733, 0.5925925925925926, 0.4087591240875913, None)\n",
      "\n",
      "[1.00629488 0.99998974 1.00492245 1.0000026  1.00618626 1.00553408\n",
      " 1.00679789 1.00541405 1.00657533 1.00577758 0.99999735 1.00579607\n",
      " 0.99999732 1.00591471 1.00552712 1.00554386 0.99999256 0.99997483\n",
      " 1.00572632 0.999967  ]\n",
      "[[1.11768722 0.81455747 1.01092109 1.00187176 1.10680481 1.04437395\n",
      "  1.169317   1.03257348 1.14756348 1.06511013 0.98370875 1.06695926\n",
      "  0.98374307 1.07985962 1.04123877 1.04393806 0.85340773 0.92129988\n",
      "  1.06088576 0.83680073]]\n",
      "{0: 2455, 1: 359}\n",
      "acc 0.8848614072494669\n",
      "acc 0.8848614072494669\n",
      "[[2378  247]\n",
      " [  77  112]]\n",
      "(0.31197771587743733, 0.5925925925925926, 0.4087591240875913, None)\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print(\"alpha-mean\",i)\n",
    "    R=train(0.001/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                                af = tf.truncated_normal_initializer(i,0.001,seed),\n",
    "                              pcl=np.array([-1,1],dtype=np.float64),norm=True,smooth=True,penalty=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss 154419.85892351693\n",
      "[0.70199849 0.69863948 0.70064995 0.70050634 0.70158368 0.69974811\n",
      " 0.7024189  0.69989863 0.70116149 0.70031883]\n",
      "[[1.11684702 0.81388424 1.00909607 1.00020123 1.10603129 1.04198871\n",
      "  1.16832551 1.03148074 1.14652466 1.06476878]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "1 loss 154412.0944320077\n",
      "[0.70281514 0.69912683 0.7012039  0.70100454 0.70210083 0.69908183\n",
      " 0.70313802 0.69948195 0.70085416 0.69998278]\n",
      "[[1.11616031 0.81356764 1.00863199 0.99977896 1.10568849 1.04264002\n",
      "  1.1674484  1.03175502 1.14671642 1.0648187 ]]\n",
      "{0: 2557, 1: 257}\n",
      "acc 0.9090262970859986\n",
      "(0.36964980544747084, 0.5026455026455027, 0.4260089686098655, None)\n",
      "\n",
      "2 loss 154404.293113523\n",
      "[0.7036304  0.69961253 0.70175796 0.70150177 0.70261692 0.69841554\n",
      " 0.70385303 0.69906154 0.70054362 0.69964356]\n",
      "[[1.11547508 0.81325195 1.00816643 0.99935532 1.10534605 1.04329152\n",
      "  1.1665718  1.03203151 1.14691    1.0648712 ]]\n",
      "{0: 2562, 1: 252}\n",
      "acc 0.9108031272210376\n",
      "(0.376984126984127, 0.5026455026455027, 0.4308390022675737, None)\n",
      "\n",
      "3 loss 154396.45568353802\n",
      "[0.70444425 0.70009655 0.70231192 0.70199854 0.70313194 0.69774924\n",
      " 0.70457133 0.69863844 0.70023073 0.69929905]\n",
      "[[1.11479133 0.81293715 1.00769945 0.99893033 1.10500399 1.0439432\n",
      "  1.16569574 1.0323102  1.14710539 1.06492631]]\n",
      "{0: 2564, 1: 250}\n",
      "acc 0.9115138592750534\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n",
      "\n",
      "4 loss 154388.58431126399\n",
      "[0.70525669 0.7005789  0.70286542 0.70249399 0.70364588 0.69708293\n",
      " 0.70528778 0.69821268 0.69991554 0.69895001]\n",
      "[[1.11410906 0.81262325 1.00723105 0.99850403 1.10466231 1.04459504\n",
      "  1.16482024 1.03259108 1.14730257 1.06498403]]\n",
      "{0: 2566, 1: 248}\n",
      "acc 0.912224591329069\n",
      "(0.38306451612903225, 0.5026455026455027, 0.43478260869565216, None)\n",
      "\n",
      "[0.70525669 0.7005789  0.70286542 0.70249399 0.70364588 0.69708293\n",
      " 0.70528778 0.69821268 0.69991554 0.69895001]\n",
      "[[1.11410906 0.81262325 1.00723105 0.99850403 1.10466231 1.04459504\n",
      "  1.16482024 1.03259108 1.14730257 1.06498403]]\n",
      "{0: 2566, 1: 248}\n",
      "acc 0.912224591329069\n",
      "acc 0.912224591329069\n",
      "[[2472  153]\n",
      " [  94   95]]\n",
      "(0.38306451612903225, 0.5026455026455027, 0.43478260869565216, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(0.001/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            af = tf.truncated_normal_initializer(0.7,0.001,seed),\n",
    "                          pcl=np.array([-1,1],dtype=np.float64),smooth=True,penalty=0,alp=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "ky Tensor(\"zy/while/Select:0\", shape=(10,), dtype=float64)\n",
      "intsy Tensor(\"zy/while/add:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"zy/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "unnormlized loss\n",
      "Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "0 loss -15939.431711918833\n",
      "[0.70114658 0.6980671  0.7005352  0.70036628 0.70097048 0.69970941\n",
      " 0.70172842 0.69983442 0.70106882 0.70023938]\n",
      "[[1.1175735  0.81428958 1.00926217 1.00040094 1.10647117 1.04204262\n",
      "  1.16921675 1.03155796 1.14662476 1.06497891]]\n",
      "{0: 2551, 1: 263}\n",
      "acc 0.9076048329779673\n",
      "(0.3650190114068441, 0.5079365079365079, 0.4247787610619469, None)\n",
      "\n",
      "1 loss -15945.54796805883\n",
      "[0.70111772 0.69799241 0.7009752  0.70072644 0.70087748 0.69900428\n",
      " 0.70176563 0.69935282 0.70067024 0.69982519]\n",
      "[[1.11760236 0.81436427 1.00896215 1.0001753  1.10656417 1.04274786\n",
      "  1.16922713 1.03190938 1.14691616 1.06524055]]\n",
      "{0: 2556, 1: 258}\n",
      "acc 0.9086709310589908\n",
      "(0.3682170542635659, 0.5026455026455027, 0.4250559284116331, None)\n",
      "\n",
      "2 loss -15951.757772791369\n",
      "[0.70108887 0.69791784 0.70141635 0.7010881  0.70078491 0.69829879\n",
      " 0.7018038  0.69886784 0.70026877 0.69940672]\n",
      "[[1.1176312  0.81443884 1.0086587  0.9999462  1.10665674 1.04345345\n",
      "  1.16923675 1.03226318 1.14720957 1.06550534]]\n",
      "{0: 2561, 1: 253}\n",
      "acc 0.9104477611940298\n",
      "(0.37549407114624506, 0.5026455026455027, 0.4298642533936652, None)\n",
      "\n",
      "3 loss -15958.059847491313\n",
      "[0.70106004 0.69784341 0.70185925 0.70145038 0.70069277 0.69759296\n",
      " 0.70184291 0.69838007 0.69986473 0.69898245]\n",
      "[[1.11766004 0.81451327 1.00835185 0.99971367 1.10674889 1.04415938\n",
      "  1.16924559 1.03261936 1.14750498 1.06577329]]\n",
      "{0: 2564, 1: 250}\n",
      "acc 0.9115138592750534\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n",
      "\n",
      "4 loss -15964.453597918462\n",
      "[0.70103121 0.69776911 0.70230358 0.70181466 0.70060106 0.69688679\n",
      " 0.70188297 0.69788888 0.69945783 0.6985552 ]\n",
      "[[1.11768886 0.81458757 1.00804164 0.99947771 1.1068406  1.04486566\n",
      "  1.16925366 1.03297791 1.14780238 1.06604442]]\n",
      "{0: 2564, 1: 250}\n",
      "acc 0.9115138592750534\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n",
      "\n",
      "[0.70103121 0.69776911 0.70230358 0.70181466 0.70060106 0.69688679\n",
      " 0.70188297 0.69788888 0.69945783 0.6985552 ]\n",
      "[[1.11768886 0.81458757 1.00804164 0.99947771 1.1068406  1.04486566\n",
      "  1.16925366 1.03297791 1.14780238 1.06604442]]\n",
      "{0: 2564, 1: 250}\n",
      "acc 0.9115138592750534\n",
      "acc 0.9115138592750534\n",
      "[[2470  155]\n",
      " [  94   95]]\n",
      "(0.38, 0.5026455026455027, 0.4328018223234624, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(0.001/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            af = tf.truncated_normal_initializer(0.7,0.001,seed),\n",
    "                          pcl=np.array([-1,1],dtype=np.float64),norm=False,\\\n",
    "                          smooth=True,penalty=2,alp=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"unstack:1\", shape=(?, 20), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 20), dtype=float64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 20 and 10 for 'Sub' (op: 'Sub') with input shapes: [?,20], [10].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 20 and 10 for 'Sub' (op: 'Sub') with input shapes: [?,20], [10].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-dcce0456e436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train(0.001/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),                            af = tf.truncated_normal_initializer(0.7,0.001,seed),\n\u001b[1;32m      2\u001b[0m                           \u001b[0mpcl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                           smooth=True,penalty=0,alp=2)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-159-d16530ac715f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(lr, ep, th, af, pcl, norm, smooth, penalty, p3k, alp)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#         print(s.graph)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0ms_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s_\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36msubtract\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"subtract\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   7931\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7932\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 7933\u001b[0;31m         \"Sub\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   7934\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7935\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3290\u001b[0m           op_def=op_def)\n\u001b[1;32m   3291\u001b[0m       self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[0;32m-> 3292\u001b[0;31m                              compute_device=compute_device)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3330\u001b[0m     \u001b[0;31m# compute_shapes argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3332\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3333\u001b[0m     \u001b[0;31m# TODO(b/XXXX): move to Operation.__init__ once _USE_C_API flag is removed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3334\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs_c_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_set_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2467\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2469\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2470\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2399\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/snorkelEnv/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 20 and 10 for 'Sub' (op: 'Sub') with input shapes: [?,20], [10]."
     ]
    }
   ],
   "source": [
    "train(0.001/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            af = tf.truncated_normal_initializer(0.7,0.001,seed),\n",
    "                          pcl=np.array([-1,1],dtype=np.float64),norm=False,\\\n",
    "                          smooth=True,penalty=0,alp=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
