{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8272 888\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "# TO USE A DATABASE OTHER THAN SQLITE, USE THIS LINE\n",
    "# Note that this is necessary for parallel execution amongst other things...\n",
    "# os.environ['SNORKELDB'] = 'postgres:///snorkel-intro'\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "\n",
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])\n",
    "\n",
    "train_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 0).all()\n",
    "dev_cands = session.query(ChemicalDisease).filter(ChemicalDisease.split == 1).all()\n",
    "print(len(train_cands),len(dev_cands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vinay/snorkelEnv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "296 592\n",
      "888\n"
     ]
    }
   ],
   "source": [
    "# from util import load_external_labels\n",
    "\n",
    "# %time load_external_labels(session, Spouse, annotator_name='gold')\n",
    "\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "#L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, zero_one=True)\n",
    "#L_gold_test = load_gold_labels(session, annotator_name='gold', split=2, zero_one=True)\n",
    "\n",
    "# L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "# L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, zero_one=True)\n",
    "# gold_labels_dev = [L[0,0] if L[0,0]==1 else -1 for L in L_gold_dev]\n",
    "gold_labels_dev = [L[0,0] for L in L_gold_dev]\n",
    "\n",
    "\n",
    "from snorkel.learning.utils import MentionScorer\n",
    "\n",
    "print(gold_labels_dev.count(1),gold_labels_dev.count(0))\n",
    "print(len(gold_labels_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import gensim.matutils as gm\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# Load pretrained model (since intermediate data is not included, the model cannot be refined with additional data)\n",
    "model = KeyedVectors.load_word2vec_format('../../../snorkel/tutorials/glove_w2v.txt', binary=False)  # C binary format\n",
    "\n",
    "\n",
    "wordvec_unavailable= set()\n",
    "def write_to_file(wordvec_unavailable):\n",
    "    with open(\"wordvec_unavailable.txt\",\"w\") as f:\n",
    "        for word in wordvec_unavailable:\n",
    "            f.write(word+\"\\n\")\n",
    "\n",
    "def preprocess(tokens):\n",
    "    btw_words = [word for word in tokens if word not in STOPWORDS]\n",
    "    btw_words = [word for word in btw_words if word.isalpha()]\n",
    "    return btw_words\n",
    "\n",
    "def get_word_vectors(btw_words): # returns vector of embeddings of words\n",
    "    word_vectors= []\n",
    "    for word in btw_words:\n",
    "        try:\n",
    "            word_v = np.array(model[word])\n",
    "            word_v = word_v.reshape(len(word_v),1)\n",
    "            #print(word_v.shape)\n",
    "            word_vectors.append(model[word])\n",
    "        except:\n",
    "            wordvec_unavailable.add(word)\n",
    "    return word_vectors\n",
    "\n",
    "def get_similarity(word_vectors,target_word): # sent(list of word vecs) to word similarity\n",
    "    similarity = 0\n",
    "    target_word_vector = 0\n",
    "    try:\n",
    "        target_word_vector = model[target_word]\n",
    "    except:\n",
    "        wordvec_unavailable.add(target_word+\" t\")\n",
    "        return similarity\n",
    "    target_word_sparse = gm.any2sparse(target_word_vector,eps=1e-09)\n",
    "    for wv in word_vectors:\n",
    "        wv_sparse = gm.any2sparse(wv, eps=1e-09)\n",
    "        similarity = max(similarity,gm.cossim(wv_sparse,target_word_sparse))\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "from six.moves.cPickle import load\n",
    "\n",
    "with bz2.BZ2File('data/ctd.pkl.bz2', 'rb') as ctd_f:\n",
    "    ctd_unspecified, ctd_therapy, ctd_marker = load(ctd_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Discrete #########\n",
    "\n",
    "def cand_in_ctd_unspecified(c):\n",
    "    return 1 if c.get_cids() in ctd_unspecified else 0\n",
    "\n",
    "def cand_in_ctd_therapy(c):\n",
    "    return 1 if c.get_cids() in ctd_therapy else 0\n",
    "\n",
    "def cand_in_ctd_marker(c):\n",
    "    return 1 if c.get_cids() in ctd_marker else 0\n",
    "\n",
    "\n",
    "def LF_in_ctd_unspecified(c):\n",
    "    if(cand_in_ctd_unspecified(c)==1):\n",
    "        return (-1,1)\n",
    "    else:\n",
    "        return (0,0)\n",
    "\n",
    "def LF_in_ctd_therapy(c):\n",
    "    if(cand_in_ctd_therapy(c)==1):\n",
    "        return (-1,1)\n",
    "    else:\n",
    "        return (0,0)\n",
    "\n",
    "def LF_in_ctd_marker(c):\n",
    "    if(cand_in_ctd_marker(c)==1):\n",
    "        return (1,1)\n",
    "    else:\n",
    "        return (0,0)\n",
    "\n",
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B,\n",
    ")\n",
    "\n",
    "# List to parenthetical\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "def LF_induce(c):\n",
    "    return (1,1) if re.search(r'{{A}}.{0,20}induc.{0,20}{{B}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "causal_past = ['induced', 'caused', 'due']\n",
    "def LF_d_induced_by_c(c):\n",
    "    if (rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + '.{0,9}(by|to).{0,50}', 1)==1):\n",
    "        return (1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_d_induced_by_c_tight(c):\n",
    "    if (rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + ' (by|to) ', 1)==1):\n",
    "        return (1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_induce_name(c):\n",
    "    return (1,1) if 'induc' in c.chemical.get_span().lower() else (0,0)     \n",
    "\n",
    "causal = ['cause[sd]?', 'induce[sd]?', 'associated with']\n",
    "def LF_c_cause_d(c):\n",
    "    return (1,1) if (\n",
    "        re.search(r'{{A}}.{0,50} ' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search('{{A}}.{0,50}(not|no).{0,20}' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "    ) else (0,0)\n",
    "\n",
    "treat = ['treat', 'effective', 'prevent', 'resistant', 'slow', 'promise', 'therap']\n",
    "def LF_d_treat_c(c):\n",
    "    if (rule_regex_search_btw_BA(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)==-1):\n",
    "        return (-1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_c_treat_d(c):\n",
    "    if (rule_regex_search_btw_AB(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)==-1):\n",
    "        return (-1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_treat_d(c):\n",
    "    if (rule_regex_search_before_B(c, ltp(treat) + '.{0,50}', -1)==-1):\n",
    "        return (-1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_c_treat_d_wide(c):\n",
    "    if (rule_regex_search_btw_AB(c, '.{0,200}' + ltp(treat) + '.{0,200}', -1)==-1):\n",
    "        return (-1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_c_d(c):\n",
    "    return (1,1) if ('{{A}} {{B}}' in get_tagged_text(c)) else (0,0)\n",
    "\n",
    "def LF_c_induced_d(c):\n",
    "    return (1,1) if (\n",
    "        ('{{A}} {{B}}' in get_tagged_text(c)) and \n",
    "        (('-induc' in c[0].get_span().lower()) or ('-assoc' in c[0].get_span().lower()))\n",
    "        ) else (0,0)\n",
    "\n",
    "def LF_improve_before_disease(c):\n",
    "    if(rule_regex_search_before_B(c, 'improv.*', -1)==-1):\n",
    "        return (-1,1)\n",
    "    return (0,0)\n",
    "\n",
    "pat_terms = ['in a patient with ', 'in patients with']\n",
    "def LF_in_patient_with(c):\n",
    "    return (-1,1) if re.search(ltp(pat_terms) + '{{B}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "uncertain = ['combin', 'possible', 'unlikely']\n",
    "def LF_uncertain(c):\n",
    "    if (rule_regex_search_before_A(c, ltp(uncertain) + '.*', -1)==-1):\n",
    "        return (-1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_induced_other(c):\n",
    "    if (rule_regex_search_tagged_text(c, '{{A}}.{20,1000}-induced {{B}}', -1)==-1):\n",
    "        return (-1,1)\n",
    "    return (0,0)  \n",
    "\n",
    "def LF_far_c_d(c):\n",
    "    if (rule_regex_search_btw_AB(c, '.{100,5000}', -1)==-1):\n",
    "        return (-1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_far_d_c(c):\n",
    "    if (rule_regex_search_btw_BA(c, '.{100,5000}', -1)==-1):\n",
    "        return (-1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_risk_d(c):\n",
    "    if (rule_regex_search_before_B(c, 'risk of ', 1)==1):\n",
    "        return (1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_develop_d_following_c(c):\n",
    "    return (1,1) if re.search(r'develop.{0,25}{{B}}.{0,25}following.{0,25}{{A}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "procedure, following = ['inject', 'administrat'], ['following']\n",
    "def LF_d_following_c(c):\n",
    "    return (1,1) if re.search('{{B}}.{0,50}' + ltp(following) + '.{0,20}{{A}}.{0,50}' + ltp(procedure), get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "def LF_measure(c):\n",
    "    return (-1,1) if re.search('measur.{0,75}{{A}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "def LF_level(c):\n",
    "    return (-1,1) if re.search('{{A}}.{0,25} level', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "def LF_neg_d(c):\n",
    "    return (-1,1) if re.search('(none|not|no) .{0,25}{{B}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "WEAK_PHRASES = ['none', 'although', 'was carried out', 'was conducted',\n",
    "                'seems', 'suggests', 'risk', 'implicated',\n",
    "               'the aim', 'to (investigate|assess|study)']\n",
    "\n",
    "WEAK_RGX = r'|'.join(WEAK_PHRASES)\n",
    "\n",
    "def LF_weak_assertions(c):\n",
    "    return (-1,1) if re.search(WEAK_RGX, get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "\n",
    "def LF_ctd_marker_c_d(c):\n",
    "    l,s = LF_c_d(c)\n",
    "    cl = cand_in_ctd_marker(c)\n",
    "    return (l*cl,s*cl)\n",
    "\n",
    "def LF_ctd_marker_induce(c):\n",
    "    l1,s1 = LF_c_induced_d(c)\n",
    "    l2,s2 = LF_d_induced_by_c_tight(c)\n",
    "    cl = cand_in_ctd_marker(c)\n",
    "    return ((l1 or l2)*cl,max(s1,s2)*cl)\n",
    "\n",
    "def LF_ctd_therapy_treat(c):\n",
    "    l,s = LF_c_treat_d_wide(c)\n",
    "    cl = cand_in_ctd_therapy(c)\n",
    "    return (l*cl,s*cl)\n",
    "\n",
    "def LF_ctd_unspecified_treat(c):\n",
    "    l,s = LF_c_treat_d_wide(c)\n",
    "    cl = cand_in_ctd_unspecified(c)\n",
    "    return (l*cl,s*cl)\n",
    "\n",
    "def LF_ctd_unspecified_induce(c):\n",
    "    l1,s1 = LF_c_induced_d(c)\n",
    "    l2,s2 = LF_d_induced_by_c_tight(c)\n",
    "    cl = cand_in_ctd_unspecified(c)\n",
    "    return ((l1 or l2)*cl,max(s1,s2)*cl)\n",
    "\n",
    "\n",
    "# def LF_ctd_marker_c_d(c):\n",
    "#     return LF_c_d(c) * cand_in_ctd_marker(c)\n",
    "\n",
    "# def LF_ctd_marker_induce(c):\n",
    "#     return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_marker(c)\n",
    "\n",
    "# def LF_ctd_therapy_treat(c):\n",
    "#     return LF_c_treat_d_wide(c) * cand_in_ctd_therapy(c)\n",
    "\n",
    "# def LF_ctd_unspecified_treat(c):\n",
    "#     return LF_c_treat_d_wide(c) * cand_in_ctd_unspecified(c)\n",
    "\n",
    "# def LF_ctd_unspecified_induce(c):\n",
    "#     return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_unspecified(c)\n",
    "\n",
    "def LF_closer_chem(c):\n",
    "    # Get distance between chemical and disease\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    # Try to find chemical closer than @dist/2 in either direction\n",
    "    sent = c.get_parent()\n",
    "    closest_other_chem = float('inf')\n",
    "    for i in range(dis_end, min(len(sent.words), dis_end + dist // 2)):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "            return (-1,1)\n",
    "    for i in range(max(0, dis_start - dist // 2), dis_start):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "            return (-1,1)\n",
    "    return (0,0)\n",
    "\n",
    "def LF_closer_dis(c):\n",
    "    # Get distance between chemical and disease\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    # Try to find chemical disease than @dist/8 in either direction\n",
    "    sent = c.get_parent()\n",
    "    for i in range(chem_end, min(len(sent.words), chem_end + dist // 8)):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "            return (-1,1)\n",
    "    for i in range(max(0, chem_start - dist // 8), chem_start):\n",
    "        et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "        if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "            return (-1,1)\n",
    "    return (0,0)\n",
    "\n",
    "\n",
    "LFs = [LF_c_cause_d,LF_c_d,LF_c_induced_d,LF_c_treat_d,LF_c_treat_d_wide,LF_closer_chem,\n",
    "    LF_closer_dis,LF_ctd_marker_c_d,LF_ctd_marker_induce,LF_ctd_therapy_treat,\n",
    "    LF_ctd_unspecified_treat,LF_ctd_unspecified_induce,LF_d_following_c,\n",
    "    LF_d_induced_by_c,LF_d_induced_by_c_tight,LF_d_treat_c,LF_develop_d_following_c,\n",
    "    LF_far_c_d,LF_far_d_c,LF_improve_before_disease,LF_in_ctd_therapy,\n",
    "    LF_in_ctd_marker,LF_in_patient_with,LF_induce,LF_induce_name,LF_induced_other,\n",
    "    LF_level,LF_measure,LF_neg_d,LF_risk_d,LF_treat_d,LF_uncertain,LF_weak_assertions\n",
    "]\n",
    "\n",
    "LF_l = [\n",
    "    1,1,1,-1,-1,-1,\n",
    "    -1,1,1,-1,\n",
    "    -1,1,1,\n",
    "    1,1,-1,1,\n",
    "    -1,-1,-1,-1,\n",
    "    1,-1,1,1,-1,\n",
    "    -1,-1,-1,1,-1,-1,-1\n",
    "]\n",
    "print(len(LFs),len(LF_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def distanceCD(c):\n",
    "    dist = 0\n",
    "    chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "    dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "    if dis_start < chem_start:\n",
    "        dist = chem_start - dis_end\n",
    "    else:\n",
    "        dist = dis_start - chem_end\n",
    "    return dist/5000\n",
    "\n",
    "\n",
    "def distanceCD_(c,l):\n",
    "    dist = []\n",
    "    for w in l:\n",
    "        pattern = r'({{A}})(.*)('+w+r')(.*)({{B}})'\n",
    "        matchObj = re.search(pattern, get_tagged_text(c), flags=re.I)\n",
    "        if(matchObj):\n",
    "            match_groups = matchObj.group(2,4)\n",
    "            dist.append(sum([len(mg) for mg in match_groups]))\n",
    "    if(len(dist)>0):\n",
    "        return min(dist)\n",
    "    return 0\n",
    "\n",
    "def distanceDC_(c,l):\n",
    "    dist = []\n",
    "    for w in l:\n",
    "        pattern = r'({{B}})(.*)('+w+r')(.*)({{A}})'\n",
    "        matchObj = re.search(pattern, get_tagged_text(c), flags=re.I)\n",
    "        if(matchObj):\n",
    "            match_groups = matchObj.group(2,4)\n",
    "            dist.append(sum([len(mg) for mg in match_groups]))\n",
    "    if(len(dist)>0):\n",
    "        return min(dist)\n",
    "    return 0\n",
    "\n",
    "   \n",
    "\n",
    "def levenshtein(source, target):\n",
    "    if len(source) < len(target):\n",
    "        return levenshtein(target, source)\n",
    "\n",
    "    # So now we have len(source) >= len(target).\n",
    "    if len(target) == 0:\n",
    "        return len(source)\n",
    "\n",
    "    # We call tuple() to force strings to be used as sequences\n",
    "    # ('c', 'a', 't', 's') - numpy uses them as values by default.\n",
    "    source = np.array(tuple(source))\n",
    "    target = np.array(tuple(target))\n",
    "\n",
    "    # We use a dynamic programming algorithm, but with the\n",
    "    # added optimization that we only need the last two rows\n",
    "    # of the matrix.\n",
    "    previous_row = np.arange(target.size + 1)\n",
    "    for s in source:\n",
    "        # Insertion (target grows longer than source):\n",
    "        current_row = previous_row + 1\n",
    "\n",
    "        # Substitution or matching:\n",
    "        # Target and source items are aligned, and either\n",
    "        # are different (cost of 1), or are the same (cost of 0).\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                np.add(previous_row[:-1], target != s))\n",
    "\n",
    "        # Deletion (target grows shorter than source):\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                current_row[0:-1] + 1)\n",
    "\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### Smooth LFs #########\n",
    "\n",
    "# def cand_in_ctd_unspecified(c):\n",
    "#     return 1 if c.get_cids() in ctd_unspecified else 0\n",
    "\n",
    "# def cand_in_ctd_therapy(c):\n",
    "#     return 1 if c.get_cids() in ctd_therapy else 0\n",
    "\n",
    "# def cand_in_ctd_marker(c):\n",
    "#     return 1 if c.get_cids() in ctd_marker else 0\n",
    "\n",
    "\n",
    "# def LF_in_ctd_unspecified(c):\n",
    "#     if(cand_in_ctd_unspecified(c)==1):\n",
    "#         return (-1,1)\n",
    "#     else:\n",
    "#         return (0,0)\n",
    "\n",
    "# def LF_in_ctd_therapy(c):\n",
    "#     if(cand_in_ctd_therapy(c)==1):\n",
    "#         return (-1,1)\n",
    "#     else:\n",
    "#         return (0,0)\n",
    "\n",
    "# def LF_in_ctd_marker(c):\n",
    "#     if(cand_in_ctd_marker(c)==1):\n",
    "#         return (1,1)\n",
    "#     else:\n",
    "#         return (0,0)\n",
    "\n",
    "# import re\n",
    "# from snorkel.lf_helpers import (\n",
    "#     get_tagged_text,\n",
    "#     rule_regex_search_tagged_text,\n",
    "#     rule_regex_search_btw_AB,\n",
    "#     rule_regex_search_btw_BA,\n",
    "#     rule_regex_search_before_A,\n",
    "#     rule_regex_search_before_B,\n",
    "# )\n",
    "\n",
    "# import re\n",
    "# from snorkel.lf_helpers import (\n",
    "#     get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "#     get_text_between, get_tagged_text,\n",
    "# )\n",
    "\n",
    "# # List to parenthetical\n",
    "# def ltp(x):\n",
    "#     return '(' + '|'.join(x) + ')'\n",
    "\n",
    "# # def LF_induce(c):\n",
    "# #     return (1,1) if re.search(r'{{A}}.{0,20}induc.{0,20}{{B}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "# def LF_induce(c):\n",
    "#     return (1,distanceCD_(c,['induc'])) if re.search(r'{{A}}.*induc.*{{B}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "# causal_past = ['induced', 'caused', 'due']\n",
    "# # def LF_d_induced_by_c(c):\n",
    "# #     if (rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + '.{0,9}(by|to).{0,50}', 1)==1):\n",
    "# #         return (1,1)\n",
    "# #     return (0,0)\n",
    "\n",
    "# def LF_d_induced_by_c(c):\n",
    "#     sc = 0\n",
    "#     word_vectors = get_word_vectors(get_between_tokens(c))\n",
    "#     for w in causal_past:\n",
    "#         sc=max(sc,get_similarity(word_vectors,w))\n",
    "#     return (1,sc)\n",
    "\n",
    "# # def LF_d_induced_by_c_tight(c):\n",
    "# #     if (rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + ' (by|to) ', 1)==1):\n",
    "# #         return (1,1)\n",
    "# #     return (0,0)\n",
    "\n",
    "# def LF_d_induced_by_c_tight(c):\n",
    "#     if (rule_regex_search_btw_BA(c, '.*' + ltp(causal_past) + ' (by|to) ', 1)==1):\n",
    "#         return (1,(1-distanceDC_(c,causal_past)))\n",
    "#     return (0,0)\n",
    "\n",
    "# def LF_induce_name(c):\n",
    "#     return (1,1) if 'induc' in c.chemical.get_span().lower() else (0,0)     \n",
    "\n",
    "# causal = ['cause[sd]?', 'induce[sd]?', 'associated with']\n",
    "# # def LF_c_cause_d(c):\n",
    "# #     return (1,1) if (\n",
    "# #         re.search(r'{{A}}.{0,50} ' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "# #         and not re.search('{{A}}.{0,50}(not|no).{0,20}' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "# #     ) else (0,0)\n",
    "\n",
    "\n",
    "# def LF_c_cause_d(c):\n",
    "#     return (1,(1-distanceCD_(c,causal))) if (\n",
    "#         re.search(r'{{A}}.* ' + ltp(causal) + '.*{{B}}', get_tagged_text(c), re.I)\n",
    "#         and not re.search('{{A}}.{0,50}(not|no).{0,20}' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "#     ) else (0,0)\n",
    "\n",
    "\n",
    "# treat = ['treat', 'effective', 'prevent', 'resistant', 'slow', 'promise', 'therap']\n",
    "# # def LF_d_treat_c(c):\n",
    "# #     if (rule_regex_search_btw_BA(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)==-1):\n",
    "# #         return (-1,1)\n",
    "# #     return (0,0)\n",
    "\n",
    "# def LF_d_treat_c(c):\n",
    "#     if (rule_regex_search_btw_BA(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)==-1):\n",
    "#         return (-1,1-distanceDC_(c,treat))\n",
    "#     return (0,0)\n",
    "\n",
    "\n",
    "# # def LF_c_treat_d(c):\n",
    "# #     if (rule_regex_search_btw_AB(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)==-1):\n",
    "# #         return (-1,1)\n",
    "# #     return (0,0)\n",
    "\n",
    "# def LF_c_treat_d(c):\n",
    "#     if (rule_regex_search_btw_AB(c, '.{0,50}' + ltp(treat) + '.{0,50}', -1)==-1):\n",
    "#         return (-1,1-distanceCD_(c,treat))\n",
    "#     return (0,0)\n",
    "\n",
    "# # def LF_treat_d(c):\n",
    "# #     if (rule_regex_search_before_B(c, ltp(treat) + '.{0,50}', -1)==-1):\n",
    "# #         return (-1,1)\n",
    "# #     return (0,0)\n",
    "\n",
    "# def LF_treat_d(c):\n",
    "#     sc = 0\n",
    "#     word_vectors = get_word_vectors(get_left_tokens(c[1],7))\n",
    "#     for w in treat:\n",
    "#         sc=max(sc,get_similarity(word_vectors,w))\n",
    "#     if(re.search('(not|no|none) .* {{B}}', get_tagged_text(c), re.I)):\n",
    "#         return (0,0)\n",
    "#     else:\n",
    "#         return (-1,sc)\n",
    "\n",
    "# # def LF_c_treat_d_wide(c):\n",
    "# #     if (rule_regex_search_btw_AB(c, '.{0,200}' + ltp(treat) + '.{0,200}', -1)==-1):\n",
    "# #         return (-1,1)\n",
    "# #     return (0,0)\n",
    "\n",
    "# def LF_c_treat_d_wide(c):\n",
    "#     if (rule_regex_search_btw_AB(c, '.{0,200}' + ltp(treat) + '.{0,200}', -1)==-1):\n",
    "#         return (-1,1-distanceCD_(c,treat))\n",
    "#     return (0,0)\n",
    "\n",
    "# def LF_c_d(c):\n",
    "#     return (1,1) if ('{{A}} {{B}}' in get_tagged_text(c)) else (0,0)\n",
    "\n",
    "# def LF_c_induced_d(c):\n",
    "#     return (1,1) if (\n",
    "#         ('{{A}} {{B}}' in get_tagged_text(c)) and \n",
    "#         (('-induc' in c[0].get_span().lower()) or ('-assoc' in c[0].get_span().lower()))\n",
    "#         ) else (0,0)\n",
    "\n",
    "# # def LF_improve_before_disease(c):\n",
    "# #     if(rule_regex_search_before_B(c, 'improv.*', -1)==-1):\n",
    "# #         return (-1,1)\n",
    "# #     return (0,0)\n",
    "\n",
    "\n",
    "# def distanceImproveBeforeDisease(c):\n",
    "#     m=re.search(r'(improv)(.*)({{B}})', get_tagged_text(c), flags=re.I)\n",
    "#     if(m):\n",
    "#         return len(m.group(2))/5000\n",
    "#     return 0\n",
    "\n",
    "\n",
    "# def LF_improve_before_disease(c):\n",
    "#     if(rule_regex_search_before_B(c, 'improv.*', -1) == -1):\n",
    "#         return (-1,1-distanceImproveBeforeDisease(c))\n",
    "#     else:\n",
    "#         return (0,0)\n",
    "\n",
    "\n",
    "# pat_terms = ['in a patient with ', 'in patients with']\n",
    "# def LF_in_patient_with(c):\n",
    "#     return (-1,1) if re.search(ltp(pat_terms) + '{{B}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "# uncertain = ['combin', 'possible', 'unlikely']\n",
    "# # def LF_uncertain(c):\n",
    "# #     if (rule_regex_search_before_A(c, ltp(uncertain) + '.*', -1)==-1):\n",
    "# #         return (-1,1)\n",
    "# #     return (0,0)\n",
    "\n",
    "# def LF_uncertain(c):\n",
    "#     sc = 0\n",
    "#     word_vectors = get_word_vectors(get_left_tokens(c[1],7))\n",
    "#     for w in uncertain:\n",
    "#         sc=max(sc,get_similarity(word_vectors,w))\n",
    "#     if(re.search('(not|no|none) .* {{B}}', get_tagged_text(c), re.I)):\n",
    "#         return (0,0)\n",
    "#     else:\n",
    "#         return (-1,sc)\n",
    "\n",
    "# # def LF_induced_other(c):\n",
    "# #     if (rule_regex_search_tagged_text(c, '{{A}}.{20,1000}-induced {{B}}', -1)==-1):\n",
    "# #         return (-1,1)\n",
    "# #     return (0,0)  \n",
    "\n",
    "# def LF_induced_other(c):\n",
    "#     if (rule_regex_search_tagged_text(c, '{{A}}.{20,1000}-induced {{B}}', -1)==-1):\n",
    "#         return (-1,distanceCD(c))\n",
    "#     return (0,0)  \n",
    "\n",
    "# # def LF_far_c_d(c):\n",
    "# #     if (rule_regex_search_btw_AB(c, '.{100,5000}', -1)==-1):\n",
    "# #         return (-1,1)\n",
    "# #     return (0,0)\n",
    "\n",
    "# def LF_far_c_d(c):\n",
    "#     if (rule_regex_search_btw_AB(c, '.{100,5000}', -1)==-1):\n",
    "#         return (-1,distanceCD(c))\n",
    "#     return (0,0)\n",
    "\n",
    "# # def LF_far_d_c(c):\n",
    "# #     if (rule_regex_search_btw_BA(c, '.{100,5000}', -1)==-1):\n",
    "# #         return (-1,1)\n",
    "# #     return (0,0)\n",
    "\n",
    "# def LF_far_d_c(c):\n",
    "#     if (rule_regex_search_btw_BA(c, '.{100,5000}', -1)==-1):\n",
    "#         return (-1,distanceCD(c))\n",
    "#     return (0,0)\n",
    "\n",
    "# #without deps\n",
    "# gen_model.weights.lf_accuracy\n",
    "# # def LF_risk_d(c):\n",
    "# #     if (rule_regex_search_before_B(c, 'risk of ', 1)==1):\n",
    "# #         return (1,1)\n",
    "# #     return (0,0)\n",
    "\n",
    "\n",
    "# def LF_risk_d(c):\n",
    "#     sc = 0\n",
    "#     word_vectors = get_word_vectors(get_left_tokens(c[1],7))\n",
    "#     sc=max(sc,get_similarity(word_vectors,'risk'))\n",
    "#     return (1,sc)\n",
    "\n",
    "\n",
    "# # def LF_develop_d_following_c(c):\n",
    "# #     return (1,1) if re.search(r'develop.{0,25}{{B}}.{0,25}following.{0,25}{{A}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "\n",
    "# def distanceDevFol(c):\n",
    "#     dist = 0\n",
    "#     matchObj = re.search(r'(develop)(.*)({{B}})(.*)(following)(.*)({{A}})', get_tagged_text(c), flags=re.I)\n",
    "#     if(matchObj):\n",
    "#         match_groups = matchObj.group(2,4,6)\n",
    "#         dist = sum([len(mg) for mg in match_groups])\n",
    "#     return dist/5000\n",
    "\n",
    "# def LF_develop_d_following_c(c):\n",
    "#     return (1,1-distanceDevFol(c)) if re.search(r'develop.*{{B}}.*following.*{{A}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "\n",
    "# procedure, following = ['inject', 'administrat'], ['following']\n",
    "# # def LF_d_following_c(c):\n",
    "# #     return (1,distanceDFollC(c)) if re.search('{{B}}.{0,50}' + ltp(following) + '.{0,20}{{A}}.{0,50}' + ltp(procedure), get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "\n",
    "# def LF_d_following_c(c):\n",
    "#     return (1,1-distanceDC_(c,following)) if re.search('{{B}}.*' + ltp(following) + '.*{{A}}.*' + ltp(procedure), get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "# # def LF_measure(c):\n",
    "# #     return (-1,1) if re.search('measur.{0,75}{{A}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "\n",
    "# def distanceMeasureA(c):\n",
    "#     m = re.search('(measur)(.*)({{A}})', get_tagged_text(c), flags=re.I) \n",
    "#     if(m):\n",
    "#         return (5000-len(m.group(2)))/5000\n",
    "#     return 0\n",
    "\n",
    "# def LF_measure(c):\n",
    "#     return (-1,distanceMeasureA(c)) if re.search('measur.{0,75}{{A}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "\n",
    "# # def LF_level(c):\n",
    "# #     return (-1,1) if re.search('{{A}}.{0,25} level', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "\n",
    "# def distanceLevel(c):\n",
    "#     m = re.search('({{A}})(.*)(level)', get_tagged_text(c), flags=re.I)\n",
    "#     if(m):\n",
    "#         return (5000-len(m.group(2)))/5000\n",
    "#     return 0\n",
    "\n",
    "# def LF_level(c):\n",
    "#     return (-1,distanceLevel(c)) if re.search('{{A}}.{0,25} level', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "# # def LF_neg_d(c):\n",
    "# #     return (-1,1) if re.search('(none|not|no) .{0,25}{{B}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "\n",
    "# def distanceNeg(c):\n",
    "#     m = re.search('(none|not|no)(.*)({{B}})', get_tagged_text(c), flags=re.I)\n",
    "#     if(m):\n",
    "#         return (5000-len(m.group(2)))/5000\n",
    "#     return 0\n",
    "\n",
    "\n",
    "# def LF_neg_d(c):\n",
    "#     return (-1,distanceNeg(c)) if re.search('(none|not|no) .{0,25}{{B}}', get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "\n",
    "# WEAK_PHRASES = ['none', 'although', 'was carried out', 'was conducted',\n",
    "#                 'seems', 'suggests', 'risk', 'implicated',\n",
    "#                'the aim', 'to (investigate|assess|study)']\n",
    "\n",
    "# WEAK_RGX = r'|'.join(WEAK_PHRASES)\n",
    "\n",
    "# def LF_weak_assertions(c):\n",
    "#     return (-1,1) if re.search(WEAK_RGX, get_tagged_text(c), flags=re.I) else (0,0)\n",
    "\n",
    "\n",
    "# def LF_ctd_marker_c_d(c):\n",
    "#     l,s = LF_c_d(c)\n",
    "#     cl = cand_in_ctd_marker(c)\n",
    "#     return (l*cl,s*cl)\n",
    "\n",
    "# def LF_ctd_marker_induce(c):\n",
    "#     l1,s1 = LF_c_induced_d(c)\n",
    "#     l2,s2 = LF_d_induced_by_c_tight(c)\n",
    "#     cl = cand_in_ctd_marker(c)\n",
    "#     return ((l1 or l2)*cl,max(s1,s2)*cl)\n",
    "\n",
    "# def LF_ctd_therapy_treat(c):\n",
    "#     l,s = LF_c_treat_d_wide(c)\n",
    "#     cl = cand_in_ctd_therapy(c)\n",
    "#     return (l*cl,s*cl)\n",
    "\n",
    "# def LF_ctd_unspecified_treat(c):\n",
    "#     l,s = LF_c_treat_d_wide(c)\n",
    "#     cl = cand_in_ctd_unspecified(c)\n",
    "#     return (l*cl,s*cl)\n",
    "\n",
    "# def LF_ctd_unspecified_induce(c):\n",
    "#     l1,s1 = LF_c_induced_d(c)\n",
    "#     l2,s2 = LF_d_induced_by_c_tight(c)\n",
    "#     cl = cand_in_ctd_unspecified(c)\n",
    "#     return ((l1 or l2)*cl,max(s1,s2)*cl)\n",
    "\n",
    "\n",
    "# # def LF_ctd_marker_c_d(c):\n",
    "# #     return LF_c_d(c) * cand_in_ctd_marker(c)\n",
    "\n",
    "# # def LF_ctd_marker_induce(c):\n",
    "# #     return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_marker(c)\n",
    "\n",
    "# # def LF_ctd_therapy_treat(c):\n",
    "# #     return LF_c_treat_d_wide(c) * cand_in_ctd_therapy(c)\n",
    "\n",
    "# # def LF_ctd_unspecified_treat(c):\n",
    "# #     return LF_c_treat_d_wide(c) * cand_in_ctd_unspecified(c)\n",
    "\n",
    "# # def LF_ctd_unspecified_induce(c):\n",
    "# #     return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_unspecified(c)\n",
    "\n",
    "# def LF_closer_chem(c):\n",
    "#     # Get distance between chemical and disease\n",
    "#     chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "#     dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "#     if dis_start < chem_start:\n",
    "#         dist = chem_start - dis_end\n",
    "#     else:\n",
    "#         dist = dis_start - chem_end\n",
    "#     # Try to find chemical closer than @dist/2 in either direction\n",
    "#     sent = c.get_parent()\n",
    "#     closest_other_chem = float('inf')\n",
    "#     for i in range(dis_end, min(len(sent.words), dis_end + dist // 2)):\n",
    "#         et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "#         if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "#             return (-1,1)\n",
    "#     for i in range(max(0, dis_start - dist // 2), dis_start):\n",
    "#         et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "#         if et == 'Chemical' and cid != sent.entity_cids[chem_start]:\n",
    "#             return (-1,1)\n",
    "#     return (0,0)\n",
    "\n",
    "# def LF_closer_dis(c):\n",
    "#     # Get distance between chemical and disease\n",
    "#     chem_start, chem_end = c.chemical.get_word_start(), c.chemical.get_word_end()\n",
    "#     dis_start, dis_end = c.disease.get_word_start(), c.disease.get_word_end()\n",
    "#     if dis_start < chem_start:\n",
    "#         dist = chem_start - dis_end\n",
    "#     else:\n",
    "#         dist = dis_start - chem_end\n",
    "#     # Try to find chemical disease than @dist/8 in either direction\n",
    "#     sent = c.get_parent()\n",
    "#     for i in range(chem_end, min(len(sent.words), chem_end + dist // 8)):\n",
    "#         et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "#         if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "#             return (-1,1)\n",
    "#     for i in range(max(0, chem_start - dist // 8), chem_start):\n",
    "#         et, cid = sent.entity_types[i], sent.entity_cids[i]\n",
    "#         if et == 'Disease' and cid != sent.entity_cids[dis_start]:\n",
    "#             return (-1,1)\n",
    "#     return (0,0)\n",
    "\n",
    "\n",
    "# LFs = [LF_c_cause_d,LF_c_d,LF_c_induced_d,LF_c_treat_d,LF_c_treat_d_wide,LF_closer_chem,\n",
    "#     LF_closer_dis,LF_ctd_marker_c_d,LF_ctd_marker_induce,LF_ctd_therapy_treat,\n",
    "#     LF_ctd_unspecified_treat,LF_ctd_unspecified_induce,LF_d_following_c,\n",
    "#     LF_d_induced_by_c,LF_d_induced_by_c_tight,LF_d_treat_c,LF_develop_d_following_c,\n",
    "#     LF_far_c_d,LF_far_d_c,LF_improve_before_disease,LF_in_ctd_therapy,\n",
    "#     LF_in_ctd_marker,LF_in_patient_with,LF_induce,LF_induce_name,LF_induced_other,\n",
    "#     LF_level,LF_measure,LF_neg_d,LF_risk_d,LF_treat_d,LF_uncertain,LF_weak_assertions\n",
    "# ]\n",
    "\n",
    "# LF_l = [\n",
    "#     1,1,1,-1,-1,-1,\n",
    "#     -1,1,1,-1,\n",
    "#     -1,1,1,\n",
    "#     1,1,-1,1,\n",
    "#     -1,-1,-1,-1,\n",
    "#     1,-1,1,1,-1,\n",
    "#     -1,-1,-1,1,-1,-1,-1\n",
    "# ]\n",
    "# print(len(LFs),len(LF_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' output:\n",
    "\n",
    "    [[[L_x1],[S_x1]],\n",
    "     [[L_x2],[S_x2]],\n",
    "     ......\n",
    "     ......\n",
    "    ]\n",
    "\n",
    "'''\n",
    "def get_L_S_Tensor(cands): \n",
    "    \n",
    "    L_S = []\n",
    "    for i,ci in enumerate(cands):\n",
    "        L_S_ci=[]\n",
    "        L=[]\n",
    "        S=[]\n",
    "        for LF in LFs:\n",
    "            #print LF.__name__\n",
    "            l,s = LF(ci)\n",
    "            L.append(l)\n",
    "            S.append((s+1)/2)  #to scale scores in [0,1] \n",
    "        L_S_ci.append(L)\n",
    "        L_S_ci.append(S)\n",
    "        L_S.append(L_S_ci) \n",
    "        if(i%500==0 and i!=0):\n",
    "            print(str(i)+'data points labelled in',(time.time() - start_time)/60,'mins')\n",
    "    return L_S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "start_time = time.time()\n",
    "\n",
    "lt = time.localtime()\n",
    "\n",
    "print(\"started at: {}-{}-{}, {}:{}:{}\".format(lt.tm_mday,lt.tm_mon,lt.tm_year,lt.tm_hour,lt.tm_min,lt.tm_sec))\n",
    "\n",
    "dev_L_S = get_L_S_Tensor(dev_cands)\n",
    "\n",
    "np.save(\"dev_L_S_smooth\",np.array(dev_L_S))\n",
    "\n",
    "train_L_S = get_L_S_Tensor(train_cands)\n",
    "np.save(\"train_L_S_smooth\",np.array(train_L_S))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# test_L_S = get_L_S_Tensor(test_cands)\n",
    "# pkl.dump(test_L_S,open(\"test_L_S.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def draw2DArray(a):\n",
    "    fig = plt.figure(figsize=(6, 3.2))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('colorMap')\n",
    "    plt.imshow(np.array(a))\n",
    "    ax.set_aspect('equal')\n",
    "    cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
    "    cax.get_xaxis().set_visible(False)\n",
    "    cax.get_yaxis().set_visible(False)\n",
    "    cax.patch.set_alpha(0)\n",
    "    cax.set_frame_on(False)\n",
    "    plt.colorbar(orientation='vertical')\n",
    "    plt.show()\n",
    "    \n",
    "      \n",
    "def report2dict(cr):\n",
    "    # Parse rows\n",
    "    tmp = list()\n",
    "    for row in cr.split(\"\\n\"):\n",
    "        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n",
    "        if len(parsed_row) > 0:\n",
    "            tmp.append(parsed_row)\n",
    "    \n",
    "    # Store in dictionary\n",
    "    measures = tmp[0]\n",
    "\n",
    "    D_class_data = defaultdict(dict)\n",
    "    for row in tmp[1:]:\n",
    "        class_label = row[0]\n",
    "        for j, m in enumerate(measures):\n",
    "            D_class_data[class_label][m.strip()] = float(row[j + 1].strip())\n",
    "    return pd.DataFrame(D_class_data).T\n",
    "\n",
    "def predictAndPrint(pl):\n",
    "    print(\"acc\",accuracy_score(gold_labels_dev,pl))\n",
    "#     print(precision_recall_fscore_support(true_labels,pl,average='macro'))\n",
    "    print(confusion_matrix(gold_labels_dev,pl))\n",
    "#     draw2DArray(confusion_matrix(gold_labels_dev,pl))\n",
    "    return report2dict(classification_report(gold_labels_dev, pl))# target_names=class_names))\n",
    "    \n",
    "\n",
    "\n",
    "def drawPRcurve(y_test,y_score,it_no):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    splt = fig.add_subplot(111)\n",
    "    \n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score,pos_label=1)\n",
    "\n",
    "    splt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    splt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    average_precision = average_precision_score(y_test, y_score)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.05])\n",
    "    plt.title('{0:d} Precision-Recall curve: AP={1:0.2f}'.format(it_no,\n",
    "              average_precision))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(888, 2, 33) (8272, 2, 33)\n"
     ]
    }
   ],
   "source": [
    "LF_l = [\n",
    "    1,1,1,-1,-1,-1,\n",
    "    -1,1,1,-1,\n",
    "    -1,1,1,\n",
    "    1,1,-1,1,\n",
    "    -1,-1,-1,-1,\n",
    "    1,-1,1,1,-1,\n",
    "    -1,-1,-1,1,-1,-1,-1\n",
    "]\n",
    "\n",
    "import numpy as np\n",
    "dev_L_S = np.load(\"dev_L_S_smooth.npy\")\n",
    "train_L_S = np.load(\"train_L_S_smooth.npy\")\n",
    "\n",
    "# dev_L_S = np.load(\"dev_L_S_discrete.npy\")\n",
    "# train_L_S = np.load(\"train_L_S_discrete.npy\")\n",
    "\n",
    "test_L_S = dev_L_S\n",
    "true_labels = gold_labels_dev\n",
    "print(dev_L_S.shape,train_L_S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call this only once for a kernel startup\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "# BATCH_SIZE = 32\n",
    "seed = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "NoOfLFs= len(LF_l)\n",
    "NoOfClasses = 2\n",
    "print(len(LF_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## normalized model with smooth LFs\n",
    "\n",
    "def train_nl_s(lr,ep,th,af):\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "#         print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],\\\n",
    "                                 initializer=af,\\\n",
    "                                 dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],\\\n",
    "                                initializer=th,\\\n",
    "                        dtype=tf.float64)\n",
    "\n",
    "#         print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "#         print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "#         print(alphas)\n",
    "#         print(s)\n",
    "#         print(\"l\",l)\n",
    "#         print(s.graph)\n",
    "\n",
    "        s_ = tf.maximum(tf.subtract(s,alphas), 0)\n",
    "#         print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "    \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),\\\n",
    "                           -tf.ones_like(v))\n",
    "#             print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        ## smooth pout\n",
    "        pout = tf.map_fn(lambda c: iskequalsy(l,c)*s_ ,np.array([-1,1],dtype=np.float64),name=\"pout\")\n",
    "       \n",
    "        ## discrete pout\n",
    "#         pout = tf.map_fn(lambda c: iskequalsy(l,c) ,np.array([-1,1],dtype=np.float64),name=\"pout\")\n",
    "\n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,name=\"t_pout\")\n",
    "#         print(\"pout\",pout)\n",
    "\n",
    "#         print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "#         print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "#             print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "#             print(\"intsy\",out1)\n",
    "            return out1\n",
    "        \n",
    "        ## discrete normalizer\n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),np.arange(NoOfClasses,dtype=np.float64))\n",
    "\n",
    "\n",
    "        ## smooth normalizer\n",
    "        zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "                   np.array([-1,1],dtype=np.float64),name=\"zy\")\n",
    "    \n",
    "\n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "#                        np.array(NoOfClasses,dtype=np.float64))\n",
    "        \n",
    "#         print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        \n",
    "#         print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "#         print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "\n",
    "\n",
    "        normloss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "        \n",
    "   \n",
    "        tf.summary.scalar('un-normloss', normloss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "#         print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "#         print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "#         print(\"predict\",predict)\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(normloss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',\n",
    "                                      tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "                tl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    while True:\n",
    "                        sm,_,ls,t = sess.run([summary_merged,train_step,normloss,thetas])\n",
    "#                         print(t)\n",
    "#                         print(tl)\n",
    "                        train_writer.add_summary(sm, it)\n",
    "#                         if(ls<1e-5):\n",
    "#                             break\n",
    "                        tl = tl + ls\n",
    "                        it = it + 1\n",
    "                        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                print(en,\"loss\",tl)\n",
    "\n",
    "                sess.run(dev_init_op)\n",
    "                sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                test_writer.add_summary(sm, en)\n",
    "                print(a)\n",
    "                print(t)\n",
    "\n",
    "                unique, counts = np.unique(pl, return_counts=True)\n",
    "                print(dict(zip(unique, counts)))\n",
    "                print(\"acc\",accuracy_score(true_labels,pl))\n",
    "                print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "                print()\n",
    "\n",
    "            # Initialize an iterator over the validation dataset.\n",
    "            sess.run(dev_init_op)\n",
    "            a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "            print(a)\n",
    "            print(t)\n",
    "\n",
    "            unique, counts = np.unique(pl, return_counts=True)\n",
    "            print(dict(zip(unique, counts)))\n",
    "\n",
    "            print(\"acc\",accuracy_score(true_labels,pl))\n",
    "\n",
    "            predictAndPrint(pl)\n",
    "            print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "\n",
    "#             cf = confusion_matrix(true_labels,pl)\n",
    "#             print(cf)\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha-mean 0.0\n",
      "0 loss 276454.1542314165\n",
      "[ 0.01055597  0.00460971  0.00741015  0.00990061  0.01086975  0.00967792\n",
      "  0.01159471  0.00715229  0.00835285  0.01053219  0.00969638  0.00806058\n",
      "  0.00982088 -0.0061938   0.01019854  0.0103459   0.00846706  0.00885507\n",
      "  0.01025639  0.00833013  0.00925665 -0.00385336  0.00993405  0.00818247\n",
      "  0.00472511  0.01175482  0.01061927  0.01065399  0.01052143 -0.00712766\n",
      "  0.00622718  0.00639786  0.00923408]\n",
      "[[1.10806905 0.80955813 1.00379715 0.99072586 1.09655594 1.03263284\n",
      "  1.15937217 1.02605476 1.14074346 1.05483374 0.97370305 1.06042058\n",
      "  0.97239845 1.08446464 1.03100092 1.03231293 0.84348392 0.91025144\n",
      "  1.04993045 0.8264619  1.02720751 0.9456143  0.98625403 1.1650302\n",
      "  0.86956646 1.16750624 1.05818307 1.05855864 1.04755632 0.99645537\n",
      "  0.81445804 0.83079723 0.95282736]]\n",
      "{0: 263, 1: 625}\n",
      "acc 0.5146396396396397\n",
      "(0.392, 0.8277027027027027, 0.5320304017372421, None)\n",
      "\n",
      "1 loss 272332.1897618076\n",
      "[ 0.01996494  0.01118729  0.01482879  0.01977512  0.02066303  0.01895709\n",
      "  0.02149212  0.01409449  0.01535201  0.02040751  0.01955092  0.015555\n",
      "  0.01982244 -0.01333084  0.02000386  0.02025864  0.01840543  0.01852888\n",
      "  0.01990826  0.01829091  0.01819896 -0.00714359  0.01989966  0.01481728\n",
      "  0.01083017  0.02172851  0.0205552   0.02061579  0.02046472 -0.0143145\n",
      "  0.01431061  0.01448782  0.01884929]\n",
      "[[1.09857952 0.80483797 0.99795939 0.9808483  1.08674757 1.02392683\n",
      "  1.14954544 1.02084018 1.13507156 1.04495536 0.96384289 1.05415279\n",
      "  0.96241477 1.09055438 1.02118237 1.02240223 0.83363155 0.90055161\n",
      "  1.04024628 0.81651496 1.0189903  0.94988635 0.97630202 1.1669959\n",
      "  0.86533403 1.1575439  1.04828532 1.04861562 1.03764184 1.00276674\n",
      "  0.80681374 0.82311228 0.94349286]]\n",
      "{0: 249, 1: 639}\n",
      "acc 0.5146396396396397\n",
      "(0.39436619718309857, 0.8513513513513513, 0.5390374331550802, None)\n",
      "\n",
      "2 loss 268263.4191187875\n",
      "[ 0.02940344  0.01788586  0.02234617  0.02964515  0.03044938  0.02825008\n",
      "  0.03138966  0.02114733  0.02245702  0.03027836  0.02940037  0.02314276\n",
      "  0.02982657 -0.02062261  0.02982086  0.03016802  0.02834882  0.02820988\n",
      "  0.0295681   0.02825015  0.02717314 -0.01043113  0.02986375  0.02157378\n",
      "  0.01704738  0.03170058  0.03049008  0.03057628  0.030408   -0.02165418\n",
      "  0.0224802   0.02266362  0.02847334]\n",
      "[[1.08907009 0.80003355 0.99204849 0.97097484 1.076945   1.01519386\n",
      "  1.13971746 1.0155458  1.12932094 1.03508106 0.95398726 1.04781505\n",
      "  0.95242857 1.09686594 1.01135551 1.01249482 0.8237751  0.8908447\n",
      "  1.03055445 0.8065697  1.01070951 0.95423191 0.96635184 1.16895976\n",
      "  0.86103843 1.14758365 1.0383884  1.03867415 1.02772758 1.0092875\n",
      "  0.79904417 0.81530422 0.93414294]]\n",
      "{0: 239, 1: 649}\n",
      "acc 0.5123873873873874\n",
      "(0.39445300462249616, 0.8648648648648649, 0.5417989417989418, None)\n",
      "\n",
      "3 loss 264248.52801790216\n",
      "[ 0.03887207  0.02471269  0.0299671   0.03951024  0.04022804  0.03755753\n",
      "  0.04128732  0.02831698  0.02967415  0.04014428  0.0392442   0.03082877\n",
      "  0.03983315 -0.02806009  0.03964962  0.04007372  0.03829725  0.03789804\n",
      "  0.03923604  0.03820776  0.03617959 -0.01369156  0.03982624  0.02845865\n",
      "  0.02338636  0.04167094  0.04042386  0.04053539  0.04035114 -0.02913779\n",
      "  0.03073395  0.03092328  0.03810629]\n",
      "[[1.07953929 0.79513296 0.98605439 0.96110592 1.06714891 1.00643281\n",
      "  1.12988828 1.01016053 1.12348097 1.02521128 0.94413668 1.0413978\n",
      "  0.9424398  1.10338967 1.00151982 1.00259104 0.81391401 0.88113089\n",
      "  1.02085501 0.79662624 1.00236472 0.95863176 0.95640365 1.17092136\n",
      "  0.85666655 1.13762562 1.02849235 1.02873437 1.01781392 1.01600825\n",
      "  0.79115237 0.80737619 0.92477797]]\n",
      "{0: 223, 1: 665}\n",
      "acc 0.5078828828828829\n",
      "(0.39398496240601505, 0.8851351351351351, 0.5452653485952134, None)\n",
      "\n",
      "4 loss 260288.88536997902\n",
      "[ 0.04837102  0.03167369  0.03769525  0.04936993  0.04999818  0.04688011\n",
      "  0.05118509  0.03560839  0.03700847  0.05000479  0.04908185  0.03861681\n",
      "  0.04984202 -0.03563453  0.04949006  0.04997543  0.04825063  0.04759336\n",
      "  0.04891228  0.04816368  0.04521882 -0.01689888  0.04978706  0.03547727\n",
      "  0.02985555  0.05163953  0.05035651  0.05049306  0.05029405 -0.03675674\n",
      "  0.03907004  0.03926498  0.04774823]\n",
      "[[1.06998596 0.79012479 0.97996766 0.95124201 1.05736005 0.99764269\n",
      "  1.12005802 1.00467383 1.11754163 1.0153465  0.93429169 1.03489212\n",
      "  0.93244854 1.1101159  0.99167497 0.99269123 0.80404782 0.8714104\n",
      "  1.011148   0.78668473 0.99395569 0.96306593 0.94645758 1.17288032\n",
      "  0.85220553 1.12766996 1.01859721 1.01879639 1.00790125 1.02291968\n",
      "  0.78314131 0.79933126 0.91539839]]\n",
      "{0: 214, 1: 674}\n",
      "acc 0.5\n",
      "(0.39020771513353114, 0.8885135135135135, 0.5422680412371134, None)\n",
      "\n",
      "[ 0.04837102  0.03167369  0.03769525  0.04936993  0.04999818  0.04688011\n",
      "  0.05118509  0.03560839  0.03700847  0.05000479  0.04908185  0.03861681\n",
      "  0.04984202 -0.03563453  0.04949006  0.04997543  0.04825063  0.04759336\n",
      "  0.04891228  0.04816368  0.04521882 -0.01689888  0.04978706  0.03547727\n",
      "  0.02985555  0.05163953  0.05035651  0.05049306  0.05029405 -0.03675674\n",
      "  0.03907004  0.03926498  0.04774823]\n",
      "[[1.06998596 0.79012479 0.97996766 0.95124201 1.05736005 0.99764269\n",
      "  1.12005802 1.00467383 1.11754163 1.0153465  0.93429169 1.03489212\n",
      "  0.93244854 1.1101159  0.99167497 0.99269123 0.80404782 0.8714104\n",
      "  1.011148   0.78668473 0.99395569 0.96306593 0.94645758 1.17288032\n",
      "  0.85220553 1.12766996 1.01859721 1.01879639 1.00790125 1.02291968\n",
      "  0.78314131 0.79933126 0.91539839]]\n",
      "{0: 214, 1: 674}\n",
      "acc 0.5\n",
      "acc 0.5\n",
      "[[181 411]\n",
      " [ 33 263]]\n",
      "(0.39020771513353114, 0.8885135135135135, 0.5422680412371134, None)\n",
      "alpha-mean 0.1\n",
      "0 loss 250075.50593016375\n",
      "[0.11065983 0.10511028 0.10778853 0.10988675 0.11084451 0.10961194\n",
      " 0.11158681 0.1075826  0.10877467 0.11051795 0.10967953 0.10843481\n",
      " 0.10982301 0.09413202 0.11023522 0.1103367  0.1084806  0.10883147\n",
      " 0.11023475 0.10832773 0.109143   0.09690369 0.10993169 0.10861607\n",
      " 0.1052851  0.11175309 0.11061411 0.11065125 0.11051488 0.09319527\n",
      " 0.1059835  0.10615481 0.10919636]\n",
      "[[1.10802971 0.80975261 1.00401019 0.99073655 1.09657054 1.03283228\n",
      "  1.1593997  1.0262732  1.14091463 1.05484455 0.97371489 1.06057911\n",
      "  0.97239968 1.08423782 1.03098843 1.03232197 0.84349196 0.91025753\n",
      "  1.04993319 0.82647061 1.02747568 0.94559472 0.98626216 1.16506503\n",
      "  0.86973339 1.16751264 1.05819969 1.05856971 1.04757343 0.99624586\n",
      "  0.81466372 0.83099162 0.95293944]]\n",
      "{0: 263, 1: 625}\n",
      "acc 0.5146396396396397\n",
      "(0.392, 0.8277027027027027, 0.5320304017372421, None)\n",
      "\n",
      "1 loss 246354.3773171099\n",
      "[0.12016676 0.11217885 0.11557335 0.11974626 0.12061109 0.11882576\n",
      " 0.12147622 0.11494584 0.11618481 0.12037819 0.11951634 0.11629166\n",
      " 0.11982562 0.08731736 0.12007435 0.12023955 0.11843196 0.1184816\n",
      " 0.11986537 0.1182859  0.11797185 0.0943884  0.11989476 0.11568333\n",
      " 0.11194052 0.12172483 0.12054466 0.12061007 0.12045156 0.08632754\n",
      " 0.11382721 0.11400563 0.11877404]\n",
      "[[1.09850085 0.80522553 0.99838419 0.98087193 1.08677916 1.02433566\n",
      "  1.14960249 1.02127595 1.13541112 1.04497908 0.96386868 1.0544678\n",
      "  0.96241849 1.09009616 1.02115829 1.02242232 0.83364943 0.90056583\n",
      "  1.0402535  0.8165345  1.01953158 0.94984004 0.97632018 1.16706308\n",
      "  0.86566639 1.15755849 1.04832076 1.04863857 1.03767808 1.00234346\n",
      "  0.80722264 0.82349966 0.94371872]]\n",
      "{0: 246, 1: 642}\n",
      "acc 0.5135135135135135\n",
      "(0.3940809968847352, 0.8547297297297297, 0.5394456289978679, None)\n",
      "\n",
      "2 loss 242686.55484121383\n",
      "[0.12969664 0.11935155 0.12344202 0.1296009  0.13036972 0.12805456\n",
      " 0.13136618 0.12240432 0.12368577 0.13023357 0.12934755 0.12422697\n",
      " 0.12982967 0.08033888 0.1299221  0.13013895 0.12838652 0.12813968\n",
      " 0.12950499 0.12824285 0.1268343  0.09188782 0.12985665 0.12285691\n",
      " 0.11869336 0.1316953  0.1304745  0.13056794 0.13038868 0.07929758\n",
      " 0.12176636 0.12195151 0.12836147]\n",
      "[[1.08895239 0.8006166  0.99268687 0.97101193 1.07699441 1.01581382\n",
      "  1.13980443 1.01620098 1.12982954 1.0351182  0.95402762 1.04828763\n",
      "  0.95243566 1.09617952 1.01132056 1.01252634 0.82380415 0.89086739\n",
      "  1.0305663  0.80660027 1.01152115 0.95415575 0.9663802  1.16905995\n",
      "  0.86153875 1.14760658 1.03844288 1.03870918 1.02778342 1.00865275\n",
      "  0.79964817 0.81587686 0.93448389]]\n",
      "{0: 227, 1: 661}\n",
      "acc 0.5123873873873874\n",
      "(0.39636913767019666, 0.8851351351351351, 0.5475444096133752, None)\n",
      "\n",
      "3 loss 239071.84730854348\n",
      "[0.13924918 0.12663045 0.1313955  0.13945035 0.14011975 0.13729968\n",
      " 0.14125683 0.12995969 0.1312794  0.14008377 0.13917274 0.13224191\n",
      " 0.13983497 0.07320312 0.13977822 0.14003467 0.13834415 0.13780609\n",
      " 0.13915418 0.13819861 0.13573185 0.08942178 0.13981738 0.13013864\n",
      " 0.12554731 0.14166448 0.14040373 0.1405249  0.14032626 0.07211186\n",
      " 0.12980073 0.12999227 0.13795913]\n",
      "[[1.07938377 0.79591829 0.98691195 0.96115695 1.06721692 1.00726506\n",
      "  1.13000551 1.01104129 1.12416313 1.02526232 0.94419215 1.04203259\n",
      "  0.94245132 1.10248119 1.00147514 1.00263432 0.81395588 0.8811622\n",
      "  1.02087142 0.79666801 1.00344291 0.95852582 0.95644233 1.17105546\n",
      "  0.85734208 1.137657   1.028566   1.02878163 1.01788993 1.01516736\n",
      "  0.79194184 0.80812492 0.92523531]]\n",
      "{0: 219, 1: 669}\n",
      "acc 0.5033783783783784\n",
      "(0.39162929745889385, 0.8851351351351351, 0.5430051813471503, None)\n",
      "\n",
      "4 loss 235510.63613062366\n",
      "[0.14882386 0.13401655 0.13943389 0.14929425 0.14986049 0.14656261\n",
      " 0.15114832 0.1376126  0.13896655 0.1499284  0.14899147 0.14033676\n",
      " 0.14984133 0.06591628 0.14964241 0.14992651 0.14830464 0.14748124\n",
      " 0.14881353 0.14815321 0.14466613 0.0870106  0.14977698 0.13752931\n",
      " 0.13250498 0.15163239 0.15033242 0.15048098 0.15026432 0.06477648\n",
      " 0.13793035 0.13812792 0.14756753]\n",
      "[[1.06979468 0.79112405 0.98105409 0.9513074  1.05744738 0.9986878\n",
      "  1.12020578 1.00579083 1.11840616 1.01541184 0.93436276 1.0356976\n",
      "  0.93246566 1.10899455 0.99162204 0.99274654 0.80410444 0.87145023\n",
      "  1.0111687  0.78673778 0.99529568 0.9629339  0.94650667 1.17304946\n",
      "  0.85306881 1.12770986 1.01869006 1.018856   1.00799815 1.02188107\n",
      "  0.78410518 0.80024556 0.91597354]]\n",
      "{0: 211, 1: 677}\n",
      "acc 0.5011261261261262\n",
      "(0.3914327917282127, 0.8952702702702703, 0.5447070914696814, None)\n",
      "\n",
      "[0.14882386 0.13401655 0.13943389 0.14929425 0.14986049 0.14656261\n",
      " 0.15114832 0.1376126  0.13896655 0.1499284  0.14899147 0.14033676\n",
      " 0.14984133 0.06591628 0.14964241 0.14992651 0.14830464 0.14748124\n",
      " 0.14881353 0.14815321 0.14466613 0.0870106  0.14977698 0.13752931\n",
      " 0.13250498 0.15163239 0.15033242 0.15048098 0.15026432 0.06477648\n",
      " 0.13793035 0.13812792 0.14756753]\n",
      "[[1.06979468 0.79112405 0.98105409 0.9513074  1.05744738 0.9986878\n",
      "  1.12020578 1.00579083 1.11840616 1.01541184 0.93436276 1.0356976\n",
      "  0.93246566 1.10899455 0.99162204 0.99274654 0.80410444 0.87145023\n",
      "  1.0111687  0.78673778 0.99529568 0.9629339  0.94650667 1.17304946\n",
      "  0.85306881 1.12770986 1.01869006 1.018856   1.00799815 1.02188107\n",
      "  0.78410518 0.80024556 0.91597354]]\n",
      "{0: 211, 1: 677}\n",
      "acc 0.5011261261261262\n",
      "acc 0.5011261261261262\n",
      "[[180 412]\n",
      " [ 31 265]]\n",
      "(0.3914327917282127, 0.8952702702702703, 0.5447070914696814, None)\n",
      "alpha-mean 0.2\n",
      "0 loss 224386.61647020705\n",
      "[0.2107386  0.20553131 0.20809969 0.20987053 0.21081375 0.20953664\n",
      " 0.21157898 0.20794372 0.209133   0.21050127 0.20965966 0.20874716\n",
      " 0.20982279 0.19452135 0.2102616  0.21032643 0.20848936 0.20880647\n",
      " 0.2102132  0.20832617 0.20900626 0.19775845 0.20993015 0.20898135\n",
      " 0.20576547 0.21175231 0.2106093  0.21064927 0.21050755 0.19358189\n",
      " 0.20567292 0.2058447  0.20915261]\n",
      "[[1.10799437 0.8101653  1.00443755 0.99074921 1.09658665 1.03314497\n",
      "  1.15944346 1.02670731 1.14128612 1.05485727 0.97372858 1.06092953\n",
      "  0.97240541 1.08395003 1.03098046 1.0323331  0.84351377 0.9102613\n",
      "  1.04993222 0.82648315 1.02788323 0.94564897 0.98627379 1.16510314\n",
      "  0.8701099  1.16752134 1.05822495 1.05858671 1.04760148 0.99597852\n",
      "  0.81492876 0.8312391  0.95312134]]\n",
      "{0: 250, 1: 638}\n",
      "acc 0.5112612612612613\n",
      "(0.39184952978056425, 0.8445945945945946, 0.5353319057815845, None)\n",
      "\n",
      "1 loss 221055.18226960418\n",
      "[0.22031756 0.21300278 0.21617762 0.21971314 0.22054864 0.21867791\n",
      " 0.22146109 0.2156512  0.21688296 0.22034449 0.21947622 0.21689864\n",
      " 0.21982375 0.18808516 0.22012378 0.22021876 0.21844829 0.21843268\n",
      " 0.21982395 0.21828297 0.21770116 0.19610132 0.21989191 0.2164033\n",
      " 0.21288108 0.22172348 0.22053529 0.22060629 0.22043735 0.18708965\n",
      " 0.21321639 0.2133957  0.21868794]\n",
      "[[1.09843303 0.80607016 0.99925709 0.9809     1.08681409 1.02497911\n",
      "  1.14969326 1.02216333 1.13617044 1.04500713 0.96389867 1.05518467\n",
      "  0.96243271 1.08952033 1.0211452  1.02244719 0.83369832 0.90057567\n",
      "  1.0402535  0.81656276 1.02035554 0.94995059 0.9763462  1.16713701\n",
      "  0.86643932 1.15757845 1.04837466 1.04867337 1.03773734 1.00180946\n",
      "  0.8077468  0.82399011 0.94408705]]\n",
      "{0: 233, 1: 655}\n",
      "acc 0.5146396396396397\n",
      "(0.3969465648854962, 0.8783783783783784, 0.5467928496319664, None)\n",
      "\n",
      "2 loss 217774.70348615112\n",
      "[0.22991293 0.22055522 0.22432051 0.2295508  0.23027495 0.2278374\n",
      " 0.23134452 0.22343297 0.22470311 0.23018276 0.22928697 0.22510977\n",
      " 0.22982522 0.18146734 0.22999173 0.23010776 0.22840885 0.22806863\n",
      " 0.22944585 0.22823906 0.22643399 0.19445426 0.22985299 0.2239096\n",
      " 0.22007131 0.23169383 0.23046118 0.23056289 0.23036828 0.18041715\n",
      " 0.22087203 0.22105844 0.22823507]\n",
      "[[1.08885402 0.80191713 0.99402728 0.97105593 1.07704876 1.01679373\n",
      "  1.13994351 1.01756489 1.13099691 1.03516209 0.95407445 1.04939057\n",
      "  0.95245965 1.09532531 1.01130387 1.01256542 0.8238832  0.8908834\n",
      "  1.03056713 0.80664476 1.01275988 0.95433    0.96642108 1.1691708\n",
      "  0.86273255 1.14763818 1.03852602 1.03876238 1.02787539 1.00786096\n",
      "  0.80041863 0.81659802 0.93504322]]\n",
      "{0: 222, 1: 666}\n",
      "acc 0.5067567567567568\n",
      "(0.3933933933933934, 0.8851351351351351, 0.5446985446985446, None)\n",
      "\n",
      "3 loss 214544.19115920248\n",
      "[0.23952411 0.22818784 0.23252733 0.23938327 0.23999219 0.23701729\n",
      " 0.24122957 0.2312882  0.23259282 0.24001583 0.23909161 0.23337972\n",
      " 0.23982703 0.174671   0.23986514 0.2399933  0.23837088 0.23771506\n",
      " 0.23907986 0.2381945  0.2352076  0.19283036 0.23981346 0.23149935\n",
      " 0.22733627 0.24166343 0.24038714 0.24051917 0.24030045 0.17356752\n",
      " 0.22864194 0.22883504 0.23779492]\n",
      "[[1.07925732 0.79770368 0.98874617 0.96121737 1.06729124 1.00858687\n",
      "  1.13019429 1.01290965 1.12576314 1.02532252 0.94425635 1.04354524\n",
      "  0.94248642 1.10136202 1.00145659 1.00268806 0.81406845 0.88118434\n",
      "  1.02087284 0.79672923 1.00509357 0.95877499 0.95649857 1.17120451\n",
      "  0.85898662 1.13770065 1.02867895 1.02885388 1.01801655 1.01413058\n",
      "  0.79294397 0.80906287 0.92599082]]\n",
      "{0: 217, 1: 671}\n",
      "acc 0.5011261261261262\n",
      "(0.39046199701937406, 0.8851351351351351, 0.5418821096173733, None)\n",
      "\n",
      "4 loss 211363.19067516326\n",
      "[0.24915045 0.23589928 0.24079663 0.24921031 0.24969984 0.24621992\n",
      " 0.25111652 0.23921554 0.24055094 0.24984348 0.24888985 0.24170727\n",
      " 0.24982904 0.16769907 0.24974368 0.24987526 0.24833421 0.24737276\n",
      " 0.24872693 0.2481494  0.24402492 0.19124272 0.24977339 0.23917107\n",
      " 0.23467547 0.25163233 0.25031335 0.25047524 0.25023395 0.16654372\n",
      " 0.23652825 0.23672762 0.24736848]\n",
      "[[1.06964309 0.79342821 0.98341274 0.95138475 1.05754217 1.000357\n",
      "  1.12044588 1.00819624 1.12046768 1.01548884 0.93444484 1.03764754\n",
      "  0.93251325 1.10762727 0.99160355 0.99281543 0.80425422 0.87147837\n",
      "  1.01117038 0.78681629 0.99735463 0.96327318 0.94657882 1.17323815\n",
      "  0.85519943 1.12776601 1.0188334  1.01894805 1.00816193 1.02061576\n",
      "  0.78532282 0.80138496 0.91693138]]\n",
      "{0: 210, 1: 678}\n",
      "acc 0.5022522522522522\n",
      "(0.39233038348082594, 0.8986486486486487, 0.5462012320328542, None)\n",
      "\n",
      "[0.24915045 0.23589928 0.24079663 0.24921031 0.24969984 0.24621992\n",
      " 0.25111652 0.23921554 0.24055094 0.24984348 0.24888985 0.24170727\n",
      " 0.24982904 0.16769907 0.24974368 0.24987526 0.24833421 0.24737276\n",
      " 0.24872693 0.2481494  0.24402492 0.19124272 0.24977339 0.23917107\n",
      " 0.23467547 0.25163233 0.25031335 0.25047524 0.25023395 0.16654372\n",
      " 0.23652825 0.23672762 0.24736848]\n",
      "[[1.06964309 0.79342821 0.98341274 0.95138475 1.05754217 1.000357\n",
      "  1.12044588 1.00819624 1.12046768 1.01548884 0.93444484 1.03764754\n",
      "  0.93251325 1.10762727 0.99160355 0.99281543 0.80425422 0.87147837\n",
      "  1.01117038 0.78681629 0.99735463 0.96327318 0.94657882 1.17323815\n",
      "  0.85519943 1.12776601 1.0188334  1.01894805 1.00816193 1.02061576\n",
      "  0.78532282 0.80138496 0.91693138]]\n",
      "{0: 210, 1: 678}\n",
      "acc 0.5022522522522522\n",
      "acc 0.5022522522522522\n",
      "[[180 412]\n",
      " [ 30 266]]\n",
      "(0.39233038348082594, 0.8986486486486487, 0.5462012320328542, None)\n",
      "alpha-mean 0.30000000000000004\n",
      "0 loss 199422.01708822604\n",
      "[0.31079442 0.30586448 0.30833874 0.30985242 0.31077807 0.30946057\n",
      " 0.31157253 0.30822809 0.30942006 0.31048267 0.30963734 0.30899406\n",
      " 0.30982074 0.29495259 0.31027895 0.31031551 0.30849435 0.30878425\n",
      " 0.31019704 0.30832583 0.30885524 0.29865922 0.30992978 0.30926574\n",
      " 0.306152   0.31175282 0.31060556 0.31064847 0.31049945 0.29401181\n",
      " 0.3052997  0.30547166 0.30910652]\n",
      "[[1.10797193 0.81106616 1.00536241 0.99076439 1.09660183 1.0337006\n",
      "  1.15952804 1.02763165 1.14213741 1.05487229 0.97374394 1.0617517\n",
      "  0.97242058 1.08359899 1.03098337 1.032348   0.84357384 0.91025795\n",
      "  1.04992225 0.82650517 1.02856703 0.94586961 0.9862942  1.1651458\n",
      "  0.87095831 1.1675359  1.0582711  1.05861936 1.04765866 0.99565429\n",
      "  0.81526755 0.83154889 0.9534689 ]]\n",
      "{0: 240, 1: 648}\n",
      "acc 0.5067567567567568\n",
      "(0.3904320987654321, 0.8547297297297297, 0.5360169491525424, None)\n",
      "\n",
      "1 loss 196457.9143260944\n",
      "[0.32042285 0.31364836 0.31663662 0.3196769  0.32047722 0.31853117\n",
      " 0.32144939 0.31620069 0.31743627 0.32030757 0.31943188 0.31737356\n",
      " 0.31981821 0.28892643 0.32015531 0.32019719 0.31845689 0.31839066\n",
      " 0.31979463 0.31828287 0.31740548 0.29788848 0.31989178 0.31695673\n",
      " 0.31363002 0.32172504 0.32052853 0.32060524 0.3204221  0.28792817\n",
      " 0.31248925 0.31266884 0.31859867]\n",
      "[[1.09839434 0.80793013 1.00116633 0.98093471 1.08684822 1.02613303\n",
      "  1.1498712  1.0240709  1.13792913 1.04504144 0.96393359 1.05688516\n",
      "  0.96246892 1.08882312 1.0211571  1.02248153 0.83383337 0.90057276\n",
      "  1.04023691 0.81661329 1.02174621 0.95040522 0.97639267 1.16721997\n",
      "  0.86819596 1.15761247 1.04847447 1.04874012 1.03785954 1.00116837\n",
      "  0.80841489 0.8246021  0.9448005 ]]\n",
      "{0: 224, 1: 664}\n",
      "acc 0.509009009009009\n",
      "(0.39457831325301207, 0.8851351351351351, 0.5458333333333334, None)\n",
      "\n",
      "2 loss 193540.38108412168\n",
      "[0.33006215 0.32148972 0.32498095 0.32949663 0.33016771 0.32762557\n",
      " 0.33132866 0.32422628 0.32550164 0.33012771 0.32922075 0.32579431\n",
      " 0.32981559 0.28269029 0.3300352  0.33007584 0.32841996 0.32800953\n",
      " 0.32940651 0.32823971 0.32600106 0.29710557 0.32985361 0.32470903\n",
      " 0.32115853 0.33169691 0.33045215 0.33056218 0.33034668 0.28163583\n",
      " 0.31981703 0.32000377 0.32810586]\n",
      "[[1.08880189 0.80480062 0.99698528 0.97111112 1.07710219 1.01857019\n",
      "  1.14022125 1.02052029 1.13372374 1.03521662 0.95412976 1.05203042\n",
      "  0.95251911 1.0942985  1.01132719 1.01262037 0.82410219 0.89088134\n",
      "  1.03054413 0.80672584 1.01486728 0.95503756 0.96649557 1.16929535\n",
      "  0.86546095 1.1476932  1.03868243 1.03886593 1.02806919 1.00691942\n",
      "  0.80139892 0.81749584 0.93614371]]\n",
      "{0: 218, 1: 670}\n",
      "acc 0.5022522522522522\n",
      "(0.39104477611940297, 0.8851351351351351, 0.5424430641821947, None)\n",
      "\n",
      "3 loss 190667.88435672587\n",
      "[0.33971177 0.32938683 0.33337019 0.33931148 0.33984924 0.33674668\n",
      " 0.3412107  0.33230326 0.3336147  0.33994296 0.33900381 0.33425493\n",
      " 0.33981278 0.27624368 0.33991836 0.3399514  0.33838346 0.33764187\n",
      " 0.33903382 0.33819646 0.33464605 0.29631686 0.33981536 0.33252082\n",
      " 0.32873615 0.34166851 0.34037663 0.34051939 0.34027336 0.27513446\n",
      " 0.32728734 0.32748074 0.33762945]\n",
      "[[1.07919473 0.8016817  0.99282399 0.96129415 1.06736434 1.01101279\n",
      "  1.13057972 1.01698408 1.12952514 1.02539831 0.944333   1.04719185\n",
      "  0.9425715  1.10002589 1.00149393 1.00276498 0.81438147 0.88118371\n",
      "  1.02084386 0.79684321 1.00792779 0.95975765 0.95660338 1.17137202\n",
      "  0.86275702 1.13777849 1.0288953  1.02899748 1.01829051 1.01290919\n",
      "  0.7942178  0.81022883 0.92750369]]\n",
      "{0: 214, 1: 674}\n",
      "acc 0.5\n",
      "(0.39020771513353114, 0.8885135135135135, 0.5422680412371134, None)\n",
      "\n",
      "4 loss 187839.4167803007\n",
      "[0.34937117 0.33733778 0.34180264 0.34912133 0.34952152 0.34589748\n",
      " 0.35109587 0.34042982 0.34177379 0.3497532  0.34878088 0.3427539\n",
      " 0.34980972 0.26958653 0.34980457 0.34982382 0.34834726 0.34728868\n",
      " 0.3486777  0.34815322 0.34334455 0.29552889 0.34977711 0.34039008\n",
      " 0.33636126 0.3516399  0.35030221 0.35047699 0.35020227 0.26842409\n",
      " 0.33490402 0.33510361 0.34717077]\n",
      "[[1.06957308 0.79857848 0.98868831 0.9514844  1.05763535 1.00346293\n",
      "  1.12094882 1.0134676  1.12533829 1.01558713 0.93454395 1.04237493\n",
      "  0.93262649 1.10600526 0.99165765 0.99291594 0.80467267 0.87148002\n",
      "  1.01113618 0.78696594 1.00092698 0.96455608 0.94671675 1.17345008\n",
      "  0.86008882 1.12786884 1.01911362 1.01913573 1.00852739 1.01913871\n",
      "  0.78687056 0.80280064 0.91888767]]\n",
      "{0: 209, 1: 679}\n",
      "acc 0.5011261261261262\n",
      "(0.3917525773195876, 0.8986486486486487, 0.5456410256410257, None)\n",
      "\n",
      "[0.34937117 0.33733778 0.34180264 0.34912133 0.34952152 0.34589748\n",
      " 0.35109587 0.34042982 0.34177379 0.3497532  0.34878088 0.3427539\n",
      " 0.34980972 0.26958653 0.34980457 0.34982382 0.34834726 0.34728868\n",
      " 0.3486777  0.34815322 0.34334455 0.29552889 0.34977711 0.34039008\n",
      " 0.33636126 0.3516399  0.35030221 0.35047699 0.35020227 0.26842409\n",
      " 0.33490402 0.33510361 0.34717077]\n",
      "[[1.06957308 0.79857848 0.98868831 0.9514844  1.05763535 1.00346293\n",
      "  1.12094882 1.0134676  1.12533829 1.01558713 0.93454395 1.04237493\n",
      "  0.93262649 1.10600526 0.99165765 0.99291594 0.80467267 0.87148002\n",
      "  1.01113618 0.78696594 1.00092698 0.96455608 0.94671675 1.17345008\n",
      "  0.86008882 1.12786884 1.01911362 1.01913573 1.00852739 1.01913871\n",
      "  0.78687056 0.80280064 0.91888767]]\n",
      "{0: 209, 1: 679}\n",
      "acc 0.5011261261261262\n",
      "acc 0.5011261261261262\n",
      "[[179 413]\n",
      " [ 30 266]]\n",
      "(0.3917525773195876, 0.8986486486486487, 0.5456410256410257, None)\n",
      "alpha-mean 0.4\n",
      "0 loss 175164.839698541\n",
      "[0.41083099 0.40611571 0.40851062 0.40983341 0.41073942 0.40939844\n",
      " 0.41156922 0.40844035 0.40964014 0.41046314 0.40961387 0.40918191\n",
      " 0.40981782 0.39538455 0.41028926 0.41030451 0.40849716 0.40877083\n",
      " 0.41019344 0.40832679 0.40870791 0.39954194 0.40993063 0.40946786\n",
      " 0.40644658 0.41175454 0.4106036  0.410649   0.41049045 0.39444543\n",
      " 0.40488353 0.40505518 0.40906483]\n",
      "[[1.10798995 0.8131211  1.00754704 0.99078701 1.09660971 1.03494159\n",
      "  1.15978228 1.02974803 1.14423681 1.05489382 0.97376296 1.06388047\n",
      "  0.97247023 1.08316255 1.03102381 1.03237581 0.84382718 0.91023772\n",
      "  1.04989435 0.82656364 1.02995008 0.94640514 0.98634901 1.16519358\n",
      "  0.87291333 1.16757234 1.05839903 1.05871828 1.04784284 0.99526272\n",
      "  0.8157237  0.83195253 0.95439523]]\n",
      "{0: 234, 1: 654}\n",
      "acc 0.5112612612612613\n",
      "(0.3944954128440367, 0.8716216216216216, 0.5431578947368422, None)\n",
      "\n",
      "1 loss 172532.76471602818\n",
      "[0.42049078 0.41413247 0.41696405 0.41963957 0.42040089 0.41841441\n",
      " 0.42144451 0.41660814 0.41785814 0.42026947 0.4193859  0.41773325\n",
      " 0.41981112 0.38976076 0.42017332 0.42017596 0.41846142 0.4183672\n",
      " 0.41979109 0.41828563 0.41712027 0.39962715 0.41989433 0.41734531\n",
      " 0.41419714 0.42172924 0.42052574 0.42060715 0.42040545 0.38876582\n",
      " 0.41168446 0.41186336 0.41851949]\n",
      "[[1.0984476  0.8121887  1.00570921 0.98099172 1.08687281 1.02874604\n",
      "  1.15042921 1.02845955 1.1422962  1.04509653 0.96398322 1.06132629\n",
      "  0.96258954 1.08795685 1.02125812 1.0225505  0.83442494 0.90054359\n",
      "  1.04019133 0.81675323 1.02459223 0.95149906 0.97652254 1.16731275\n",
      "  0.8722569  1.157701   1.04876233 1.04894713 1.03826928 1.00039714\n",
      "  0.80932014 0.82540438 0.94676064]]\n",
      "{0: 222, 1: 666}\n",
      "acc 0.5045045045045045\n",
      "(0.3918918918918919, 0.8817567567567568, 0.5426195426195426, None)\n",
      "\n",
      "2 loss 169941.00657922018\n",
      "[0.43015728 0.42218689 0.42544871 0.42944148 0.43005429 0.42746121\n",
      " 0.43132345 0.42481084 0.42610766 0.43007152 0.42915283 0.42631092\n",
      " 0.42980406 0.38389142 0.43005935 0.43004482 0.42842567 0.42797913\n",
      " 0.42940632 0.42824472 0.42558726 0.39966762 0.42985829 0.42526394\n",
      " 0.42197747 0.43170397 0.43044929 0.43056596 0.43032322 0.38284195\n",
      " 0.41865723 0.41884285 0.42799325]\n",
      "[[1.08889734 0.81142373 1.0040696  0.97120735 1.07714453 1.02266813\n",
      "  1.14113828 1.02735011 1.14053575 1.03530992 0.95421399 1.05897994\n",
      "  0.95272258 1.09302181 1.01149921 1.01273683 0.82510744 0.89084696\n",
      "  1.03048473 0.80696073 1.01924803 0.95671773 0.96671348 1.16943431\n",
      "  0.8717789  1.1478426  1.03915455 1.03920164 1.02875523 1.00578946\n",
      "  0.8027388  0.81868285 0.93926966]]\n",
      "{0: 216, 1: 672}\n",
      "acc 0.5\n",
      "(0.3898809523809524, 0.8851351351351351, 0.5413223140495868, None)\n",
      "\n",
      "3 loss 167387.65301547214\n",
      "[0.4398301  0.43027725 0.43396323 0.43923913 0.43969954 0.43654203\n",
      " 0.44120643 0.43304689 0.43438721 0.4398693  0.43891461 0.43491361\n",
      " 0.43979663 0.3777734  0.4399472  0.43991109 0.43838988 0.43760767\n",
      " 0.43904024 0.43820417 0.43411371 0.3996646  0.43982259 0.43322196\n",
      " 0.42978587 0.44167877 0.44037449 0.44052555 0.44024394 0.37667091\n",
      " 0.42580752 0.42599933 0.43748769]\n",
      "[[1.07934011 0.81084364 1.00265034 0.96143609 1.06742616 1.01672595\n",
      "  1.13193163 1.02643863 1.13897612 1.02553607 0.94445726 1.05686628\n",
      "  0.942873   1.09836133 1.00174982 1.00293731 0.81590161 0.88114972\n",
      "  1.02077645 0.79719082 1.01392363 0.96205355 0.95692671 1.17155838\n",
      "  0.87149459 1.13800019 1.02958396 1.02949014 1.01932555 1.01144523\n",
      "  0.79597778 0.81178691 0.93196027]]\n",
      "{0: 211, 1: 677}\n",
      "acc 0.5033783783783784\n",
      "(0.3929098966026588, 0.8986486486486487, 0.5467625899280576, None)\n",
      "\n",
      "4 loss 164871.27120428233\n",
      "[0.44950883 0.43840184 0.44250619 0.4490325  0.44933655 0.44566\n",
      " 0.45109381 0.44131474 0.4426953  0.44966277 0.44867122 0.44354001\n",
      " 0.44978878 0.37140484 0.44983672 0.4497748  0.44835406 0.4472538\n",
      " 0.44869383 0.44816406 0.44270428 0.39961973 0.4497873  0.44121758\n",
      " 0.43762057 0.45165369 0.45030159 0.45048603 0.4501678  0.370251\n",
      " 0.43313988 0.43333736 0.4470043 ]\n",
      "[[1.06977733 0.81046752 1.00147601 0.95168106 1.05771959 1.01094248\n",
      "  1.12284345 1.02574593 1.13764026 1.01577805 0.93471589 1.05501318\n",
      "  0.93304612 1.10397778 0.99201393 0.99315556 0.8068477  0.87145481\n",
      "  1.0110695  0.78745052 1.00862906 0.96749807 0.94716961 1.17368507\n",
      "  0.87142029 1.12817817 1.02006344 1.01982561 1.01001866 1.01736844\n",
      "  0.78903697 0.80471729 0.92488239]]\n",
      "{0: 209, 1: 679}\n",
      "acc 0.5033783783783784\n",
      "(0.39322533136966126, 0.902027027027027, 0.5476923076923077, None)\n",
      "\n",
      "[0.44950883 0.43840184 0.44250619 0.4490325  0.44933655 0.44566\n",
      " 0.45109381 0.44131474 0.4426953  0.44966277 0.44867122 0.44354001\n",
      " 0.44978878 0.37140484 0.44983672 0.4497748  0.44835406 0.4472538\n",
      " 0.44869383 0.44816406 0.44270428 0.39961973 0.4497873  0.44121758\n",
      " 0.43762057 0.45165369 0.45030159 0.45048603 0.4501678  0.370251\n",
      " 0.43313988 0.43333736 0.4470043 ]\n",
      "[[1.06977733 0.81046752 1.00147601 0.95168106 1.05771959 1.01094248\n",
      "  1.12284345 1.02574593 1.13764026 1.01577805 0.93471589 1.05501318\n",
      "  0.93304612 1.10397778 0.99201393 0.99315556 0.8068477  0.87145481\n",
      "  1.0110695  0.78745052 1.00862906 0.96749807 0.94716961 1.17368507\n",
      "  0.87142029 1.12817817 1.02006344 1.01982561 1.01001866 1.01736844\n",
      "  0.78903697 0.80471729 0.92488239]]\n",
      "{0: 209, 1: 679}\n",
      "acc 0.5033783783783784\n",
      "acc 0.5033783783783784\n",
      "[[180 412]\n",
      " [ 29 267]]\n",
      "(0.39322533136966126, 0.902027027027027, 0.5476923076923077, None)\n",
      "alpha-mean 0.5\n",
      "0 loss 152643.68026954329\n",
      "[0.500005   0.50000018 0.50000098 0.50986974 0.51093166 0.50477487\n",
      " 0.51023291 0.50000027 0.50000074 0.51051345 0.50763178 0.50000073\n",
      " 0.50000353 0.49594162 0.5000032  0.51028764 0.50000221 0.50439683\n",
      " 0.50913339 0.50443267 0.50389121 0.49996783 0.50855505 0.50001201\n",
      " 0.50000657 0.51156429 0.50998685 0.5100901  0.50939532 0.49490625\n",
      " 0.50384798 0.50400317 0.50426551]\n",
      "[[1.11366131 0.81744988 1.01228427 0.99075973 1.09650985 1.03841578\n",
      "  1.16209261 1.03416752 1.14885455 1.05485659 0.97369785 1.06897865\n",
      "  0.9903206  1.08245846 1.04493432 1.03237014 0.85700297 0.91006335\n",
      "  1.04975305 0.82695318 1.03332471 0.94740421 0.98668413 1.16532965\n",
      "  0.87699959 1.167607   1.05955305 1.05972495 1.04986643 0.99462266\n",
      "  0.81654221 0.83265683 0.95855135]]\n",
      "{0: 250, 1: 638}\n",
      "acc 0.527027027027027\n",
      "(0.40282131661442006, 0.8682432432432432, 0.5503211991434689, None)\n",
      "\n",
      "1 loss 152320.47715262612\n",
      "[0.50001252 0.50000073 0.50000006 0.51968462 0.52075305 0.50880182\n",
      " 0.51847809 0.49999973 0.50000092 0.52033236 0.51744363 0.50000094\n",
      " 0.50000788 0.49087517 0.50000774 0.52010518 0.50000124 0.51353206\n",
      " 0.51893322 0.51398215 0.50722298 0.49996806 0.51820051 0.5000135\n",
      " 0.50000569 0.52138956 0.51911489 0.51946058 0.51796858 0.48978825\n",
      " 0.50943884 0.5096039  0.5093818 ]\n",
      "[[1.10241048 0.82051537 1.01480275 0.98094072 1.08668564 1.03564581\n",
      "  1.1553498  1.03692881 1.15115577 1.04503434 0.96387922 1.0711016\n",
      "  0.98007871 1.08642011 1.03286196 1.022549   0.85797961 0.90024218\n",
      "  1.03993055 0.81768772 1.03129549 0.95344602 0.97730976 1.16748964\n",
      "  0.88013574 1.15777962 1.05133968 1.05098084 1.04259757 0.99896791\n",
      "  0.8110583  0.82690877 0.95514411]]\n",
      "{0: 235, 1: 653}\n",
      "acc 0.5123873873873874\n",
      "(0.39509954058192953, 0.8716216216216216, 0.5437302423603794, None)\n",
      "\n",
      "2 loss 152021.84818340262\n",
      "[0.50327494 0.50000004 0.50000165 0.52948276 0.53055909 0.51260649\n",
      " 0.52641308 0.50000009 0.50000379 0.53013541 0.52724075 0.50000207\n",
      " 0.50009796 0.48566405 0.5007907  0.52990654 0.50000962 0.52311434\n",
      " 0.52873594 0.52350139 0.51041091 0.4999684  0.52778377 0.50001421\n",
      " 0.50000425 0.53120042 0.5280827  0.52869576 0.52623326 0.48452546\n",
      " 0.51513176 0.51530511 0.51414019]\n",
      "[[1.09184143 0.82338776 1.01709709 0.97113465 1.07687322 1.03294753\n",
      "  1.14896623 1.03948382 1.15322377 1.03522432 0.95407378 1.07296672\n",
      "  0.96917843 1.09052819 1.02213422 1.01274033 0.85689157 0.89043896\n",
      "  1.03012051 0.80855305 1.02924412 0.9595649  0.96804402 1.16964779\n",
      "  0.88310505 1.14796335 1.04336811 1.04246291 1.03572123 1.00342572\n",
      "  0.80548818 0.82107142 0.95191786]]\n",
      "{0: 225, 1: 663}\n",
      "acc 0.5078828828828829\n",
      "(0.3936651583710407, 0.8817567567567568, 0.5443169968717414, None)\n",
      "\n",
      "3 loss 151742.53012848162\n",
      "[0.51416456 0.5000009  0.50000251 0.53928329 0.5403682  0.51622157\n",
      " 0.5340079  0.50000022 0.50000287 0.53994127 0.53704017 0.50000027\n",
      " 0.50858809 0.48028983 0.51123156 0.53971059 0.50042252 0.53290318\n",
      " 0.53854165 0.53294756 0.51349495 0.49996501 0.53730852 0.50001522\n",
      " 0.50001004 0.54101471 0.53687742 0.53777759 0.53414674 0.47909975\n",
      " 0.52094813 0.52113021 0.518569  ]\n",
      "[[1.08158828 0.82608585 1.01918833 0.96132526 1.06705709 1.03029679\n",
      "  1.14294604 1.04185249 1.15508063 1.02541073 0.94426507 1.07459851\n",
      "  0.95879812 1.0948036  1.01182322 1.00292817 0.85413509 0.88063391\n",
      "  1.02030691 0.79955774 1.02714274 0.96576519 0.95889288 1.1718043\n",
      "  0.88592605 1.13814317 1.03564776 1.03419615 1.02925275 1.00802695\n",
      "  0.79981297 0.81512708 0.94884165]]\n",
      "{0: 219, 1: 669}\n",
      "acc 0.5056306306306306\n",
      "(0.3931240657698057, 0.8885135135135135, 0.5450777202072539, None)\n",
      "\n",
      "4 loss 151476.7845028443\n",
      "[0.52463573 0.50000082 0.50000522 0.54907011 0.55016529 0.51968095\n",
      " 0.54121906 0.50000012 0.50000497 0.5497345  0.54682564 0.5000082\n",
      " 0.51924973 0.47473575 0.52179594 0.54950163 0.50345959 0.54268228\n",
      " 0.54833468 0.54227971 0.51651529 0.49996423 0.54673959 0.50001555\n",
      " 0.50000483 0.55081796 0.54545361 0.54665333 0.54164845 0.47349462\n",
      " 0.52690573 0.52709563 0.52270024]\n",
      "[[1.07141429 0.82862799 1.02109739 0.95152538 1.05724923 1.02766955\n",
      "  1.13729167 1.04405436 1.1567483  1.01560587 0.93446602 1.07602137\n",
      "  0.94857272 1.09926637 1.00162251 0.993125   0.85018585 0.87083949\n",
      "  1.01050205 0.79074401 1.02496382 0.97204939 0.94989345 1.17395937\n",
      "  0.88861659 1.12833058 1.02820488 1.0262234  1.02320552 1.01280013\n",
      "  0.7940165  0.80906082 0.94588526]]\n",
      "{0: 214, 1: 674}\n",
      "acc 0.5045045045045045\n",
      "(0.39317507418397624, 0.8952702702702703, 0.5463917525773196, None)\n",
      "\n",
      "[0.52463573 0.50000082 0.50000522 0.54907011 0.55016529 0.51968095\n",
      " 0.54121906 0.50000012 0.50000497 0.5497345  0.54682564 0.5000082\n",
      " 0.51924973 0.47473575 0.52179594 0.54950163 0.50345959 0.54268228\n",
      " 0.54833468 0.54227971 0.51651529 0.49996423 0.54673959 0.50001555\n",
      " 0.50000483 0.55081796 0.54545361 0.54665333 0.54164845 0.47349462\n",
      " 0.52690573 0.52709563 0.52270024]\n",
      "[[1.07141429 0.82862799 1.02109739 0.95152538 1.05724923 1.02766955\n",
      "  1.13729167 1.04405436 1.1567483  1.01560587 0.93446602 1.07602137\n",
      "  0.94857272 1.09926637 1.00162251 0.993125   0.85018585 0.87083949\n",
      "  1.01050205 0.79074401 1.02496382 0.97204939 0.94989345 1.17395937\n",
      "  0.88861659 1.12833058 1.02820488 1.0262234  1.02320552 1.01280013\n",
      "  0.7940165  0.80906082 0.94588526]]\n",
      "{0: 214, 1: 674}\n",
      "acc 0.5045045045045045\n",
      "acc 0.5045045045045045\n",
      "[[183 409]\n",
      " [ 31 265]]\n",
      "(0.39317507418397624, 0.8952702702702703, 0.5463917525773196, None)\n",
      "alpha-mean 0.6000000000000001\n",
      "0 loss 152027.93422717266\n",
      "[0.60146963 0.5948654  0.59732969 0.60983209 0.6108959  0.60347301\n",
      " 0.60891119 0.59732253 0.59889745 0.61047697 0.60966047 0.59825193\n",
      " 0.59197475 0.59748624 0.59488786 0.61025077 0.59436861 0.60901985\n",
      " 0.61042569 0.60782326 0.60250957 0.59370451 0.60947665 0.5984331\n",
      " 0.5954755  0.61161071 0.60929437 0.609449   0.60819544 0.59585032\n",
      " 0.60298249 0.60313753 0.60333155]\n",
      "[[1.10690437 0.81715075 1.01201242 0.99079639 1.09654485 1.03922149\n",
      "  1.16377139 1.03390971 1.1486248  1.05489221 0.97374362 1.06869135\n",
      "  0.97110568 1.08191956 1.0298893  1.03240611 0.85398108 0.91011101\n",
      "  1.04979398 0.82741477 1.03418146 0.94700653 0.98715002 1.16523854\n",
      "  0.87667764 1.16764145 1.0607005  1.06084702 1.05155866 0.99365538\n",
      "  0.81742288 0.83323225 0.95981491]]\n",
      "{0: 291, 1: 597}\n",
      "acc 0.5709459459459459\n",
      "(0.4288107202680067, 0.8648648648648649, 0.5733482642777156, None)\n",
      "\n",
      "1 loss 151802.089175875\n",
      "[0.61280421 0.59182849 0.59483026 0.61963384 0.6207052  0.60630658\n",
      " 0.6156799  0.59458797 0.59660948 0.62028342 0.61946091 0.59614616\n",
      " 0.60162139 0.59402547 0.60680087 0.62005561 0.59350135 0.61881512\n",
      " 0.62023178 0.61708014 0.60456457 0.58795368 0.61884008 0.59557484\n",
      " 0.59240999 0.62142458 0.61756872 0.61813637 0.61544042 0.59164723\n",
      " 0.60785055 0.60798156 0.60676265]\n",
      "[[1.09664462 0.81996795 1.01433442 0.98099454 1.08673708 1.03718077\n",
      "  1.15878305 1.03648588 1.15077756 1.04508667 0.9639428  1.07061542\n",
      "  0.96067038 1.08529529 1.01956197 1.02260183 0.85230394 0.90031427\n",
      "  1.03998873 0.81882674 1.03294344 0.95268173 0.97837349 1.16739539\n",
      "  0.87954404 1.15783015 1.05386383 1.05331085 1.04602499 0.99699886\n",
      "  0.81286064 0.82807979 0.95759061]]\n",
      "{0: 264, 1: 624}\n",
      "acc 0.5427927927927928\n",
      "(0.41185897435897434, 0.8682432432432432, 0.558695652173913, None)\n",
      "\n",
      "2 loss 151588.6511535886\n",
      "[0.62336636 0.58901491 0.59258364 0.62942192 0.63050227 0.60903512\n",
      " 0.62204325 0.59208876 0.59458216 0.63007709 0.62924741 0.59432805\n",
      " 0.61249412 0.59034626 0.61750679 0.62984738 0.59513185 0.62859542\n",
      " 0.63002502 0.62618182 0.60659783 0.58213296 0.62807555 0.59292654\n",
      " 0.5895427  0.63122704 0.62556134 0.62654651 0.6222513  0.58724488\n",
      " 0.61288108 0.61297841 0.6099666 ]\n",
      "[[1.08646659 0.82267001 1.01652408 0.97120313 1.07693868 1.03514043\n",
      "  1.15412751 1.03893982 1.15279395 1.0352909  0.95415262 1.07238949\n",
      "  0.9504281  1.08880046 1.00935078 1.01280754 0.84950272 0.89052898\n",
      "  1.03019328 0.8104772  1.03161765 0.95847992 0.96980013 1.16955142\n",
      "  0.88232026 1.14802759 1.04734523 1.04613608 1.04088073 1.00046729\n",
      "  0.80822158 0.82282515 0.95543515]]\n",
      "{0: 243, 1: 645}\n",
      "acc 0.5281531531531531\n",
      "(0.4046511627906977, 0.8817567567567568, 0.5547290116896918, None)\n",
      "\n",
      "3 loss 151384.8417304432\n",
      "[0.63370665 0.58642206 0.59058612 0.63919002 0.64028154 0.61167003\n",
      " 0.62795493 0.58982134 0.59281092 0.63985217 0.63901355 0.59279213\n",
      " 0.62294544 0.5864375  0.62790311 0.63962008 0.59875263 0.63835375\n",
      " 0.63979956 0.63506851 0.60862532 0.57624342 0.63713367 0.59048632\n",
      " 0.58687072 0.64101295 0.63320783 0.63460302 0.62856635 0.58263602\n",
      " 0.61808327 0.61810226 0.61295406]\n",
      "[[1.07634008 0.82525949 1.01858469 0.96142644 1.0671534  1.03309117\n",
      "  1.149812   1.0412746  1.15467762 1.02550884 0.94437746 1.07401791\n",
      "  0.94025838 1.09244553 0.99920165 1.00302731 0.84582508 0.88075989\n",
      "  1.02041163 0.80242657 1.03019075 0.96439732 0.96148142 1.17170665\n",
      "  0.88500855 1.13823727 1.0411788  1.0393731  1.03613848 1.0040822\n",
      "  0.80350497 0.81746308 0.95333778]]\n",
      "{0: 234, 1: 654}\n",
      "acc 0.5247747747747747\n",
      "(0.4036697247706422, 0.8918918918918919, 0.5557894736842105, None)\n",
      "\n",
      "4 loss 151188.9150643394\n",
      "[0.64393779 0.58404464 0.5888309  0.64893325 0.65003907 0.61422459\n",
      " 0.63337512 0.58777935 0.59128807 0.64960434 0.64875424 0.59152928\n",
      " 0.63323337 0.58228631 0.63816391 0.64936922 0.60376079 0.64808428\n",
      " 0.64955106 0.64365622 0.61066479 0.57028565 0.64594749 0.5882498\n",
      " 0.5843885  0.65077887 0.64043438 0.6422156  0.63433096 0.57781441\n",
      " 0.62344719 0.62340353 0.61573941]\n",
      "[[1.06625121 0.82774014 1.02052084 0.95166699 1.05738325 1.03102298\n",
      "  1.14583707 1.04349446 1.15643363 1.01574267 0.93461992 1.07550653\n",
      "  0.93013866 1.09624185 0.98909643 0.99326342 0.84148183 0.87101005\n",
      "  1.01064597 0.79474847 1.02864861 0.97043008 0.95347821 1.1738611\n",
      "  0.88761235 1.1284609  1.03539751 1.03306985 1.03180156 1.00786552\n",
      "  0.79871054 0.81198861 0.95128668]]\n",
      "{0: 225, 1: 663}\n",
      "acc 0.5191441441441441\n",
      "(0.40120663650075417, 0.8986486486486487, 0.5547445255474454, None)\n",
      "\n",
      "[0.64393779 0.58404464 0.5888309  0.64893325 0.65003907 0.61422459\n",
      " 0.63337512 0.58777935 0.59128807 0.64960434 0.64875424 0.59152928\n",
      " 0.63323337 0.58228631 0.63816391 0.64936922 0.60376079 0.64808428\n",
      " 0.64955106 0.64365622 0.61066479 0.57028565 0.64594749 0.5882498\n",
      " 0.5843885  0.65077887 0.64043438 0.6422156  0.63433096 0.57781441\n",
      " 0.62344719 0.62340353 0.61573941]\n",
      "[[1.06625121 0.82774014 1.02052084 0.95166699 1.05738325 1.03102298\n",
      "  1.14583707 1.04349446 1.15643363 1.01574267 0.93461992 1.07550653\n",
      "  0.93013866 1.09624185 0.98909643 0.99326342 0.84148183 0.87101005\n",
      "  1.01064597 0.79474847 1.02864861 0.97043008 0.95347821 1.1738611\n",
      "  0.88761235 1.1284609  1.03539751 1.03306985 1.03180156 1.00786552\n",
      "  0.79871054 0.81198861 0.95128668]]\n",
      "{0: 225, 1: 663}\n",
      "acc 0.5191441441441441\n",
      "acc 0.5191441441441441\n",
      "[[195 397]\n",
      " [ 30 266]]\n",
      "(0.40120663650075417, 0.8986486486486487, 0.5547445255474454, None)\n",
      "alpha-mean 0.7000000000000001\n",
      "0 loss 151857.2707145959\n",
      "[0.71161263 0.69521588 0.69761823 0.70985139 0.71091413 0.70257634\n",
      " 0.70691522 0.69760205 0.69913285 0.71049562 0.70967994 0.69855148\n",
      " 0.71074609 0.69807418 0.71103588 0.71026964 0.6977481  0.70903998\n",
      " 0.71044438 0.7073306  0.70156445 0.69425381 0.70896761 0.69869941\n",
      " 0.69584695 0.71162824 0.70799189 0.7080749  0.7058754  0.69798208\n",
      " 0.70126278 0.70196047 0.70184589]\n",
      "[[1.10745197 0.81703288 1.01196518 0.99078975 1.09653944 1.03969478\n",
      "  1.16562585 1.0338544  1.14862157 1.05488633 0.97373677 1.06866032\n",
      "  0.97223069 1.08144895 1.0306902  1.03239997 0.85107054 0.91010336\n",
      "  1.04978804 0.82826806 1.03469667 0.94655889 0.98807908 1.1652363\n",
      "  0.87652853 1.16763684 1.06229475 1.06270201 1.05390548 0.99047254\n",
      "  0.81947438 0.83378476 0.96074638]]\n",
      "{0: 341, 1: 547}\n",
      "acc 0.6069819819819819\n",
      "(0.4515539305301645, 0.8344594594594594, 0.5860023724792408, None)\n",
      "\n",
      "1 loss 151711.39707197412\n",
      "[0.72194778 0.69239377 0.69525235 0.71964628 0.72071652 0.70463323\n",
      " 0.71165156 0.69500003 0.69691846 0.72029519 0.71947351 0.69656667\n",
      " 0.72128467 0.69525051 0.72146557 0.72006762 0.69928316 0.71882834\n",
      " 0.7202436  0.71583094 0.70275937 0.68904733 0.71759487 0.69588434\n",
      " 0.69303366 0.72143511 0.7146992  0.71529112 0.71081619 0.695858\n",
      " 0.70433773 0.70557941 0.70394348]\n",
      "[[1.09737592 0.81980775 1.0143221  0.98100665 1.08675077 1.03807873\n",
      "  1.16245001 1.03645323 1.15085681 1.04509974 0.96395466 1.07064792\n",
      "  0.9621018  1.08426933 1.02058731 1.02261457 0.84889188 0.90032518\n",
      "  1.04000172 0.82089201 1.03396104 0.95176257 0.98057589 1.16739151\n",
      "  0.87930702 1.15784487 1.05734194 1.05708967 1.05058906 0.99045198\n",
      "  0.81713025 0.82932405 0.95937074]]\n",
      "{0: 322, 1: 566}\n",
      "acc 0.6013513513513513\n",
      "(0.44876325088339225, 0.8581081081081081, 0.5893271461716938, None)\n",
      "\n",
      "2 loss 151571.3624428451\n",
      "[0.73217014 0.68968656 0.69301458 0.72942535 0.73050456 0.70664533\n",
      " 0.71601997 0.69251799 0.69483524 0.73007986 0.729251   0.69472599\n",
      " 0.73160499 0.69226736 0.73173644 0.72985038 0.70209702 0.72859953\n",
      " 0.73002784 0.72403342 0.70396318 0.68376719 0.7259507  0.69317326\n",
      " 0.69031872 0.73122847 0.72101141 0.72206498 0.71535166 0.69354607\n",
      " 0.70748197 0.70927755 0.70592667]\n",
      "[[1.08733101 0.8225244  1.01661238 0.97123683 1.07697429 1.03645054\n",
      "  1.15950156 1.03899057 1.15302372 1.03532575 0.95418603 1.07256081\n",
      "  0.95201805 1.08712514 1.01052239 1.01284199 0.84612749 0.89056128\n",
      "  1.03022804 0.8138804  1.03315817 0.95707095 0.97341246 1.16954645\n",
      "  0.88204411 1.14806449 1.05271802 1.05189069 1.04752755 0.99033805\n",
      "  0.81487227 0.82489385 0.95801366]]\n",
      "{0: 302, 1: 586}\n",
      "acc 0.5878378378378378\n",
      "(0.4402730375426621, 0.8716216216216216, 0.5850340136054422, None)\n",
      "\n",
      "3 loss 151436.25792656024\n",
      "[0.74232464 0.68709068 0.69090071 0.73918541 0.7402756  0.70862042\n",
      " 0.72002102 0.69015198 0.69287865 0.73984679 0.73900911 0.69302415\n",
      " 0.74181683 0.68912098 0.74192027 0.73961499 0.70590141 0.73834985\n",
      " 0.73979425 0.73186377 0.70518574 0.67841275 0.73397152 0.69056374\n",
      " 0.68769871 0.74100594 0.72689388 0.72834871 0.71948038 0.69113279\n",
      " 0.71062369 0.7130365  0.70780688]\n",
      "[[1.07731148 0.82518487 1.01883847 0.96148222 1.06721162 1.0348051\n",
      "  1.15676919 1.04146865 1.15512489 1.02556608 0.94443285 1.07440206\n",
      "  0.94196902 1.09002515 1.00048746 1.00308403 0.84289346 0.88081391\n",
      "  1.02046875 0.80728528 1.03228082 0.96248316 0.9666312  1.17170113\n",
      "  0.88474157 1.13829716 1.04842677 1.04711041 1.04470829 0.99017729\n",
      "  0.81270197 0.82050457 0.95666786]]\n",
      "{0: 275, 1: 613}\n",
      "acc 0.5731981981981982\n",
      "(0.43230016313213704, 0.8952702702702703, 0.583058305830583, None)\n",
      "\n",
      "4 loss 151305.4330715769\n",
      "[0.75243369 0.6846023  0.68890619 0.74892143 0.75002547 0.71056616\n",
      " 0.72365902 0.68789779 0.69104385 0.7495915  0.74874264 0.69145547\n",
      " 0.7519634  0.68580978 0.75204891 0.74935676 0.71045489 0.74807337\n",
      " 0.74953831 0.73922958 0.70643657 0.67298399 0.74158015 0.68805305\n",
      " 0.68517    0.75076384 0.73231304 0.73409887 0.72320577 0.68863153\n",
      " 0.71382686 0.71686613 0.7095953 ]\n",
      "[[1.06731295 0.82779129 1.02100295 0.95174577 1.05746524 1.03313751\n",
      "  1.15424106 1.04388984 1.15716308 1.01582338 0.9346982  1.07617484\n",
      "  0.93194729 1.09297794 0.99047669 0.99334344 0.83928705 0.87108651\n",
      "  1.01072653 0.80116059 1.03132212 0.96799764 0.96027648 1.17385555\n",
      "  0.88740123 1.1285451  1.04447023 1.04274832 1.04211768 0.99000764\n",
      "  0.81062113 0.81617132 0.95532649]]\n",
      "{0: 261, 1: 627}\n",
      "acc 0.5574324324324325\n",
      "(0.4226475279106858, 0.8952702702702703, 0.5742145178764897, None)\n",
      "\n",
      "[0.75243369 0.6846023  0.68890619 0.74892143 0.75002547 0.71056616\n",
      " 0.72365902 0.68789779 0.69104385 0.7495915  0.74874264 0.69145547\n",
      " 0.7519634  0.68580978 0.75204891 0.74935676 0.71045489 0.74807337\n",
      " 0.74953831 0.73922958 0.70643657 0.67298399 0.74158015 0.68805305\n",
      " 0.68517    0.75076384 0.73231304 0.73409887 0.72320577 0.68863153\n",
      " 0.71382686 0.71686613 0.7095953 ]\n",
      "[[1.06731295 0.82779129 1.02100295 0.95174577 1.05746524 1.03313751\n",
      "  1.15424106 1.04388984 1.15716308 1.01582338 0.9346982  1.07617484\n",
      "  0.93194729 1.09297794 0.99047669 0.99334344 0.83928705 0.87108651\n",
      "  1.01072653 0.80116059 1.03132212 0.96799764 0.96027648 1.17385555\n",
      "  0.88740123 1.1285451  1.04447023 1.04274832 1.04211768 0.99000764\n",
      "  0.81062113 0.81617132 0.95532649]]\n",
      "{0: 261, 1: 627}\n",
      "acc 0.5574324324324325\n",
      "acc 0.5574324324324325\n",
      "[[230 362]\n",
      " [ 31 265]]\n",
      "(0.4226475279106858, 0.8952702702702703, 0.5742145178764897, None)\n",
      "alpha-mean 0.8\n",
      "0 loss 152014.90862417966\n",
      "[0.8112384  0.79536284 0.79767862 0.80982701 0.8108898  0.80218895\n",
      " 0.80452165 0.79767644 0.79914397 0.81047129 0.80965554 0.79859318\n",
      " 0.80993163 0.7982153  0.81049376 0.8102453  0.80141642 0.80901546\n",
      " 0.81042005 0.80620652 0.8013773  0.79462693 0.80779298 0.79868289\n",
      " 0.79600057 0.81160387 0.80595892 0.80552237 0.80320792 0.80104714\n",
      " 0.79918061 0.80069139 0.80091923]\n",
      "[[1.10759614 0.81700002 1.0120052  0.9908307  1.09658074 1.03977466\n",
      "  1.16732692 1.03387397 1.14869861 1.05492747 0.97377767 1.06872548\n",
      "  0.97241312 1.08094022 1.03085342 1.03244104 0.85053135 0.91014412\n",
      "  1.04982917 0.82971053 1.03458107 0.9462415  0.98948446 1.16523432\n",
      "  0.87648301 1.16767842 1.0640206  1.06508612 1.05582982 0.98930244\n",
      "  0.82061731 0.83432599 0.96121094]]\n",
      "{0: 436, 1: 452}\n",
      "acc 0.6711711711711712\n",
      "(0.504424778761062, 0.7702702702702703, 0.6096256684491979, None)\n",
      "\n",
      "1 loss 151910.22739425395\n",
      "[0.82128164 0.79261509 0.79529622 0.81959029 0.82066048 0.80391248\n",
      " 0.80689307 0.79507487 0.79686105 0.82023921 0.8194175  0.79656203\n",
      " 0.82001478 0.79572865 0.82055756 0.82001165 0.80423873 0.81877211\n",
      " 0.82018762 0.81312098 0.80240107 0.78982653 0.81461113 0.79578624\n",
      " 0.79328218 0.82137886 0.81025511 0.81008761 0.80560119 0.80253474\n",
      " 0.80005784 0.80266164 0.80217586]\n",
      "[[1.09767986 0.81977919 1.01444288 0.98110209 1.0868472  1.03822988\n",
      "  1.16581337 1.03653193 1.15105322 1.04519575 0.96404996 1.07082469\n",
      "  0.96247565 1.08322802 1.020926   1.02271037 0.84812757 0.90042004\n",
      "  1.04009768 0.82421978 1.03375355 0.95107734 0.98421332 1.16738773\n",
      "  0.87923951 1.15794207 1.06117538 1.06186436 1.05433476 0.98812314\n",
      "  0.81952761 0.83060875 0.96027008]]\n",
      "{0: 429, 1: 459}\n",
      "acc 0.6768018018018018\n",
      "(0.5098039215686274, 0.7905405405405406, 0.6198675496688741, None)\n",
      "\n",
      "2 loss 151808.06314858966\n",
      "[0.83129845 0.78991434 0.79296604 0.82933437 0.83041337 0.80562471\n",
      " 0.8090716  0.7925221  0.79463136 0.82998882 0.82915999 0.79458859\n",
      " 0.83006158 0.79327119 0.83059004 0.82975939 0.80757954 0.82850824\n",
      " 0.82993682 0.81956592 0.80343837 0.7849762  0.82097491 0.79292983\n",
      " 0.79060141 0.83113683 0.81418106 0.81422707 0.80777272 0.80432168\n",
      " 0.80087594 0.80474319 0.80338828]\n",
      "[[1.08778048 0.82253477 1.01685309 0.97139235 1.0771316  1.036674\n",
      "  1.1643974  1.03916502 1.15337973 1.03548232 0.95434128 1.0728937\n",
      "  0.95255779 1.08551276 1.01101682 1.01299817 0.84549168 0.8907157\n",
      "  1.03038452 0.81917813 1.0328884  0.9559771  0.97936185 1.16954111\n",
      "  0.8819818  1.14822318 1.05857134 1.05893273 1.0529539  0.98681272\n",
      "  0.81851139 0.82715355 0.95933293]]\n",
      "{0: 346, 1: 542}\n",
      "acc 0.6509009009009009\n",
      "(0.4870848708487085, 0.8918918918918919, 0.630071599045346, None)\n",
      "\n",
      "3 loss 151707.8424184586\n",
      "[0.84129317 0.78725849 0.79068573 0.8390547  0.84014447 0.80732889\n",
      " 0.81107033 0.79001597 0.79245248 0.83971594 0.83887838 0.79267001\n",
      " 0.8400798  0.79082305 0.8405972  0.83948422 0.81132032 0.83821872\n",
      " 0.83966342 0.82548564 0.80449258 0.78007622 0.82684276 0.79011264\n",
      " 0.78795651 0.84087409 0.81774318 0.8179563  0.80973797 0.80635786\n",
      " 0.80164144 0.8067318  0.80456172]\n",
      "[[1.07789772 0.82526781 1.01923705 0.96170488 1.06743705 1.03510534\n",
      "  1.16307069 1.04177436 1.15567939 1.02579037 0.94465512 1.07493398\n",
      "  0.9426586  1.08779536 1.00112528 1.00330772 0.84267933 0.88103486\n",
      "  1.0206929  0.81459973 1.03198387 0.96094006 0.97493514 1.17169447\n",
      "  0.8847106  1.13852468 1.05619565 1.05626902 1.05167737 0.98539672\n",
      "  0.81756336 0.82395238 0.95839707]]\n",
      "{0: 345, 1: 543}\n",
      "acc 0.652027027027027\n",
      "(0.4880294659300184, 0.8952702702702703, 0.6317044100119189, None)\n",
      "\n",
      "4 loss 151609.21346095053\n",
      "[0.85126888 0.78464551 0.78845298 0.84874434 0.84984784 0.80902842\n",
      " 0.81290245 0.78755434 0.79032204 0.84941425 0.8485655  0.79080355\n",
      " 0.8500746  0.78826978 0.8505831  0.84917962 0.81536506 0.8478956\n",
      " 0.84936109 0.83082987 0.80556749 0.77512582 0.83217795 0.78733365\n",
      " 0.78534565 0.85058519 0.82095062 0.82129505 0.81151251 0.80859783\n",
      " 0.80236102 0.80853619 0.80570145]\n",
      "[[1.06803157 0.82797933 1.02159597 0.95204457 1.05776791 1.03352194\n",
      "  1.16182506 1.04436101 1.15795343 1.01612445 0.93499644 1.07694696\n",
      "  0.93277752 1.09007827 0.9912511  0.99364368 0.83973773 0.87138292\n",
      "  1.01102741 0.81048791 1.03103771 0.96596647 0.97093138 1.17384782\n",
      "  0.88742677 1.12885069 1.05403499 1.05385112 1.05049543 0.98389889\n",
      "  0.81667793 0.8209983  0.95745984]]\n",
      "{0: 340, 1: 548}\n",
      "acc 0.6463963963963963\n",
      "(0.4835766423357664, 0.8952702702702703, 0.6279620853080569, None)\n",
      "\n",
      "[0.85126888 0.78464551 0.78845298 0.84874434 0.84984784 0.80902842\n",
      " 0.81290245 0.78755434 0.79032204 0.84941425 0.8485655  0.79080355\n",
      " 0.8500746  0.78826978 0.8505831  0.84917962 0.81536506 0.8478956\n",
      " 0.84936109 0.83082987 0.80556749 0.77512582 0.83217795 0.78733365\n",
      " 0.78534565 0.85058519 0.82095062 0.82129505 0.81151251 0.80859783\n",
      " 0.80236102 0.80853619 0.80570145]\n",
      "[[1.06803157 0.82797933 1.02159597 0.95204457 1.05776791 1.03352194\n",
      "  1.16182506 1.04436101 1.15795343 1.01612445 0.93499644 1.07694696\n",
      "  0.93277752 1.09007827 0.9912511  0.99364368 0.83973773 0.87138292\n",
      "  1.01102741 0.81048791 1.03103771 0.96596647 0.97093138 1.17384782\n",
      "  0.88742677 1.12885069 1.05403499 1.05385112 1.05049543 0.98389889\n",
      "  0.81667793 0.8209983  0.95745984]]\n",
      "{0: 340, 1: 548}\n",
      "acc 0.6463963963963963\n",
      "acc 0.6463963963963963\n",
      "[[309 283]\n",
      " [ 31 265]]\n",
      "(0.4835766423357664, 0.8952702702702703, 0.6279620853080569, None)\n",
      "alpha-mean 0.9\n",
      "0 loss 152313.84897488722\n",
      "[0.9110542  0.89537947 0.89761258 0.90972772 0.9107896  0.90232271\n",
      " 0.90279678 0.89763724 0.89904062 0.91037148 0.90955636 0.89849701\n",
      " 0.90971773 0.89866835 0.91029499 0.91014569 0.90127324 0.9089166\n",
      " 0.91032029 0.90379888 0.90165996 0.89508906 0.90555725 0.89857289\n",
      " 0.89603849 0.9115029  0.90378599 0.90268604 0.9014411  0.9007866\n",
      " 0.89928751 0.90177676 0.90054298]\n",
      "[[1.10779045 0.81700828 1.01208234 0.99098018 1.09673238 1.03947714\n",
      "  1.16838947 1.0339232  1.14880295 1.05507824 0.97392683 1.06882802\n",
      "  0.9726154  1.08073202 1.03105161 1.03259134 0.85110198 0.91029214\n",
      "  1.04997982 0.83213196 1.03412623 0.9457906  0.99147146 1.16523203\n",
      "  0.87646421 1.16783162 1.06552254 1.0671075  1.05690497 0.98989321\n",
      "  0.82118593 0.83603367 0.96131487]]\n",
      "{0: 455, 1: 433}\n",
      "acc 0.6835585585585585\n",
      "(0.5173210161662818, 0.7567567567567568, 0.6145404663923183, None)\n",
      "\n",
      "1 loss 152227.4242781849\n",
      "[0.92087373 0.89261102 0.89512579 0.91934365 0.92041163 0.904213\n",
      " 0.90355384 0.89495791 0.89661496 0.91999133 0.91917113 0.89632694\n",
      " 0.91955472 0.89661157 0.92012395 0.91976425 0.90348333 0.91852649\n",
      " 0.91993986 0.90771605 0.90301321 0.89074146 0.90854238 0.89553825\n",
      " 0.8933288  0.92112809 0.90548223 0.9044666  0.90219438 0.90171984\n",
      " 0.89992827 0.90474305 0.90149754]\n",
      "[[1.09813771 0.81981761 1.01461877 0.98147075 1.08722135 1.03762711\n",
      "  1.16785912 1.03665307 1.15128421 1.04556767 0.9644178  1.07105337\n",
      "  0.96294695 1.08282851 1.02139026 1.02308112 0.84953176 0.90078499\n",
      "  1.04046933 0.82934409 1.03281989 0.9501765  0.98947746 1.16738316\n",
      "  0.87921533 1.15832022 1.06450512 1.06584507 1.05641104 0.9894599\n",
      "  0.82071483 0.83400967 0.9604353 ]]\n",
      "{0: 349, 1: 539}\n",
      "acc 0.6565315315315315\n",
      "(0.49165120593692024, 0.8952702702702703, 0.6347305389221557, None)\n",
      "\n",
      "2 loss 152141.43370804438\n",
      "[0.93066495 0.88985671 0.89265618 0.92889974 0.92997562 0.90612505\n",
      " 0.9042764  0.89229353 0.89420678 0.92955251 0.92872568 0.89417521\n",
      " 0.92936361 0.89455013 0.9299248  0.92932375 0.90581625 0.92807458\n",
      " 0.92950066 0.91114729 0.90442445 0.88630879 0.91119738 0.89251495\n",
      " 0.89061839 0.93069609 0.90701152 0.9060568  0.90289976 0.90269445\n",
      " 0.90054568 0.90729536 0.9024717 ]\n",
      "[[1.08853191 0.82262038 1.01714586 0.97203062 1.0777792  1.03575014\n",
      "  1.16733801 1.03937572 1.1537559  1.03612609 0.95497818 1.07326883\n",
      "  0.95332372 1.08493686 1.01177484 1.01363996 0.84792617 0.89134783\n",
      "  1.03102784 0.82689142 1.03144944 0.95465208 0.98768324 1.16953435\n",
      "  0.88197455 1.14887768 1.06357348 1.06469356 1.055932   0.98903706\n",
      "  0.82026112 0.83223708 0.95952599]]\n",
      "{0: 349, 1: 539}\n",
      "acc 0.6565315315315315\n",
      "(0.49165120593692024, 0.8952702702702703, 0.6347305389221557, None)\n",
      "\n",
      "3 loss 152055.5091159558\n",
      "[0.94042252 0.88711569 0.89020278 0.93836917 0.93945648 0.90806036\n",
      " 0.90496894 0.88964326 0.89181513 0.93902934 0.93819288 0.89204069\n",
      " 0.93913977 0.89248359 0.93969258 0.93879816 0.90822991 0.93753223\n",
      " 0.93897696 0.91411626 0.90589551 0.88179203 0.91354526 0.88950299\n",
      " 0.88790726 0.94018265 0.90838746 0.90747918 0.90356351 0.90368961\n",
      " 0.90112374 0.90947898 0.90346758]\n",
      "[[1.07898498 0.82541698 1.01966406 0.9626846  1.06843022 1.03384524\n",
      "  1.16682365 1.04209155 1.15621847 1.02677795 0.94563291 1.07547495\n",
      "  0.94375673 1.08705732 1.00221677 1.00429244 0.84630708 0.88200619\n",
      "  1.02167983 0.82474093 1.03001358 0.95921631 0.98606975 1.17168561\n",
      "  0.88474148 1.13952812 1.06271895 1.06363908 1.05546445 0.98863381\n",
      "  0.81982185 0.83068206 0.9585857 ]]\n",
      "{0: 346, 1: 542}\n",
      "acc 0.6554054054054054\n",
      "(0.4907749077490775, 0.8986486486486487, 0.6348448687350836, None)\n",
      "\n",
      "4 loss 151969.54311733245\n",
      "[0.95013808 0.88438715 0.88776472 0.94769995 0.94880681 0.91002033\n",
      " 0.90563566 0.88700627 0.88943913 0.94837283 0.94751976 0.88992235\n",
      " 0.94887575 0.89041154 0.94941945 0.94813751 0.91068898 0.9468423\n",
      " 0.94831954 0.91665374 0.90742814 0.87719213 0.91560969 0.88650236\n",
      " 0.88519539 0.94954254 0.90962296 0.90875386 0.9041914  0.90468767\n",
      " 0.90166694 0.91134011 0.9044872 ]\n",
      "[[1.06951506 0.82820779 1.02217383 0.95347466 1.05921503 1.03191147\n",
      "  1.16631371 1.04480094 1.15867237 1.0175643  0.93642427 1.07767225\n",
      "  0.93426278 1.08919007 0.99273343 0.99507989 0.84469271 0.87280377\n",
      "  1.01246641 0.82286008 1.0285111  0.96386813 0.9846192  1.17383694\n",
      "  0.88751575 1.13031165 1.06193348 1.06266946 1.05500529 0.98825758\n",
      "  0.81939461 0.82931334 0.9576132 ]]\n",
      "{0: 346, 1: 542}\n",
      "acc 0.6554054054054054\n",
      "(0.4907749077490775, 0.8986486486486487, 0.6348448687350836, None)\n",
      "\n",
      "[0.95013808 0.88438715 0.88776472 0.94769995 0.94880681 0.91002033\n",
      " 0.90563566 0.88700627 0.88943913 0.94837283 0.94751976 0.88992235\n",
      " 0.94887575 0.89041154 0.94941945 0.94813751 0.91068898 0.9468423\n",
      " 0.94831954 0.91665374 0.90742814 0.87719213 0.91560969 0.88650236\n",
      " 0.88519539 0.94954254 0.90962296 0.90875386 0.9041914  0.90468767\n",
      " 0.90166694 0.91134011 0.9044872 ]\n",
      "[[1.06951506 0.82820779 1.02217383 0.95347466 1.05921503 1.03191147\n",
      "  1.16631371 1.04480094 1.15867237 1.0175643  0.93642427 1.07767225\n",
      "  0.93426278 1.08919007 0.99273343 0.99507989 0.84469271 0.87280377\n",
      "  1.01246641 0.82286008 1.0285111  0.96386813 0.9846192  1.17383694\n",
      "  0.88751575 1.13031165 1.06193348 1.06266946 1.05500529 0.98825758\n",
      "  0.81939461 0.82931334 0.9576132 ]]\n",
      "{0: 346, 1: 542}\n",
      "acc 0.6554054054054054\n",
      "acc 0.6554054054054054\n",
      "[[316 276]\n",
      " [ 30 266]]\n",
      "(0.4907749077490775, 0.8986486486486487, 0.6348448687350836, None)\n",
      "alpha-mean 1.0\n",
      "0 loss 152518.84298978723\n",
      "[1.01482387 0.99489525 1.01424774 1.         1.01474245 1.01453623\n",
      " 1.01499651 1.01453593 1.01493705 1.01461005 1.         1.01465734\n",
      " 0.99953423 1.01469343 1.014576   1.01453944 0.99946904 1.\n",
      " 1.01459481 1.         1.01451312 0.99699854 1.00000326 0.99850273\n",
      " 0.99798048 1.01503503 1.01462009 1.01462135 1.01458834 0.99869702\n",
      " 0.99859508 0.99870561 1.00002865]\n",
      "[[1.12797281 0.81770798 1.01916478 1.00062431 1.11668593 1.05130016\n",
      "  1.17988217 1.04116932 1.15692792 1.07481057 0.98357063 1.07677325\n",
      "  0.98238121 1.08880162 1.05083566 1.05220298 0.85332834 0.91993331\n",
      "  1.06968575 0.83639708 1.04530082 0.94416671 0.99620664 1.16527321\n",
      "  0.87451404 1.18820396 1.07819033 1.07861456 1.06752603 0.99151307\n",
      "  0.82188144 0.83823849 0.9618892 ]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "1 loss 152445.73168977088\n",
      "[1.02623509 0.99173367 1.02570884 1.         1.02611273 1.02592248\n",
      " 1.02634752 1.02597299 1.02633863 1.02599055 1.         1.0260834\n",
      " 0.99851859 1.0261162  1.0260095  1.02592544 0.99908144 1.\n",
      " 1.02597649 1.         1.02590119 0.99458364 1.         0.99539145\n",
      " 0.99721303 1.02638317 1.02599981 1.02600097 1.02597052 0.99744837\n",
      " 0.99895691 0.99916093 1.00002851]\n",
      "[[1.13986994 0.82103699 1.03110548 1.00062431 1.12854765 1.06317266\n",
      "  1.19172776 1.05308602 1.16881678 1.08667936 0.98357063 1.08868178\n",
      "  0.98233879 1.10070777 1.06274954 1.06407531 0.85336035 0.91993331\n",
      "  1.08155528 0.83639708 1.05717461 0.9467539  0.99620664 1.16742155\n",
      "  0.8753089  1.20004693 1.09005861 1.09048278 1.07939588 0.99283598\n",
      "  0.82153038 0.83782588 0.96188919]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "2 loss 152372.5304028526\n",
      "[1.03711169 0.98863791 1.03660494 1.         1.03694731 1.03676239\n",
      " 1.03717556 1.03686046 1.03721127 1.03682855 1.         1.03696625\n",
      " 0.99701376 1.03699764 1.03689552 1.03676526 0.99875727 1.\n",
      " 1.03681488 1.         1.0367417  0.99209918 1.00003518 0.99228034\n",
      " 0.99637358 1.03721021 1.03683755 1.03683868 1.03680908 0.99622655\n",
      " 0.99932436 0.99963537 1.00001451]\n",
      "[[1.15109472 0.82424814 1.04235149 1.00062431 1.13974    1.07437048\n",
      "  1.2029127  1.06432152 1.1800374  1.09787525 0.98357063 1.09991275\n",
      "  0.9818821  1.1119374  1.07398355 1.07527305 0.85345476 0.91993331\n",
      "  1.09275157 0.83639708 1.06837308 0.94935035 0.99620639 1.16956998\n",
      "  0.87617315 1.21123071 1.10125425 1.10167839 1.09059233 0.99410406\n",
      "  0.82117891 0.83740574 0.96188907]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "3 loss 152298.88312073477\n",
      "[1.0477616  0.98557513 1.04726665 1.         1.04755536 1.04737307\n",
      " 1.04778032 1.04751738 1.04785872 1.04743828 1.         1.04762019\n",
      " 0.99500895 1.04765066 1.04755152 1.0473759  0.99814848 1.\n",
      " 1.04742481 1.         1.04735267 0.98954334 1.         0.98916946\n",
      " 0.99546066 1.04781448 1.04744715 1.04744827 1.04741909 0.99501337\n",
      " 0.99969755 1.00001388 1.00003833]\n",
      "[[1.1620069  0.82739948 1.05327646 1.00062431 1.15062049 1.08525393\n",
      "  1.21378918 1.07524056 1.19094701 1.10875765 0.98357063 1.11082889\n",
      "  0.97977052 1.12285265 1.08490166 1.08615645 0.85367027 0.91993331\n",
      "  1.10363418 0.83639708 1.07925687 0.95199113 0.99620622 1.17171849\n",
      "  0.87710923 1.22210655 1.11213651 1.11256063 1.10147503 0.9953477\n",
      "  0.82083532 0.83715732 0.96188898]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "4 loss 152224.66307838666\n",
      "[1.05828355 0.9825313  1.05779716 1.         1.05803581 1.057855\n",
      " 1.05825884 1.05804468 1.05837884 1.05791969 1.         1.05814521\n",
      " 0.99247407 1.05817498 1.05807813 1.05785781 0.99723498 1.\n",
      " 1.05790632 1.         1.05783478 0.98691424 1.00003701 0.98605885\n",
      " 0.99447267 1.0582927  1.05792849 1.05792959 1.05790065 0.99380032\n",
      " 1.00000341 1.00000421 1.0000239 ]\n",
      "[[1.17273766 0.83051448 1.06401611 1.00062431 1.16131996 1.09595516\n",
      "  1.22448623 1.08597632 1.20167595 1.11945826 0.98357063 1.12156253\n",
      "  0.97456607 1.13358564 1.09563676 1.09685765 0.85411085 0.91993331\n",
      "  1.11433492 0.83639708 1.08995831 0.95468981 0.9962058  1.17386709\n",
      "  0.8781192  1.23280322 1.12283704 1.12326115 1.11217582 0.99657897\n",
      "  0.8206023  0.83715725 0.96188807]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "[1.05828355 0.9825313  1.05779716 1.         1.05803581 1.057855\n",
      " 1.05825884 1.05804468 1.05837884 1.05791969 1.         1.05814521\n",
      " 0.99247407 1.05817498 1.05807813 1.05785781 0.99723498 1.\n",
      " 1.05790632 1.         1.05783478 0.98691424 1.00003701 0.98605885\n",
      " 0.99447267 1.0582927  1.05792849 1.05792959 1.05790065 0.99380032\n",
      " 1.00000341 1.00000421 1.0000239 ]\n",
      "[[1.17273766 0.83051448 1.06401611 1.00062431 1.16131996 1.09595516\n",
      "  1.22448623 1.08597632 1.20167595 1.11945826 0.98357063 1.12156253\n",
      "  0.97456607 1.13358564 1.09563676 1.09685765 0.85411085 0.91993331\n",
      "  1.11433492 0.83639708 1.08995831 0.95468981 0.9962058  1.17386709\n",
      "  0.8781192  1.23280322 1.12283704 1.12326115 1.11217582 0.99657897\n",
      "  0.8206023  0.83715725 0.96188807]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "acc 0.6576576576576577\n",
      "[[290 302]\n",
      " [  2 294]]\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print(\"alpha-mean\",i)\n",
    "    predicted_labels=train_nl_s(0.01/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                           tf.truncated_normal_initializer(i,0.001,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 151207.9510220813\n",
      "[0.80989634 0.67315788 0.68017891 0.78008226 0.78229886 0.7209384\n",
      " 0.73905133 0.6777094  0.68313512 0.78145473 0.77970013 0.68498014\n",
      " 0.81359542 0.6657093  0.8115127  0.78098404 0.74263401 0.77820079\n",
      " 0.78134898 0.76310889 0.71415314 0.64373272 0.76641697 0.67630578\n",
      " 0.67339027 0.78366627 0.75220351 0.75261417 0.73701073 0.67243256\n",
      " 0.72924456 0.73752678 0.71826069]\n",
      "[[1.019613   0.84043425 1.03121076 0.91986869 1.02490664 1.02395617\n",
      "  1.14220693 1.05554699 1.16671749 0.98351553 0.90294608 1.08432899\n",
      "  0.88295845 1.11028577 0.94208126 0.96118012 0.81351358 0.83984537\n",
      "  0.97845085 0.77795277 1.02472561 0.99854039 0.93630415 1.18525401\n",
      "  0.90046597 1.09560349 1.0256237  1.02858404 1.03157643 0.99170345\n",
      "  0.80039274 0.79720836 0.94816149]]\n",
      "acc 0.5168918918918919\n",
      "(0.4008941877794337, 0.9087837837837838, 0.5563598759048605, None)\n",
      "\n",
      "1 loss 149935.3607799438\n",
      "[0.90312327 0.65495563 0.66771003 0.75200622 0.77560989 0.74365941\n",
      " 0.75377123 0.66211804 0.67236441 0.76624852 0.74830646 0.67738822\n",
      " 0.90712696 0.61033613 0.90492723 0.76120706 0.80001801 0.73496257\n",
      " 0.76510302 0.75839459 0.73784346 0.57970352 0.77741609 0.6578106\n",
      " 0.65306996 0.79118822 0.76615915 0.76535412 0.75061421 0.61447491\n",
      " 0.75766262 0.76664419 0.73614902]\n",
      "[[0.9352901  0.86331554 1.04906189 0.84014895 0.94675612 1.00120897\n",
      "  1.12740785 1.07635469 1.18323105 0.90457573 0.82313718 1.09793637\n",
      "  0.79841885 1.15370673 0.85759749 0.88189627 0.77576856 0.76028799\n",
      "  0.89942728 0.76235229 1.00104599 1.06575024 0.91467365 1.20678165\n",
      "  0.92556894 1.01906119 1.00872329 1.01191279 1.01678605 1.02036521\n",
      "  0.78420604 0.774154   0.92985358]]\n",
      "acc 0.4617117117117117\n",
      "(0.38242894056847543, 1.0, 0.5532710280373832, None)\n",
      "\n",
      "2 loss 148359.30984137114\n",
      "[0.98198386 0.63896751 0.65768672 0.64695937 0.6777669  0.77539121\n",
      " 0.76513808 0.64882451 0.66400274 0.66470255 0.64269894 0.67211334\n",
      " 0.98500551 0.53403193 0.98338951 0.65814963 0.84280963 0.62818419\n",
      " 0.663185   0.73548465 0.77731924 0.50907464 0.76690807 0.64201623\n",
      " 0.63345565 0.70193213 0.76925111 0.76784181 0.76109419 0.53480538\n",
      " 0.78246081 0.78572581 0.7607043 ]\n",
      "[[0.87616534 0.88502818 1.06555353 0.72973571 0.83540497 0.96901062\n",
      "  1.11328082 1.09590159 1.19840561 0.7933952  0.71302735 1.11029392\n",
      "  0.74111266 1.21733873 0.79922507 0.77091703 0.75060292 0.65172953\n",
      "  0.78828577 0.75549016 0.96138264 1.13965599 0.90412504 1.22830107\n",
      "  0.9508771  0.90799413 0.99680788 1.00105722 1.00255896 1.08972317\n",
      "  0.76454146 0.76105467 0.90406182]]\n",
      "acc 0.356981981981982\n",
      "(0.3414071510957324, 1.0, 0.5090283748925193, None)\n",
      "\n",
      "3 loss 146280.00858372104\n",
      "[1.         0.62480832 0.64959372 0.53691694 0.56562833 0.81379011\n",
      " 0.77516864 0.63743601 0.6575112  0.55314452 0.53306578 0.66853986\n",
      " 1.         0.44150955 1.         0.54709458 0.87412338 0.51996041\n",
      " 0.55173455 0.70824031 0.82622715 0.49703497 0.75001327 0.62852756\n",
      " 0.61473598 0.59194146 0.7691256  0.76543131 0.77030044 0.44162732\n",
      " 0.81125952 0.79996033 0.78917212]\n",
      "[[0.87141737 0.90575157 1.08095832 0.62540205 0.72768324 0.93027282\n",
      "  1.09968318 1.11436632 1.21252768 0.68681337 0.60945934 1.12172711\n",
      "  0.73765955 1.2979126  0.79509226 0.66504144 0.7338277  0.55256258\n",
      "  0.68185804 0.75274292 0.91278787 1.21429998 0.89838776 1.24981291\n",
      "  0.97596012 0.79892912 0.98781941 0.99368249 0.98909661 1.1779405\n",
      "  0.74434092 0.75323807 0.8742924 ]]\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 143666.55600076722\n",
      "[1.         0.6136251  0.6445791  0.50002714 0.50000889 0.85485124\n",
      " 0.7822709  0.62912672 0.65402054 0.5000444  0.50004387 0.66784306\n",
      " 1.         0.34269944 1.         0.50004566 0.90031873 0.5029805\n",
      " 0.50274618 0.66844175 0.87851644 0.48999755 0.72166117 0.61839875\n",
      " 0.59860662 0.50177492 0.76397505 0.75483317 0.7765343  0.34261328\n",
      " 0.8380305  0.80703945 0.81846037]\n",
      "[[0.87141737 0.9249313  1.09472655 0.63858106 0.68465968 0.88907246\n",
      "  1.08768302 1.13117118 1.22505599 0.66630835 0.63180144 1.13167098\n",
      "  0.73765955 1.38966655 0.79509226 0.65639017 0.7206319  0.60458295\n",
      "  0.66432207 0.75857867 0.86153348 1.28804447 0.89968009 1.27131332\n",
      "  0.99974421 0.72130723 0.98234762 0.99117106 0.97746853 1.27472238\n",
      "  0.73141149 0.74997432 0.84349917]]\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[1.         0.6136251  0.6445791  0.50002714 0.50000889 0.85485124\n",
      " 0.7822709  0.62912672 0.65402054 0.5000444  0.50004387 0.66784306\n",
      " 1.         0.34269944 1.         0.50004566 0.90031873 0.5029805\n",
      " 0.50274618 0.66844175 0.87851644 0.48999755 0.72166117 0.61839875\n",
      " 0.59860662 0.50177492 0.76397505 0.75483317 0.7765343  0.34261328\n",
      " 0.8380305  0.80703945 0.81846037]\n",
      "[[0.87141737 0.9249313  1.09472655 0.63858106 0.68465968 0.88907246\n",
      "  1.08768302 1.13117118 1.22505599 0.66630835 0.63180144 1.13167098\n",
      "  0.73765955 1.38966655 0.79509226 0.65639017 0.7206319  0.60458295\n",
      "  0.66432207 0.75857867 0.86153348 1.28804447 0.89968009 1.27131332\n",
      "  0.99974421 0.72130723 0.98234762 0.99117106 0.97746853 1.27472238\n",
      "  0.73141149 0.74997432 0.84349917]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=train_nl_s(0.1/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                           tf.truncated_normal_initializer(0.7,0.001,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 177593.6089042592\n",
      "[0.41854278 0.11520687 0.31047011 0.30153524 0.40736582 0.34136772\n",
      " 0.47013164 0.33035577 0.44548349 0.36387167]\n",
      "[[1.11655652 0.81322315 1.00867167 0.99972798 1.10542697 1.04178828\n",
      "  1.16826229 1.03197667 1.14706397 1.06550782]]\n",
      "acc 0.9068941009239516\n",
      "(0.26143790849673204, 0.21164021164021163, 0.23391812865497075, None)\n",
      "\n",
      "1 loss 177396.56970193452\n",
      "[0.41954094 0.11619926 0.31138325 0.30244885 0.40835387 0.3413951\n",
      " 0.47105875 0.32949968 0.44462813 0.36301599]\n",
      "[[1.11556877 0.8122317  1.00778122 0.99882951 1.10447602 1.04224007\n",
      "  1.16731925 1.0327495  1.14779659 1.06629769]]\n",
      "acc 0.9086709310589908\n",
      "(0.2702702702702703, 0.21164021164021163, 0.2373887240356083, None)\n",
      "\n",
      "2 loss 177199.12666951108\n",
      "[0.42053909 0.11719167 0.3122979  0.30336394 0.409342   0.34142099\n",
      " 0.47198704 0.32864074 0.44376979 0.36215742]\n",
      "[[1.11458114 0.81124022 1.00688941 0.99792959 1.10352504 1.04269297\n",
      "  1.16637726 1.03352561 1.14853279 1.06709081]]\n",
      "acc 0.9136460554371002\n",
      "(0.29850746268656714, 0.21164021164021163, 0.24767801857585137, None)\n",
      "\n",
      "3 loss 177001.28635498337\n",
      "[0.42153725 0.11818411 0.31321404 0.30428052 0.4103302  0.34144541\n",
      " 0.4729165  0.327779   0.44290854 0.36129601]\n",
      "[[1.11359362 0.81024869 1.00599624 0.99702825 1.10257402 1.04314696\n",
      "  1.16543643 1.03430495 1.14927251 1.06788713]]\n",
      "acc 0.9175550817341862\n",
      "(0.31932773109243695, 0.20105820105820105, 0.24675324675324675, None)\n",
      "\n",
      "4 loss 176803.0511289301\n",
      "[0.42253541 0.11917658 0.31413164 0.30519854 0.41131849 0.3414684\n",
      " 0.47384712 0.32691451 0.44204442 0.36043183]\n",
      "[[1.11260622 0.80925713 1.00510178 0.99612552 1.10162297 1.043602\n",
      "  1.16449689 1.03508745 1.15001569 1.06868658]]\n",
      "acc 0.9193319118692252\n",
      "(0.33035714285714285, 0.19576719576719576, 0.24584717607973422, None)\n",
      "\n",
      "[0.42253541 0.11917658 0.31413164 0.30519854 0.41131849 0.3414684\n",
      " 0.47384712 0.32691451 0.44204442 0.36043183]\n",
      "[[1.11260622 0.80925713 1.00510178 0.99612552 1.10162297 1.043602\n",
      "  1.16449689 1.03508745 1.15001569 1.06868658]]\n",
      "{0: 2702, 1: 112}\n",
      "acc 0.9193319118692252\n",
      "acc 0.9193319118692252\n",
      "[[2550   75]\n",
      " [ 152   37]]\n",
      "(0.33035714285714285, 0.19576719576719576, 0.24584717607973422, None)\n"
     ]
    }
   ],
   "source": [
    "# for i in np.linspace(0,1,11):\n",
    "#     print(\"alpha-mean\",i)\n",
    "#     predicted_labels=train_nl_s(0.001/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,12),\\\n",
    "#                            tf.truncated_normal_initializer(i,0.1,12))\n",
    "    \n",
    "predicted_labels=train_nl_s(0.001/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,12),\\\n",
    "                           tf.truncated_normal_initializer(0.3,0.1,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 155264.53954891075\n",
      "[0.92690352 0.9971321  0.89117171 0.89079329 0.90543897 0.98363892\n",
      " 0.9542917  0.89181359 0.8937952  0.91162108]\n",
      "[[1.10009277 0.72704278 1.03085428 1.02047423 1.10633782 0.96621163\n",
      "  1.12864769 1.05197377 1.16535794 1.05758622]]\n",
      "acc 0.8941009239516702\n",
      "(0.33126934984520123, 0.5661375661375662, 0.41796875, None)\n",
      "\n",
      "1 loss 154352.82584004718\n",
      "[0.94538075 1.00003227 0.88239876 0.88170429 0.90954794 0.99722517\n",
      " 0.98051568 0.88340816 0.88622291 0.92065953]\n",
      "[[1.0884174  0.72649249 1.05094155 1.03924606 1.10629312 0.95459477\n",
      "  1.11214221 1.07165552 1.18340155 1.05207841]]\n",
      "acc 0.8948116560056859\n",
      "(0.3333333333333333, 0.5661375661375662, 0.41960784313725485, None)\n",
      "\n",
      "2 loss 154345.657013675\n",
      "[0.95711568 1.00017134 0.87422725 0.87406136 0.91291265 0.99776011\n",
      " 0.99031907 0.87564378 0.87869541 0.92818664]\n",
      "[[1.08146765 0.72632277 1.06995853 1.0570634  1.10656614 0.94945574\n",
      "  1.10669314 1.09036948 1.20057795 1.04758399]]\n",
      "acc 0.8941009239516702\n",
      "(0.3333333333333333, 0.5767195767195767, 0.42248062015503873, None)\n",
      "\n",
      "3 loss 154341.1192211615\n",
      "[0.96473516 1.00014065 0.87002874 0.86936931 0.91573331 0.99703065\n",
      " 0.99419881 0.87566606 0.87567845 0.93511696]\n",
      "[[1.0772874  0.72628999 1.0882641  1.07415257 1.10708575 0.9450955\n",
      "  1.10472967 1.1084319  1.21700396 1.04402819]]\n",
      "acc 0.8862828713574982\n",
      "(0.3154929577464789, 0.5925925925925926, 0.411764705882353, None)\n",
      "\n",
      "4 loss 154338.10484061058\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "acc 0.8791755508173419\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n",
      "\n",
      "[0.96998981 1.00014084 0.86469124 0.86383808 0.91809031 0.99519522\n",
      " 0.9964329  0.87568057 0.87567871 0.94170222]\n",
      "[[1.07469848 0.72623898 1.10667907 1.09119193 1.10790566 0.92861019\n",
      "  1.10381286 1.12572771 1.23273514 1.04161097]]\n",
      "{0: 2407, 1: 407}\n",
      "acc 0.8791755508173419\n",
      "acc 0.8791755508173419\n",
      "[[2346  279]\n",
      " [  61  128]]\n",
      "(0.3144963144963145, 0.6772486772486772, 0.42953020134228187, None)\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=train_nl_s(0.1/len(train_L_S),5,\\\n",
    "                            tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            tf.truncated_normal_initializer(0.9,0.001,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 155548.10499263214\n",
      "[0.93326346 0.98037827 0.88953763 0.88821575 0.91311962 0.98554735\n",
      " 0.96406621 0.89759127 0.90964637 0.91662847]\n",
      "[[1.1032539  0.72197787 1.03206361 1.02162306 1.10767904 0.96823482\n",
      "  1.13417441 1.05126276 1.16661986 1.05815618]]\n",
      "acc 0.8855721393034826\n",
      "(0.3147632311977716, 0.5978835978835979, 0.41240875912408764, None)\n",
      "\n",
      "1 loss 154383.652287932\n",
      "[0.94953699 1.00003838 0.8767362  0.87537624 0.91583377 0.99209049\n",
      " 0.98585481 0.89384701 0.90618009 0.92479421]\n",
      "[[1.09328744 0.7103856  1.05400886 1.04201962 1.10870954 0.92510664\n",
      "  1.12145815 1.06944685 1.18536492 1.05320904]]\n",
      "acc 0.8855721393034826\n",
      "(0.3147632311977716, 0.5978835978835979, 0.41240875912408764, None)\n",
      "\n",
      "2 loss 154346.07266892138\n",
      "[0.96029182 1.00012677 0.86560251 0.86458486 0.91794999 0.98825132\n",
      " 0.99431731 0.89279564 0.90488922 0.93167133]\n",
      "[[1.08722855 0.71028976 1.07575335 1.06207778 1.11012153 0.84748815\n",
      "  1.11739958 1.08540677 1.20247734 1.04934008]]\n",
      "acc 0.8781094527363185\n",
      "(0.3121951219512195, 0.6772486772486772, 0.42737896494156924, None)\n",
      "\n",
      "3 loss 154338.96566033977\n",
      "[0.96760865 1.00012473 0.85225636 0.85189594 0.9194952  0.98042366\n",
      " 0.99813295 0.89525075 0.90660047 0.93801452]\n",
      "[[1.08354231 0.71012754 1.09771802 1.0821421  1.11199203 0.7512131\n",
      "  1.11605471 1.09861973 1.21776018 1.04669099]]\n",
      "acc 0.8742004264392325\n",
      "(0.3049645390070922, 0.6825396825396826, 0.4215686274509804, None)\n",
      "\n",
      "4 loss 154328.02467496082\n",
      "[0.97290781 1.00012272 0.83648652 0.83773746 0.92044744 0.96624436\n",
      " 0.99960116 0.90305713 0.91281119 0.94217553]\n",
      "[[1.08125315 0.70990132 1.12052711 1.10269218 1.11442038 0.64725766\n",
      "  1.11577799 1.107643   1.23052228 1.04508611]]\n",
      "acc 0.8567874911158493\n",
      "(0.27983539094650206, 0.7195767195767195, 0.40296296296296297, None)\n",
      "\n",
      "[0.97290781 1.00012272 0.83648652 0.83773746 0.92044744 0.96624436\n",
      " 0.99960116 0.90305713 0.91281119 0.94217553]\n",
      "[[1.08125315 0.70990132 1.12052711 1.10269218 1.11442038 0.64725766\n",
      "  1.11577799 1.107643   1.23052228 1.04508611]]\n",
      "{0: 2328, 1: 486}\n",
      "acc 0.8567874911158493\n",
      "acc 0.8567874911158493\n",
      "[[2275  350]\n",
      " [  53  136]]\n",
      "(0.27983539094650206, 0.7195767195767195, 0.40296296296296297, None)\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=train_nl_s(0.1/len(train_L_S),5,\\\n",
    "                            tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            tf.truncated_normal_initializer(0.9,0.01,seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## normalized model with smooth LFs + penalties\n",
    "\n",
    "def train(lr,ep,th,af,plv=np.array([-1,1],dtype=np.float64),smooth=True,penalty=0,p3k=3):\n",
    "    \n",
    "    ## lr : learning rate\n",
    "    ## ep : no of epochs\n",
    "    ## th : thetas initializer\n",
    "    ## af : alphas initializer\n",
    "    ## penalty : {1,2,3} use one of the three penalties, 0: no-penalty\n",
    "    ## p3k : parameter for penalty-3 \n",
    "    ## smooth : flag if smooth lfs are used \n",
    "    ## make sure smooth/discrete LF data is loaded into train_L_S and test_L_S\n",
    "    ## plv : all possible label values = [-1,1] for binary, \n",
    "    ##       np.arange(0,NoOfClasses) for multiclass\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "#         print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],\\\n",
    "                                 initializer=af,\\\n",
    "                                 dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],\\\n",
    "                                initializer=th,\\\n",
    "                        dtype=tf.float64)\n",
    "\n",
    "#         print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "#         print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "#         print(alphas)\n",
    "#         print(s)\n",
    "#         print(\"l\",l)\n",
    "#         print(s.graph)\n",
    "\n",
    "        s_ = tf.maximum(tf.subtract(s,alphas), 0)\n",
    "#         print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "    \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),-tf.ones_like(v))\n",
    "#             print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        if(smooth):\n",
    "            pout = tf.map_fn(lambda c: iskequalsy(l,c)*s_ ,plv,name=\"pout\")\n",
    "        else:\n",
    "            pout = tf.map_fn(lambda c: iskequalsy(l,c) ,plv,name=\"pout\")\n",
    "\n",
    "#         print(\"pout\",pout)    \n",
    "\n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,\\\n",
    "                           name=\"t_pout\")\n",
    "    \n",
    "#         print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "#         print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "#             print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "#             print(\"intsy\",out1)\n",
    "            return out1\n",
    "                \n",
    "\n",
    "        if(smooth):\n",
    "            #smooth normalizer\n",
    "            zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "                           plv,name=\"zy\")\n",
    "        else:\n",
    "            #discrete normalizer\n",
    "            zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),\\\n",
    "                           plv,name=\"zy\")\n",
    "\n",
    "    \n",
    "# \n",
    "#         zy = tf.map_fn(lambda y: tf.reduce_prod(1+ints(y),axis=0),\\\n",
    "#                        np.array(NoOfClasses,dtype=np.float64))\n",
    "        \n",
    "#         print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        \n",
    "#         print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "#         print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "\n",
    "        if(penalty == 1):\n",
    "            normloss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                      +tf.reduce_sum(tf.maximum(tf.zeros_like(thetas),-thetas))\n",
    "        elif(penalty == 2):\n",
    "            normloss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     -tf.minimum( tf.reduce_min(thetas),0.0)\n",
    "        elif(penalty == 3):\n",
    "             normloss = tf.negative(tf.reduce_sum(lsp  - logz  )) \\\n",
    "                     +tf.reduce_sum(tf.log(1+tf.exp(-thetas-pk)))\n",
    "        else:\n",
    "             normloss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "   \n",
    "        tf.summary.scalar('un-normloss', normloss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "#         print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "#         print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(normloss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',\n",
    "                                      tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "                tl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    while True:\n",
    "                        sm,_,ls,t = sess.run([summary_merged,train_step,normloss,thetas])\n",
    "#                         print(t)\n",
    "#                         print(tl)\n",
    "                        train_writer.add_summary(sm, it)\n",
    "#                         if(ls<1e-5):\n",
    "#                             break\n",
    "                        tl = tl + ls\n",
    "                        it = it + 1\n",
    "                        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                print(en,\"loss\",tl)\n",
    "\n",
    "                sess.run(dev_init_op)\n",
    "                sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                test_writer.add_summary(sm, en)\n",
    "                print(a)\n",
    "                print(t)\n",
    "                unique, counts = np.unique(pl, return_counts=True)\n",
    "                print(dict(zip(unique, counts)))\n",
    "                print(\"acc\",accuracy_score(true_labels,pl))\n",
    "                print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "                print()\n",
    "\n",
    "            # Initialize an iterator over the validation dataset.\n",
    "            sess.run(dev_init_op)\n",
    "            a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "            print(a)\n",
    "            print(t)\n",
    "\n",
    "            unique, counts = np.unique(pl, return_counts=True)\n",
    "            print(dict(zip(unique, counts)))\n",
    "\n",
    "            print(\"acc\",accuracy_score(true_labels,pl))\n",
    "\n",
    "            predictAndPrint(pl)\n",
    "            print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "\n",
    "#             cf = confusion_matrix(true_labels,pl)\n",
    "#             print(cf)\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alpha-mean 0.0\n",
      "0 loss 258761.97377532846\n",
      "[ 0.09760699  0.06906155  0.07856466  0.09640611  0.09653547  0.09181254\n",
      "  0.09855085  0.07455734  0.07604416  0.09698834  0.09583047  0.07974186\n",
      "  0.10121241 -0.07568579  0.10015734  0.09719328  0.09931358  0.09386556\n",
      "  0.09543832  0.09541713  0.08916486 -0.03168285  0.09725393  0.07409003\n",
      "  0.06457212  0.09928821  0.09774973  0.09802521  0.09776105 -0.07706665\n",
      "  0.08102752  0.08125664  0.09399042]\n",
      "[[1.02183361 0.76346911 0.94839377 0.90496805 1.01156448 0.95517189\n",
      "  1.07388363 0.97576553 1.08656111 0.9691725  0.8882573  1.00127791\n",
      "  0.88250813 1.14733461 0.9423475  0.94631146 0.7545906  0.82570798\n",
      "  0.96529566 0.74009843 0.95249652 0.98549148 0.89985832 1.18311283\n",
      "  0.82864581 1.08103604 0.97220814 0.97224309 0.96137654 1.06089836\n",
      "  0.74204982 0.75805573 0.87081834]]\n",
      "{0: 167, 1: 721}\n",
      "acc 0.48761261261261263\n",
      "(0.3897364771151179, 0.9493243243243243, 0.5526057030481809, None)\n",
      "\n",
      "1 loss 223371.00639377302\n",
      "[ 0.19647516  0.1519857   0.16648469  0.19038969  0.18918612  0.18395212\n",
      "  0.19399375  0.15964104  0.16129418  0.19102225  0.18939546  0.16790559\n",
      "  0.20280651 -0.16092707  0.20087866  0.19187094  0.20040893  0.18803963\n",
      "  0.18972917  0.19066719  0.18054434 -0.04452787  0.19282655  0.15847535\n",
      "  0.14319498  0.19514014  0.19325478  0.19370261  0.19339747 -0.16272355\n",
      "  0.17000854  0.17029359  0.18790867]\n",
      "[[0.92422811 0.70108518 0.87740922 0.81280508 0.92055062 0.86810577\n",
      "  0.9811532  0.90956673 1.0161723  0.87703279 0.79642362 0.9266091\n",
      "  0.7825432  1.23083042 0.84317377 0.85363248 0.65548859 0.73324008\n",
      "  0.87288121 0.64668454 0.86546838 1.02288967 0.80644604 1.20240231\n",
      "  0.77250356 0.98754902 0.87906643 0.87885242 0.86826633 1.14535351\n",
      "  0.65338541 0.66930483 0.7807789 ]]\n",
      "{0: 29, 1: 859}\n",
      "acc 0.36599099099099097\n",
      "(0.3445867287543655, 1.0, 0.5125541125541125, None)\n",
      "\n",
      "2 loss 193922.88978011662\n",
      "[ 0.2946576   0.23959505  0.25746836  0.28381212  0.28041427  0.27915816\n",
      "  0.29012996  0.24874666  0.25045017  0.28451075  0.28219145  0.25898189\n",
      "  0.30270333 -0.25170085  0.30024098  0.28638661  0.29981208  0.28359156\n",
      "  0.28556467  0.2862949   0.27583394 -0.03101568  0.28885025  0.24758642\n",
      "  0.22754103  0.29145259  0.28935869  0.28985841  0.28956579 -0.25382674\n",
      "  0.26460058  0.26493675  0.28350794]\n",
      "[[0.82763529 0.63270445 0.80225977 0.72359184 0.83330489 0.78356884\n",
      "  0.89142496 0.83821826 0.94092889 0.78784029 0.70778174 0.84810106\n",
      "  0.68466087 1.32271212 0.74572652 0.76351628 0.55831023 0.64192663\n",
      "  0.78151366 0.55537281 0.78005952 1.04577924 0.71512596 1.2216414\n",
      "  0.71011642 0.89603004 0.78806916 0.78773768 0.77869428 1.2381653\n",
      "  0.55999917 0.57579866 0.69555217]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "3 loss 169903.04201030626\n",
      "[ 0.39171153  0.32772588  0.34847705  0.37779872  0.37149508  0.37697203\n",
      "  0.38792563  0.33817995  0.33988805  0.37860099  0.37540988  0.35003129\n",
      "  0.40117856 -0.34548008  0.39828858  0.38180781  0.39770716  0.38084616\n",
      "  0.38312072  0.38327206  0.37369065 -0.00226998  0.38629702  0.3372383\n",
      "  0.312861    0.38919055  0.38699197  0.38746515  0.38726639 -0.34784447\n",
      "  0.36167028  0.3620561   0.38119881]\n",
      "[[0.73339451 0.56636063 0.72994083 0.6404072  0.75319321 0.71226354\n",
      "  0.81275537 0.76932826 0.8677145  0.70464457 0.62557067 0.77200976\n",
      "  0.5898284  1.41709659 0.65109111 0.67881457 0.4642848  0.55455132\n",
      "  0.69406063 0.46969341 0.70558    1.05927275 0.6294628  1.24125649\n",
      "  0.64945384 0.80895106 0.70526597 0.70321057 0.70082521 1.33399816\n",
      "  0.46729925 0.48251793 0.62625581]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 150478.0547851803\n",
      "[ 0.48804488  0.41541092  0.43897188  0.47342714  0.46360946  0.47612111\n",
      "  0.48744362  0.42712082  0.42877802  0.47424854  0.47018055  0.44052177\n",
      "  0.4989072  -0.44040069  0.49561164  0.47905543  0.49472371  0.48041845\n",
      "  0.48273442  0.48275682  0.47269496  0.03160539  0.48585126  0.42631747\n",
      "  0.39778753  0.48894603  0.48650732  0.48704734  0.48677888 -0.44294568\n",
      "  0.45928785  0.45972133  0.4804336 ]\n",
      "[[0.64373711 0.50943642 0.66798023 0.63155131 0.72899961 0.66434651\n",
      "  0.79244338 0.71037431 0.80308335 0.69414276 0.61254207 0.70495354\n",
      "  0.50126951 1.51130039 0.56212054 0.67631997 0.37716316 0.55682755\n",
      "  0.69486188 0.46539142 0.64801503 1.07004934 0.62460854 1.26147546\n",
      "  0.59760582 0.81708243 0.68996374 0.69475092 0.68158789 1.43016967\n",
      "  0.37861081 0.39255788 0.58983833]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[ 0.48804488  0.41541092  0.43897188  0.47342714  0.46360946  0.47612111\n",
      "  0.48744362  0.42712082  0.42877802  0.47424854  0.47018055  0.44052177\n",
      "  0.4989072  -0.44040069  0.49561164  0.47905543  0.49472371  0.48041845\n",
      "  0.48273442  0.48275682  0.47269496  0.03160539  0.48585126  0.42631747\n",
      "  0.39778753  0.48894603  0.48650732  0.48704734  0.48677888 -0.44294568\n",
      "  0.45928785  0.45972133  0.4804336 ]\n",
      "[[0.64373711 0.50943642 0.66798023 0.63155131 0.72899961 0.66434651\n",
      "  0.79244338 0.71037431 0.80308335 0.69414276 0.61254207 0.70495354\n",
      "  0.50126951 1.51130039 0.56212054 0.67631997 0.37716316 0.55682755\n",
      "  0.69486188 0.46539142 0.64801503 1.07004934 0.62460854 1.26147546\n",
      "  0.59760582 0.81708243 0.68996374 0.69475092 0.68158789 1.43016967\n",
      "  0.37861081 0.39255788 0.58983833]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.1\n",
      "0 loss 234151.0249429247\n",
      "[0.19806045 0.17301418 0.18142486 0.19625912 0.19624729 0.19126569\n",
      " 0.19848645 0.17789195 0.17930346 0.19683213 0.19564832 0.18255269\n",
      " 0.20088443 0.0270292  0.20009142 0.19709826 0.19905759 0.19369319\n",
      " 0.19528246 0.1954141  0.18820886 0.0759723  0.1972427  0.17741569\n",
      " 0.16916418 0.19927373 0.19771028 0.19800886 0.19771434 0.02561138\n",
      " 0.17918176 0.17941287 0.1936894 ]\n",
      "[[1.02197974 0.76605671 0.95114066 0.90567352 1.01230799 0.95745409\n",
      "  1.07473267 0.97857589 1.08884084 0.96988075 0.88897396 1.00345416\n",
      "  0.88307601 1.14544416 0.94277432 0.94700273 0.75525368 0.82633383\n",
      "  0.96588505 0.74078055 0.9551535  0.98543526 0.9005408  1.18350274\n",
      "  0.83097049 1.08170613 0.97296341 0.9729511  0.96213915 1.05915984\n",
      "  0.74376368 0.7596745  0.87238416]]\n",
      "{0: 164, 1: 724}\n",
      "acc 0.48873873873873874\n",
      "(0.39088397790055246, 0.956081081081081, 0.5549019607843136, None)\n",
      "\n",
      "1 loss 202293.79076913805\n",
      "[ 0.29633312  0.25646121  0.26945875  0.29061716  0.28913602  0.28385634\n",
      "  0.29442709  0.26324653  0.26476338  0.29123788  0.28956897  0.27080788\n",
      "  0.30173722 -0.0582902   0.30012043  0.2922028   0.29942775  0.28840537\n",
      "  0.29013231  0.29120377  0.27983681  0.06663689  0.29333455  0.26191806\n",
      "  0.24859525  0.29562671  0.29372575  0.29419763  0.29385473 -0.06013638\n",
      "  0.26838162  0.26866503  0.28808792]\n",
      "[[0.92558255 0.70960923 0.88580345 0.81465603 0.92243589 0.87310954\n",
      "  0.98342668 0.91830895 1.02354212 0.87888213 0.79828355 0.93360591\n",
      "  0.78458055 1.22912724 0.84498264 0.85546667 0.65784621 0.73488196\n",
      "  0.87444929 0.64852353 0.87066746 1.02551035 0.80829743 1.20335434\n",
      "  0.78081279 0.98936231 0.88103513 0.88076439 0.8705265  1.14401382\n",
      "  0.65557702 0.67137609 0.78475537]]\n",
      "{0: 26, 1: 862}\n",
      "acc 0.36261261261261263\n",
      "(0.3433874709976798, 1.0, 0.5112262521588946, None)\n",
      "\n",
      "2 loss 175533.05271583927\n",
      "[ 0.39399893  0.34324944  0.35967425  0.38475691  0.3810985   0.37994033\n",
      "  0.39127384  0.3514828   0.35299229  0.38544069  0.3831095   0.36109074\n",
      "  0.4012485  -0.15099684  0.3990543   0.38741563  0.39844924  0.38472574\n",
      "  0.38670949  0.38755763  0.37593423  0.07690643  0.39004894  0.34983795\n",
      "  0.33196272  0.39259736  0.39052572  0.39103666  0.39073402 -0.15313549\n",
      "  0.36387438  0.36420277  0.38451761]\n",
      "[[0.83085091 0.65101698 0.8197448  0.72902556 0.83856778 0.79613412\n",
      "  0.89987649 0.8565362  0.95650241 0.79326028 0.71320466 0.86289305\n",
      "  0.68892434 1.32208215 0.74963543 0.76900216 0.56330413 0.64709865\n",
      "  0.78658431 0.56131816 0.79135539 1.05527011 0.72108468 1.22335252\n",
      "  0.72865196 0.90159971 0.79473472 0.794121   0.78753797 1.23818776\n",
      "  0.5631469  0.57872829 0.70822198]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "3 loss 153504.6710651051\n",
      "[ 0.49079595  0.43054184  0.44999249  0.48004811  0.47349885  0.47840345\n",
      "  0.48994812  0.44004329  0.4414753   0.48075971  0.47767939  0.45140322\n",
      "  0.49969472 -0.24661173  0.49699407  0.48405046  0.49635495  0.48321897\n",
      "  0.48530714  0.48593004  0.474362    0.09947125  0.48864668  0.43814224\n",
      "  0.41610549  0.49135164  0.48916367  0.48967381  0.48940711 -0.2489423\n",
      "  0.4614217   0.46178651  0.48302099]\n",
      "[[0.7412063  0.6006368  0.76339556 0.70084217 0.80057204 0.74336277\n",
      "  0.86609425 0.80367079 0.89722222 0.76396928 0.68263829 0.80078717\n",
      "  0.60028946 1.4172311  0.66061852 0.74452504 0.47658257 0.62246347\n",
      "  0.76056558 0.53234921 0.7300805  1.07793317 0.6954208  1.24378651\n",
      "  0.68391885 0.88288476 0.76258166 0.76427225 0.75441797 1.33493107\n",
      "  0.47368629 0.48829136 0.66505913]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 138523.98775712954\n",
      "[ 0.5602053   0.50343247  0.51344918  0.50000187  0.49999928  0.50421818\n",
      "  0.5000555   0.50739956  0.50934464  0.50000749  0.50000431  0.51573239\n",
      "  0.56746183 -0.3446829   0.56547963  0.50000566  0.56207707  0.50006539\n",
      "  0.50000547  0.50000899  0.51795251  0.1253196   0.50000197  0.50650459\n",
      "  0.4997416   0.49999926  0.50000526  0.50000553  0.50000201 -0.34710491\n",
      "  0.55369338  0.55406966  0.5000126 ]\n",
      "[[0.64830637 0.57666777 0.73478767 0.80969558 0.90884397 0.71466229\n",
      "  0.90561205 0.77794869 0.86317243 0.87249748 0.79137359 0.76454098\n",
      "  0.50630698 1.51307173 0.56700173 0.85262496 0.38934544 0.73095721\n",
      "  0.86870064 0.62683561 0.68649793 1.09948216 0.7899793  1.26478914\n",
      "  0.66228444 0.98915907 0.82894058 0.84362068 0.79504378 1.43268159\n",
      "  0.39154064 0.40380571 0.65562618]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[ 0.5602053   0.50343247  0.51344918  0.50000187  0.49999928  0.50421818\n",
      "  0.5000555   0.50739956  0.50934464  0.50000749  0.50000431  0.51573239\n",
      "  0.56746183 -0.3446829   0.56547963  0.50000566  0.56207707  0.50006539\n",
      "  0.50000547  0.50000899  0.51795251  0.1253196   0.50000197  0.50650459\n",
      "  0.4997416   0.49999926  0.50000526  0.50000553  0.50000201 -0.34710491\n",
      "  0.55369338  0.55406966  0.5000126 ]\n",
      "[[0.64830637 0.57666777 0.73478767 0.80969558 0.90884397 0.71466229\n",
      "  0.90561205 0.77794869 0.86317243 0.87249748 0.79137359 0.76454098\n",
      "  0.50630698 1.51307173 0.56700173 0.85262496 0.38934544 0.73095721\n",
      "  0.86870064 0.62683561 0.68649793 1.09948216 0.7899793  1.26478914\n",
      "  0.66228444 0.98915907 0.82894058 0.84362068 0.79504378 1.43268159\n",
      "  0.39154064 0.40380571 0.65562618]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.2\n",
      "0 loss 210146.77225080357\n",
      "[0.29822143 0.27601338 0.28350503 0.29620341 0.29602698 0.29080942\n",
      " 0.29853916 0.28038252 0.28176266 0.29676785 0.29555458 0.28463166\n",
      " 0.30048075 0.12990602 0.2998761  0.29710466 0.29871152 0.29364502\n",
      " 0.29526395 0.29552969 0.28723665 0.1838378  0.29734823 0.27983713\n",
      " 0.27274573 0.29937619 0.297787   0.29810924 0.29777233 0.12845924\n",
      " 0.27707623 0.27730717 0.29347845]\n",
      "[[1.02265548 0.77181052 0.95699916 0.90672291 1.01336264 0.96110027\n",
      "  1.0760879  0.98452763 1.0940617  0.97092864 0.89002566 1.00847799\n",
      "  0.88418413 1.14328719 0.94373903 0.94804794 0.75660248 0.82724791\n",
      "  0.96674972 0.74184996 0.95924145 0.98658724 0.9016084  1.18393695\n",
      "  0.83637803 1.08274594 0.97414577 0.97406669 0.96337631 1.05721555\n",
      "  0.74586198 0.76162346 0.8749716 ]]\n",
      "{0: 160, 1: 728}\n",
      "acc 0.4864864864864865\n",
      "(0.3901098901098901, 0.9594594594594594, 0.5546875, None)\n",
      "\n",
      "1 loss 181589.2127959817\n",
      "[0.39593973 0.35974424 0.37149339 0.39098608 0.38920507 0.38398024\n",
      " 0.39504016 0.36579204 0.36722451 0.39159556 0.38988317 0.37283561\n",
      " 0.40071123 0.04414306 0.39930557 0.39268485 0.39848275 0.38897228\n",
      " 0.39075531 0.39191015 0.37919652 0.17716995 0.39400796 0.3641306\n",
      " 0.35265752 0.39627748 0.39436677 0.39485837 0.3944672  0.04227441\n",
      " 0.36659458 0.36687253 0.38844906]\n",
      "[[0.9284438  0.72673281 0.9028074  0.81846522 0.92608992 0.8828484\n",
      "  0.98858917 0.93566976 1.03892513 0.88267248 0.80206008 0.94848869\n",
      "  0.78834402 1.22721107 0.84844424 0.85932382 0.66245375 0.73842397\n",
      "  0.87789111 0.65258553 0.87999348 1.03101694 0.81237219 1.20436815\n",
      "  0.79747703 0.99329914 0.88535677 0.8850052  0.87579739 1.14266148\n",
      "  0.65859573 0.67418661 0.79331309]]\n",
      "{0: 12, 1: 876}\n",
      "acc 0.34684684684684686\n",
      "(0.3378995433789954, 1.0, 0.5051194539249148, None)\n",
      "\n",
      "2 loss 157278.2922874035\n",
      "[ 0.49315162  0.44581214  0.46103562  0.48605095  0.48204548  0.48099979\n",
      "  0.49281066  0.45322302  0.45457183  0.48669785  0.48437003  0.4624138\n",
      "  0.49995001 -0.05042218  0.49790465  0.48880676  0.49727555  0.48629564\n",
      "  0.48825558  0.48932841  0.47611394  0.1836553   0.49167853  0.45074667\n",
      "  0.43509345  0.49410679  0.49209862  0.49261898  0.49230144 -0.0525413\n",
      "  0.4629353   0.46324955  0.4858568 ]\n",
      "[[0.83933121 0.68851104 0.85753029 0.76051905 0.86469703 0.82314576\n",
      "  0.93679093 0.89449549 0.99049098 0.82429936 0.74356883 0.89661471\n",
      "  0.70013657 1.32107484 0.75988647 0.8026788  0.57721518 0.67956984\n",
      "  0.81828115 0.5971065  0.81328581 1.06897471 0.75816684 1.2250852\n",
      "  0.7651815  0.93875648 0.83019348 0.83042601 0.8240939  1.23812594\n",
      "  0.56861733 0.58375354 0.73987598]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "3 loss 141364.86228410606\n",
      "[ 0.55840104  0.50541601  0.51407827  0.50000208  0.50000169  0.51480066\n",
      "  0.50006294  0.50908451  0.51192026  0.50000396  0.49999995  0.51715971\n",
      "  0.56348525 -0.14949874  0.56217657  0.50000306  0.55818028  0.50166226\n",
      "  0.50000387  0.49999991  0.52568387  0.19612587  0.49999813  0.50744249\n",
      "  0.50160634  0.50000445  0.50000329  0.50000289  0.50000539 -0.15172981\n",
      "  0.55598382  0.55632095  0.5001192 ]\n",
      "[[0.74634394 0.67788563 0.84075747 0.86465242 0.965088   0.78791927\n",
      "  0.95606335 0.88116283 0.96885639 0.92777251 0.84719887 0.87231698\n",
      "  0.60615607 1.41827933 0.66622903 0.9071016  0.49339448 0.78466113\n",
      "  0.9221556  0.68191987 0.76496903 1.10411461 0.83931382 1.24625249\n",
      "  0.7582831  1.04242113 0.8752167  0.88911818 0.84442386 1.3370845\n",
      "  0.48436894 0.49767572 0.72097298]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 136477.1756647597\n",
      "[ 0.65413073  0.53304596  0.55302018  0.5000027   0.50000351  0.53377791\n",
      "  0.50006546  0.5422389   0.55378022  0.50000718  0.50001152  0.56389066\n",
      "  0.65892146 -0.24833691  0.65776421  0.50000073  0.6491468   0.5007618\n",
      "  0.50000697  0.50000068  0.56268404  0.21005558  0.50000241  0.54049305\n",
      "  0.5206678   0.50001304  0.50000008  0.50001179  0.50000184 -0.25064912\n",
      "  0.64623789  0.64611487  0.50007667]\n",
      "[[0.65208529 0.67645003 0.82990266 0.96591137 1.06645509 0.75431637\n",
      "  0.97866041 0.87522021 0.95498152 1.02909712 0.94844077 0.85427352\n",
      "  0.51182978 1.51529472 0.57194926 1.00840383 0.41193128 0.88577688\n",
      "  1.02342067 0.76564181 0.71796493 1.1390218  0.91970059 1.26754702\n",
      "  0.76366961 1.14387397 0.92252661 0.95127542 0.86866788 1.43567765\n",
      "  0.41111701 0.41905412 0.70432923]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[ 0.65413073  0.53304596  0.55302018  0.5000027   0.50000351  0.53377791\n",
      "  0.50006546  0.5422389   0.55378022  0.50000718  0.50001152  0.56389066\n",
      "  0.65892146 -0.24833691  0.65776421  0.50000073  0.6491468   0.5007618\n",
      "  0.50000697  0.50000068  0.56268404  0.21005558  0.50000241  0.54049305\n",
      "  0.5206678   0.50001304  0.50000008  0.50001179  0.50000184 -0.25064912\n",
      "  0.64623789  0.64611487  0.50007667]\n",
      "[[0.65208529 0.67645003 0.82990266 0.96591137 1.06645509 0.75431637\n",
      "  0.97866041 0.87522021 0.95498152 1.02909712 0.94844077 0.85427352\n",
      "  0.51182978 1.51529472 0.57194926 1.00840383 0.41193128 0.88577688\n",
      "  1.02342067 0.76564181 0.71796493 1.1390218  0.91970059 1.26754702\n",
      "  0.76366961 1.14387397 0.92252661 0.95127542 0.86866788 1.43567765\n",
      "  0.41111701 0.41905412 0.70432923]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.30000000000000004\n",
      "0 loss 186740.5106961482\n",
      "[0.39819197 0.37822567 0.38495679 0.39624273 0.39588392 0.39053083\n",
      " 0.39871938 0.38217542 0.3835678  0.39679969 0.39555521 0.38614299\n",
      " 0.40006862 0.23272214 0.39959107 0.39721409 0.39835371 0.39375036\n",
      " 0.3954208  0.39576374 0.38633441 0.29149336 0.39756954 0.38144359\n",
      " 0.37544491 0.3995936  0.39798361 0.39832582 0.39793247 0.23126598\n",
      " 0.37477584 0.37500297 0.39339871]\n",
      "[[1.02460832 0.78430867 0.96987341 0.90885046 1.01537494 0.96820081\n",
      "  1.07906019 0.99731845 1.10602527 0.97304086 0.89212364 1.02029234\n",
      "  0.88668759 1.1408144  0.94606071 0.95020998 0.7598579  0.82912207\n",
      "  0.96856038 0.7441549  0.96665302 0.98985332 0.90390485 1.18441862\n",
      "  0.84827582 1.0849637  0.9766744  0.97648497 0.9661567  1.05509159\n",
      "  0.74857757 0.7640846  0.88052311]]\n",
      "{0: 143, 1: 745}\n",
      "acc 0.48085585585585583\n",
      "(0.38926174496644295, 0.9797297297297297, 0.5571565802113353, None)\n",
      "\n",
      "1 loss 161143.95313875042\n",
      "[0.49545535 0.46218259 0.47289721 0.49158425 0.48947189 0.4844651\n",
      " 0.49594179 0.46758174 0.4689915  0.49217524 0.49042795 0.47432921\n",
      " 0.49986777 0.14618109 0.4985788  0.49339947 0.49776976 0.48985349\n",
      " 0.4916999  0.49290981 0.47873775 0.28672578 0.49494126 0.46526774\n",
      " 0.45568712 0.49715954 0.49527074 0.49577479 0.49533874 0.14432878\n",
      " 0.46469051 0.46495655 0.48912799]\n",
      "[[0.93819536 0.7640191  0.94203041 0.83466921 0.94034942 0.90628107\n",
      "  1.01120578 0.9739351  1.07532816 0.89865632 0.81780006 0.98556061\n",
      "  0.80100472 1.22481801 0.8600785  0.87619616 0.6792271  0.75414964\n",
      "  0.89339595 0.67159203 0.90005788 1.04089956 0.83134384 1.20543751\n",
      "  0.83289559 1.01121422 0.90496166 0.90468202 0.89832337 1.14121677\n",
      "  0.66348374 0.67865681 0.8184316 ]]\n",
      "{0: 4, 1: 884}\n",
      "acc 0.33783783783783783\n",
      "(0.334841628959276, 1.0, 0.5016949152542373, None)\n",
      "\n",
      "2 loss 145139.2654390534\n",
      "[0.55225905 0.50242051 0.5083472  0.50002078 0.49999861 0.5258019\n",
      " 0.50018774 0.50497098 0.50905444 0.50001664 0.50002155 0.51231883\n",
      " 0.55446273 0.04859852 0.55410625 0.49999873 0.54794247 0.50276472\n",
      " 0.50247454 0.50000739 0.53297315 0.28560593 0.50001792 0.50327074\n",
      " 0.50007727 0.5010695  0.50001507 0.50001097 0.50000424 0.04656071\n",
      " 0.55729164 0.55757681 0.51433659]\n",
      "[[0.84481349 0.76956842 0.94076944 0.89008211 0.97827366 0.8644771\n",
      "  0.99862458 0.97624434 1.07025089 0.94558318 0.87447508 0.97766347\n",
      "  0.70680571 1.32037085 0.76611298 0.92727739 0.60490051 0.81571191\n",
      "  0.94006499 0.70412776 0.84714041 1.09060627 0.84363626 1.22678541\n",
      "  0.84260923 1.03575504 0.90186501 0.9059038  0.88792488 1.23888893\n",
      "  0.57765599 0.59180342 0.78845349]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "3 loss 140563.80782569016\n",
      "[ 0.64873125  0.51227889  0.52935575  0.50001084  0.50001317  0.55994508\n",
      "  0.50014204  0.52047359  0.53332945  0.50001272  0.50001256  0.54121087\n",
      "  0.65083143 -0.05103429  0.65053901  0.50001246  0.635237    0.50261842\n",
      "  0.50189295  0.50000939  0.58048407  0.28594841  0.50000894  0.51799927\n",
      "  0.50340606  0.50062588  0.50000179  0.50000851  0.50001078 -0.0531733\n",
      "  0.64872287  0.64861572  0.53165825]\n",
      "[[0.75010842 0.77757286 0.9398634  0.99725611 1.08785126 0.82404996\n",
      "  0.99420404 0.97982141 1.06666455 1.05411969 0.98133765 0.97030433\n",
      "  0.61192855 1.41825939 0.67132445 1.03531748 0.53238089 0.92133239\n",
      "  1.04800534 0.75854968 0.79543288 1.13931737 0.88534696 1.24816621\n",
      "  0.8566458  1.14772221 0.91234973 0.9251149  0.88576717 1.33846837\n",
      "  0.50115645 0.51090604 0.76111209]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 136512.10152937987\n",
      "[ 0.74475889  0.52829016  0.5552156   0.50000773  0.50000089  0.59046603\n",
      "  0.5000935   0.54133566  0.56185825  0.50000713  0.50000537  0.57393111\n",
      "  0.74662588 -0.15011586  0.74644627  0.50000677  0.72053819  0.50230422\n",
      "  0.50157915  0.50000152  0.62562525  0.28941336  0.50000578  0.53809938\n",
      "  0.51220631  0.5000096   0.50000361  0.50000551  0.50000705 -0.15233725\n",
      "  0.72194107  0.72983704  0.54298518]\n",
      "[[0.65680223 0.78257205 0.93669819 1.10292451 1.19454908 0.78561497\n",
      "  0.99844124 0.98084357 1.06123841 1.16039528 1.08685548 0.96134822\n",
      "  0.51842425 1.51583956 0.57792353 1.14137923 0.46479388 1.02621607\n",
      "  1.1540454  0.82429557 0.74520728 1.18627034 0.94408154 1.26952931\n",
      "  0.86757357 1.25525202 0.93524876 0.96065247 0.89219548 1.43748606\n",
      "  0.45626854 0.45612044 0.73688042]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[ 0.74475889  0.52829016  0.5552156   0.50000773  0.50000089  0.59046603\n",
      "  0.5000935   0.54133566  0.56185825  0.50000713  0.50000537  0.57393111\n",
      "  0.74662588 -0.15011586  0.74644627  0.50000677  0.72053819  0.50230422\n",
      "  0.50157915  0.50000152  0.62562525  0.28941336  0.50000578  0.53809938\n",
      "  0.51220631  0.5000096   0.50000361  0.50000551  0.50000705 -0.15233725\n",
      "  0.72194107  0.72983704  0.54298518]\n",
      "[[0.65680223 0.78257205 0.93669819 1.10292451 1.19454908 0.78561497\n",
      "  0.99844124 0.98084357 1.06123841 1.16039528 1.08685548 0.96134822\n",
      "  0.51842425 1.51583956 0.57792353 1.14137923 0.46479388 1.02621607\n",
      "  1.1540454  0.82429557 0.74520728 1.18627034 0.94408154 1.26952931\n",
      "  0.86757357 1.25525202 0.93524876 0.96065247 0.89219548 1.43748606\n",
      "  0.45626854 0.45612044 0.73688042]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.4\n",
      "0 loss 163846.17872247\n",
      "[0.49812375 0.47992678 0.48602098 0.4964117  0.49585439 0.49056294\n",
      " 0.49907779 0.48351422 0.48497374 0.49695885 0.49568711 0.48735919\n",
      " 0.49979346 0.33527665 0.49938183 0.49745612 0.49819034 0.49406565\n",
      " 0.49581048 0.4961592  0.48563203 0.3986425  0.4979379  0.4823691\n",
      " 0.47751    0.49994472 0.49833778 0.4986891  0.49823254 0.33384118\n",
      " 0.47234912 0.47256656 0.49355594]\n",
      "[[1.03603587 0.81272798 1.00088874 0.91781367 1.0233735  0.98651789\n",
      "  1.09222546 1.02681643 1.13592719 0.98186127 0.9008171  1.05171841\n",
      "  0.9009136  1.13761036 0.95928972 0.95945634 0.77917246 0.83728411\n",
      "  0.9766762  0.75446107 0.9838582  0.99657359 0.91412173 1.18494406\n",
      "  0.8751637  1.09464254 0.98776701 0.98727257 0.97874843 1.05256689\n",
      "  0.75277447 0.76778149 0.89921638]]\n",
      "{0: 125, 1: 763}\n",
      "acc 0.46283783783783783\n",
      "(0.381389252948886, 0.9831081081081081, 0.5495750708215297, None)\n",
      "\n",
      "1 loss 148897.73436784337\n",
      "[0.54296518 0.50008692 0.5012305  0.52011293 0.52375859 0.5316684\n",
      " 0.52468107 0.50019779 0.50214898 0.52292867 0.51914609 0.50356417\n",
      " 0.54146531 0.24831328 0.54237844 0.52231751 0.53269737 0.51529175\n",
      " 0.52185822 0.51401486 0.5356583  0.39416251 0.52032853 0.50013804\n",
      " 0.50010824 0.52854479 0.52282649 0.52292647 0.5228442  0.24651716\n",
      " 0.55730174 0.55753898 0.52596468]\n",
      "[[0.94019034 0.83177638 1.01311909 0.84308819 0.94632747 0.94553827\n",
      "  1.04923759 1.04241335 1.14541408 0.90554546 0.82655187 1.05846997\n",
      "  0.80523982 1.2204472  0.86339636 0.88360785 0.72566932 0.76518518\n",
      "  0.90079369 0.69624175 0.93512036 1.05772063 0.85104279 1.20643539\n",
      "  0.89777951 1.01585277 0.93296189 0.93022802 0.93742704 1.13858177\n",
      "  0.67245489 0.68660948 0.862445  ]]\n",
      "{0: 14, 1: 874}\n",
      "acc 0.3490990990990991\n",
      "(0.33867276887871856, 1.0, 0.505982905982906, None)\n",
      "\n",
      "2 loss 145132.67821288746\n",
      "[0.64123293 0.50105208 0.51063819 0.50003524 0.50005242 0.57180041\n",
      " 0.53613261 0.50468115 0.51498627 0.50004067 0.50001305 0.52067468\n",
      " 0.63982887 0.15096756 0.64071365 0.50002492 0.61606195 0.50296698\n",
      " 0.50272341 0.5000314  0.5869989  0.38890544 0.5000068  0.5025117\n",
      " 0.50009044 0.50182027 0.5213286  0.5155016  0.53121421 0.14898714\n",
      " 0.64799517 0.6478805  0.55419636]\n",
      "[[0.84418514 0.84513349 1.01778141 0.80896147 0.87702372 0.90300631\n",
      "  1.02854234 1.05133126 1.14741929 0.84619873 0.80030311 1.05693019\n",
      "  0.70885028 1.3149362  0.76718578 0.83191118 0.65950777 0.76902084\n",
      "  0.84449786 0.69351625 0.88218379 1.11888438 0.82970762 1.22786912\n",
      "  0.91653564 0.9378682  0.91346355 0.91209825 0.9187508  1.23577796\n",
      "  0.59434024 0.60540006 0.83011196]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "3 loss 141176.05942183232\n",
      "[0.73731459 0.50636167 0.52646308 0.50002143 0.50002504 0.60987862\n",
      " 0.53100896 0.51548469 0.53374171 0.50002454 0.50000935 0.54355037\n",
      " 0.73586101 0.0511561  0.73677473 0.50002446 0.69637396 0.50287883\n",
      " 0.50252642 0.50001379 0.63728352 0.38397832 0.50000667 0.51169014\n",
      " 0.50100749 0.50106783 0.50001129 0.50002325 0.52320438 0.04907156\n",
      " 0.72279652 0.73027277 0.57770877]\n",
      "[[0.75114268 0.85512155 1.01933064 0.92435643 0.9818792  0.86106609\n",
      "  1.0169393  1.05703232 1.1466165  0.95959538 0.91515113 1.05270412\n",
      "  0.6155064  1.41264091 0.67398257 0.94723714 0.59885087 0.88022493\n",
      "  0.95626712 0.72780994 0.82950257 1.17888875 0.84613469 1.24927403\n",
      "  0.932454   1.015577   0.91094131 0.91422526 0.90919285 1.33549033\n",
      "  0.54449485 0.54610233 0.8001337 ]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 137495.64772730132\n",
      "[ 0.83208115  0.51784999  0.54743046  0.50000658  0.50001155  0.64505714\n",
      "  0.5114316   0.53181388  0.55707341  0.50000559  0.49999928  0.5706993\n",
      "  0.8305082  -0.04830619  0.83148485  0.50001006  0.773166    0.50265339\n",
      "  0.50188633  0.50000426  0.68568302  0.38131839  0.50000684  0.52654337\n",
      "  0.50525864  0.50047288  0.50000241  0.49999916  0.50075314 -0.05047307\n",
      "  0.76348617  0.76799914  0.59635509]\n",
      "[[0.66074772 0.86206026 1.01844292 1.03300011 1.09234129 0.82078696\n",
      "  1.01296221 1.0600571  1.1437323  1.06926841 1.02356101 1.04659337\n",
      "  0.52474066 1.51040705 0.5833944  1.0565224  0.54436486 0.98750588\n",
      "  1.06538978 0.78015149 0.77809524 1.23713214 0.88851889 1.27065718\n",
      "  0.94532867 1.12726778 0.92139761 0.93431479 0.90734001 1.43486037\n",
      "  0.52091482 0.53976379 0.77278951]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[ 0.83208115  0.51784999  0.54743046  0.50000658  0.50001155  0.64505714\n",
      "  0.5114316   0.53181388  0.55707341  0.50000559  0.49999928  0.5706993\n",
      "  0.8305082  -0.04830619  0.83148485  0.50001006  0.773166    0.50265339\n",
      "  0.50188633  0.50000426  0.68568302  0.38131839  0.50000684  0.52654337\n",
      "  0.50525864  0.50047288  0.50000241  0.49999916  0.50075314 -0.05047307\n",
      "  0.76348617  0.76799914  0.59635509]\n",
      "[[0.66074772 0.86206026 1.01844292 1.03300011 1.09234129 0.82078696\n",
      "  1.01296221 1.0600571  1.1437323  1.06926841 1.02356101 1.04659337\n",
      "  0.52474066 1.51040705 0.5833944  1.0565224  0.54436486 0.98750588\n",
      "  1.06538978 0.78015149 0.77809524 1.23713214 0.88851889 1.27065718\n",
      "  0.94532867 1.12726778 0.92139761 0.93431479 0.90734001 1.43486037\n",
      "  0.52091482 0.53976379 0.77278951]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.5\n",
      "0 loss 151368.55182659463\n",
      "[0.55616043 0.50003111 0.50008119 0.58288913 0.58487763 0.53665535\n",
      " 0.56722344 0.50001622 0.50012334 0.5841125  0.57442603 0.50045573\n",
      " 0.54737853 0.44314513 0.55138992 0.58368999 0.52738873 0.56061844\n",
      " 0.58027855 0.55320025 0.53264423 0.49956767 0.57598975 0.50019459\n",
      " 0.50009564 0.58613606 0.57506712 0.57682992 0.56769929 0.44183277\n",
      " 0.55903482 0.55923918 0.53715212]\n",
      "[[1.00159007 0.83966713 1.02860517 0.91616139 1.02124633 1.01370532\n",
      "  1.11537714 1.05328797 1.1630079  0.9798412  0.89870068 1.08084756\n",
      "  0.88296068 1.12625092 0.93405657 0.95749595 0.8268231  0.83460796\n",
      "  0.97455859 0.75796816 1.01165489 1.00531855 0.91809104 1.18612399\n",
      "  0.90057573 1.09195668 1.00088399 0.99866936 1.00082505 1.04159381\n",
      "  0.76372236 0.77730182 0.93196151]]\n",
      "{0: 185, 1: 703}\n",
      "acc 0.48986486486486486\n",
      "(0.3883357041251778, 0.9222972972972973, 0.5465465465465464, None)\n",
      "\n",
      "1 loss 148927.2751199948\n",
      "[0.6571199  0.50017359 0.50420466 0.57926865 0.60940772 0.56808911\n",
      " 0.59228513 0.5014476  0.50728594 0.5969857  0.56976155 0.51134878\n",
      " 0.64871593 0.36402385 0.65256944 0.59050825 0.61095293 0.54533379\n",
      " 0.59356174 0.55353798 0.57070625 0.49924332 0.59655552 0.50023574\n",
      " 0.50005516 0.62876382 0.60000325 0.5998714  0.59071716 0.36228639\n",
      " 0.63687523 0.6367683  0.56340917]\n",
      "[[0.90442703 0.85540395 1.03621707 0.84016771 0.94418177 0.98177385\n",
      "  1.08868115 1.0648878  1.16791781 0.90302821 0.82270522 1.08229864\n",
      "  0.78516831 1.19743763 0.83655054 0.88088986 0.760205   0.75976745\n",
      "  0.89767797 0.72234807 0.97324242 1.07654882 0.87577442 1.2075865\n",
      "  0.92018226 1.01448096 0.96724951 0.96545207 0.97450316 1.11716481\n",
      "  0.69515828 0.70564276 0.90435702]]\n",
      "{0: 36, 1: 852}\n",
      "acc 0.3738738738738739\n",
      "(0.3474178403755869, 1.0, 0.5156794425087108, None)\n",
      "\n",
      "2 loss 145980.2986523176\n",
      "[0.75091459 0.50021084 0.51110988 0.50006293 0.50521259 0.6075589\n",
      " 0.60651568 0.50359973 0.51735285 0.50009338 0.50000606 0.5252741\n",
      " 0.74253672 0.26845308 0.74638359 0.50006169 0.68440713 0.50360547\n",
      " 0.50386222 0.51789767 0.62102589 0.49371092 0.58131302 0.50032291\n",
      " 0.50008448 0.53739314 0.60404075 0.60136665 0.60251195 0.26650047\n",
      " 0.71494639 0.71915338 0.59261195]\n",
      "[[0.81386093 0.86958568 1.04210585 0.73944135 0.84022344 0.9407031\n",
      "  1.06832974 1.07479209 1.1713511  0.79939807 0.72391586 1.08245327\n",
      "  0.69423983 1.28800037 0.74578423 0.77801671 0.70559953 0.67125043\n",
      "  0.79471579 0.70418451 0.92190635 1.1507528  0.85172691 1.22902963\n",
      "  0.93947011 0.91197209 0.94734021 0.94651467 0.95524553 1.21179269\n",
      "  0.63845671 0.64024426 0.87223271]]\n",
      "{0: 2, 1: 886}\n",
      "acc 0.3355855855855856\n",
      "(0.3340857787810384, 1.0, 0.5008460236886634, None)\n",
      "\n",
      "3 loss 142657.1981813031\n",
      "[0.8456093  0.50251957 0.5228807  0.50003265 0.50003654 0.64739673\n",
      " 0.60975229 0.51073352 0.53186297 0.50003554 0.50003035 0.5434807\n",
      " 0.83743024 0.16904832 0.84119672 0.50001215 0.75442382 0.50293305\n",
      " 0.50264348 0.50002147 0.67247986 0.48576019 0.53066567 0.50569842\n",
      " 0.50008563 0.50140729 0.5893055  0.57785273 0.60320931 0.16697499\n",
      " 0.76058158 0.76641928 0.61942652]\n",
      "[[0.72433202 0.88123855 1.0456319  0.81387047 0.86604399 0.89830264\n",
      "  1.05436013 1.08221959 1.17269305 0.84583672 0.80538929 1.08066211\n",
      "  0.60395517 1.38433925 0.65583695 0.8346265  0.65789832 0.77468876\n",
      "  0.84185492 0.71764119 0.868969   1.22369813 0.85171024 1.25045044\n",
      "  0.95684859 0.89659965 0.9402602  0.9425511  0.94275453 1.31086003\n",
      "  0.60825927 0.61985576 0.84097067]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 139315.09748152006\n",
      "[0.93564021 0.50968254 0.53934444 0.5000193  0.50002006 0.6854004\n",
      " 0.60249229 0.52283858 0.55057739 0.50000434 0.50001272 0.56564818\n",
      " 0.92797684 0.06918836 0.9315277  0.5000063  0.81870039 0.50279419\n",
      " 0.50222204 0.50000796 0.72280978 0.4784502  0.50000705 0.51626857\n",
      " 0.50188905 0.50085467 0.55869162 0.53390187 0.59364969 0.06702888\n",
      " 0.78813741 0.78251042 0.64277702]\n",
      "[[0.64395241 0.89018951 1.04693834 0.92360791 0.97923301 0.85690292\n",
      "  1.04599458 1.08723574 1.17212216 0.95742395 0.9147334  1.077131\n",
      "  0.52189753 1.48197412 0.57452416 0.94548748 0.6172889  0.8821183\n",
      "  0.95207051 0.75452829 0.81682842 1.29482569 0.87380681 1.2718497\n",
      "  0.97173646 1.01233928 0.94248292 0.95052914 0.93592174 1.41051742\n",
      "  0.58835353 0.62062757 0.81163638]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[0.93564021 0.50968254 0.53934444 0.5000193  0.50002006 0.6854004\n",
      " 0.60249229 0.52283858 0.55057739 0.50000434 0.50001272 0.56564818\n",
      " 0.92797684 0.06918836 0.9315277  0.5000063  0.81870039 0.50279419\n",
      " 0.50222204 0.50000796 0.72280978 0.4784502  0.50000705 0.51626857\n",
      " 0.50188905 0.50085467 0.55869162 0.53390187 0.59364969 0.06702888\n",
      " 0.78813741 0.78251042 0.64277702]\n",
      "[[0.64395241 0.89018951 1.04693834 0.92360791 0.97923301 0.85690292\n",
      "  1.04599458 1.08723574 1.17212216 0.95742395 0.9147334  1.077131\n",
      "  0.52189753 1.48197412 0.57452416 0.94548748 0.6172889  0.8821183\n",
      "  0.95207051 0.75452829 0.81682842 1.29482569 0.87380681 1.2718497\n",
      "  0.97173646 1.01233928 0.94248292 0.95052914 0.93592174 1.41051742\n",
      "  0.58835353 0.62062757 0.81163638]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.6000000000000001\n",
      "0 loss 151070.04968550202\n",
      "[0.7100312  0.57418233 0.5824313  0.68044697 0.6827378  0.62771296\n",
      " 0.6535066  0.57969128 0.58607797 0.68186428 0.68005313 0.58783509\n",
      " 0.69632263 0.55669071 0.70261765 0.68137777 0.63293874 0.67851152\n",
      " 0.68175493 0.66942482 0.62303135 0.53824994 0.67353768 0.57802203\n",
      " 0.57378252 0.68415518 0.66441633 0.66645546 0.65417283 0.54929844\n",
      " 0.65369588 0.65333552 0.62843143]\n",
      "[[1.01091522 0.83921447 1.02895548 0.91831226 1.02325235 1.01939494\n",
      "  1.12932677 1.05355753 1.16394247 0.98189872 0.90140628 1.08156152\n",
      "  0.87044758 1.11958062 0.93159832 0.95958411 0.80732299 0.83836977\n",
      "  0.97683873 0.76822063 1.01802121 1.00383745 0.92632396 1.18525391\n",
      "  0.89995565 1.0938882  1.0131493  1.01244895 1.01540976 1.03276681\n",
      "  0.77442174 0.78369828 0.94072303]]\n",
      "{0: 179, 1: 709}\n",
      "acc 0.49436936936936937\n",
      "(0.3921015514809591, 0.9391891891891891, 0.5532338308457712, None)\n",
      "\n",
      "1 loss 149113.2090113169\n",
      "[0.8072753  0.56305674 0.57894243 0.64874278 0.67743385 0.65663161\n",
      " 0.6715885  0.5723568  0.58503426 0.66535595 0.64471519 0.5904483\n",
      " 0.79411139 0.48458002 0.80016678 0.65924903 0.70585463 0.63087507\n",
      " 0.66394456 0.65448803 0.65776033 0.49945534 0.68244037 0.56811683\n",
      " 0.55907875 0.69929365 0.68015248 0.67939944 0.67063496 0.4736866\n",
      " 0.71655332 0.72160331 0.65172033]\n",
      "[[0.91902975 0.85783838 1.04119277 0.83827627 0.94344128 0.9899013\n",
      "  1.10921443 1.06922611 1.17429795 0.9017143  0.82158716 1.08874436\n",
      "  0.77757676 1.18193753 0.8391698  0.8793412  0.75414528 0.76019405\n",
      "  0.89663143 0.74815007 0.98286099 1.07538795 0.89704108 1.2067514\n",
      "  0.92208398 1.01520007 0.98935521 0.98997414 0.99533485 1.10191621\n",
      "  0.7307784  0.72826429 0.91606143]]\n",
      "{0: 36, 1: 852}\n",
      "acc 0.3738738738738739\n",
      "(0.3474178403755869, 1.0, 0.5156794425087108, None)\n",
      "\n",
      "2 loss 146855.16268205547\n",
      "[0.89685657 0.55403965 0.57762705 0.54584513 0.58112307 0.69432827\n",
      " 0.68479314 0.56715447 0.58597754 0.56524665 0.5414534  0.59482139\n",
      " 0.88428203 0.39120894 0.89008777 0.55783246 0.76555435 0.52695371\n",
      " 0.5634995  0.62699012 0.70582049 0.49632789 0.67024889 0.56085053\n",
      " 0.54529146 0.61398367 0.68419319 0.68163733 0.68207614 0.38038249\n",
      " 0.7606199  0.76693547 0.68006817]\n",
      "[[0.83680043 0.87539883 1.05229701 0.73104439 0.83562899 0.95121756\n",
      "  1.09167156 1.08376485 1.18364246 0.7939255  0.71458597 1.09509238\n",
      "  0.69382171 1.26518015 0.75608679 0.77168716 0.71476261 0.6543976\n",
      "  0.7888666  0.73601174 0.93429383 1.14943648 0.87955733 1.22823671\n",
      "  0.94409732 0.9081834  0.97332575 0.97507085 0.97831024 1.19182754\n",
      "  0.69990104 0.70342335 0.88570979]]\n",
      "{0: 2, 1: 886}\n",
      "acc 0.3355855855855856\n",
      "(0.3340857787810384, 1.0, 0.5008460236886634, None)\n",
      "\n",
      "3 loss 144144.18842481228\n",
      "[0.97951131 0.54765104 0.57878105 0.50000288 0.50004836 0.73509062\n",
      " 0.69385867 0.56450922 0.58917822 0.50004155 0.5000255  0.60123135\n",
      " 0.96965964 0.29253393 0.97432958 0.50000671 0.81631131 0.50304314\n",
      " 0.5027276  0.58728679 0.75776964 0.48885194 0.64520278 0.55646631\n",
      " 0.53365053 0.50179009 0.68115068 0.67379592 0.68955778 0.28159423\n",
      " 0.79097786 0.78618756 0.70919563]\n",
      "[[0.7726055  0.89158765 1.06212957 0.6930862  0.75423271 0.90932211\n",
      "  1.07676327 1.09694841 1.19185119 0.72698587 0.6847142  1.10047322\n",
      "  0.62370318 1.35851302 0.68851212 0.71441902 0.68453875 0.65283633\n",
      "  0.72555001 0.7330392  0.88201546 1.22316371 0.87172389 1.24971006\n",
      "  0.96505822 0.81277714 0.96333607 0.96698423 0.96417964 1.28935315\n",
      "  0.67603577 0.69528523 0.85421741]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 141054.7531847023\n",
      "[1.         0.54750633 0.58590525 0.50000413 0.50001999 0.77492814\n",
      " 0.69307486 0.56788328 0.59805856 0.50002322 0.50000846 0.61325297\n",
      " 1.         0.19261938 1.         0.50001072 0.86410095 0.50290134\n",
      " 0.5025789  0.5180096  0.80945006 0.48118722 0.58735232 0.55827055\n",
      " 0.52792546 0.50113464 0.66155762 0.64370828 0.68718199 0.18159776\n",
      " 0.81918297 0.79581571 0.73559634]\n",
      "[[0.76634502 0.90464402 1.06899358 0.80682338 0.86468462 0.86767258\n",
      "  1.06709832 1.10710407 1.19725839 0.84182573 0.79781516 1.10312705\n",
      "  0.61147422 1.45509389 0.67926661 0.82940989 0.65776156 0.7626567\n",
      "  0.83852767 0.75741314 0.82988322 1.29510188 0.88696418 1.27115832\n",
      "  0.98303934 0.90008562 0.96279616 0.97124149 0.95550058 1.38875789\n",
      "  0.65987795 0.69622318 0.82408076]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[1.         0.54750633 0.58590525 0.50000413 0.50001999 0.77492814\n",
      " 0.69307486 0.56788328 0.59805856 0.50002322 0.50000846 0.61325297\n",
      " 1.         0.19261938 1.         0.50001072 0.86410095 0.50290134\n",
      " 0.5025789  0.5180096  0.80945006 0.48118722 0.58735232 0.55827055\n",
      " 0.52792546 0.50113464 0.66155762 0.64370828 0.68718199 0.18159776\n",
      " 0.81918297 0.79581571 0.73559634]\n",
      "[[0.76634502 0.90464402 1.06899358 0.80682338 0.86468462 0.86767258\n",
      "  1.06709832 1.10710407 1.19725839 0.84182573 0.79781516 1.10312705\n",
      "  0.61147422 1.45509389 0.67926661 0.82940989 0.65776156 0.7626567\n",
      "  0.83852767 0.75741314 0.82988322 1.29510188 0.88696418 1.27115832\n",
      "  0.98303934 0.90008562 0.96279616 0.97124149 0.95550058 1.38875789\n",
      "  0.65987795 0.69622318 0.82408076]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.7000000000000001\n",
      "0 loss 151207.95102208134\n",
      "[0.80989634 0.67315788 0.68017891 0.78008226 0.78229886 0.7209384\n",
      " 0.73905133 0.6777094  0.68313512 0.78145473 0.77970013 0.68498014\n",
      " 0.81359542 0.6657093  0.8115127  0.78098404 0.74263401 0.77820079\n",
      " 0.78134898 0.76310889 0.71415314 0.64373272 0.76641697 0.67630578\n",
      " 0.67339027 0.78366627 0.75220351 0.75261417 0.73701073 0.67243256\n",
      " 0.72924456 0.73752678 0.71826069]\n",
      "[[1.019613   0.84043425 1.03121076 0.91986869 1.02490664 1.02395617\n",
      "  1.14220693 1.05554699 1.16671749 0.98351553 0.90294608 1.08432899\n",
      "  0.88295845 1.11028577 0.94208126 0.96118012 0.81351358 0.83984537\n",
      "  0.97845085 0.77795277 1.02472561 0.99854039 0.93630415 1.18525401\n",
      "  0.90046597 1.09560349 1.0256237  1.02858404 1.03157643 0.99170345\n",
      "  0.80039274 0.79720836 0.94816149]]\n",
      "{0: 217, 1: 671}\n",
      "acc 0.5168918918918919\n",
      "(0.4008941877794337, 0.9087837837837838, 0.5563598759048605, None)\n",
      "\n",
      "1 loss 149935.3607799438\n",
      "[0.90312327 0.65495563 0.66771003 0.75200622 0.77560989 0.74365941\n",
      " 0.75377123 0.66211804 0.67236441 0.76624852 0.74830646 0.67738822\n",
      " 0.90712696 0.61033613 0.90492723 0.76120706 0.80001801 0.73496257\n",
      " 0.76510302 0.75839459 0.73784346 0.57970352 0.77741609 0.6578106\n",
      " 0.65306996 0.79118822 0.76615915 0.76535412 0.75061421 0.61447491\n",
      " 0.75766262 0.76664419 0.73614902]\n",
      "[[0.9352901  0.86331554 1.04906189 0.84014895 0.94675612 1.00120897\n",
      "  1.12740785 1.07635469 1.18323105 0.90457573 0.82313718 1.09793637\n",
      "  0.79841885 1.15370673 0.85759749 0.88189627 0.77576856 0.76028799\n",
      "  0.89942728 0.76235229 1.00104599 1.06575024 0.91467365 1.20678165\n",
      "  0.92556894 1.01906119 1.00872329 1.01191279 1.01678605 1.02036521\n",
      "  0.78420604 0.774154   0.92985358]]\n",
      "{0: 114, 1: 774}\n",
      "acc 0.4617117117117117\n",
      "(0.38242894056847543, 1.0, 0.5532710280373832, None)\n",
      "\n",
      "2 loss 148359.30984137114\n",
      "[0.98198386 0.63896751 0.65768672 0.64695937 0.6777669  0.77539121\n",
      " 0.76513808 0.64882451 0.66400274 0.66470255 0.64269894 0.67211334\n",
      " 0.98500551 0.53403193 0.98338951 0.65814963 0.84280963 0.62818419\n",
      " 0.663185   0.73548465 0.77731924 0.50907464 0.76690807 0.64201623\n",
      " 0.63345565 0.70193213 0.76925111 0.76784181 0.76109419 0.53480538\n",
      " 0.78246081 0.78572581 0.7607043 ]\n",
      "[[0.87616534 0.88502818 1.06555353 0.72973571 0.83540497 0.96901062\n",
      "  1.11328082 1.09590159 1.19840561 0.7933952  0.71302735 1.11029392\n",
      "  0.74111266 1.21733873 0.79922507 0.77091703 0.75060292 0.65172953\n",
      "  0.78828577 0.75549016 0.96138264 1.13965599 0.90412504 1.22830107\n",
      "  0.9508771  0.90799413 0.99680788 1.00105722 1.00255896 1.08972317\n",
      "  0.76454146 0.76105467 0.90406182]]\n",
      "{0: 21, 1: 867}\n",
      "acc 0.356981981981982\n",
      "(0.3414071510957324, 1.0, 0.5090283748925193, None)\n",
      "\n",
      "3 loss 146280.00858372104\n",
      "[1.         0.62480832 0.64959372 0.53691694 0.56562833 0.81379011\n",
      " 0.77516864 0.63743601 0.6575112  0.55314452 0.53306578 0.66853986\n",
      " 1.         0.44150955 1.         0.54709458 0.87412338 0.51996041\n",
      " 0.55173455 0.70824031 0.82622715 0.49703497 0.75001327 0.62852756\n",
      " 0.61473598 0.59194146 0.7691256  0.76543131 0.77030044 0.44162732\n",
      " 0.81125952 0.79996033 0.78917212]\n",
      "[[0.87141737 0.90575157 1.08095832 0.62540205 0.72768324 0.93027282\n",
      "  1.09968318 1.11436632 1.21252768 0.68681337 0.60945934 1.12172711\n",
      "  0.73765955 1.2979126  0.79509226 0.66504144 0.7338277  0.55256258\n",
      "  0.68185804 0.75274292 0.91278787 1.21429998 0.89838776 1.24981291\n",
      "  0.97596012 0.79892912 0.98781941 0.99368249 0.98909661 1.1779405\n",
      "  0.74434092 0.75323807 0.8742924 ]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 143666.55600076722\n",
      "[1.         0.6136251  0.6445791  0.50002714 0.50000889 0.85485124\n",
      " 0.7822709  0.62912672 0.65402054 0.5000444  0.50004387 0.66784306\n",
      " 1.         0.34269944 1.         0.50004566 0.90031873 0.5029805\n",
      " 0.50274618 0.66844175 0.87851644 0.48999755 0.72166117 0.61839875\n",
      " 0.59860662 0.50177492 0.76397505 0.75483317 0.7765343  0.34261328\n",
      " 0.8380305  0.80703945 0.81846037]\n",
      "[[0.87141737 0.9249313  1.09472655 0.63858106 0.68465968 0.88907246\n",
      "  1.08768302 1.13117118 1.22505599 0.66630835 0.63180144 1.13167098\n",
      "  0.73765955 1.38966655 0.79509226 0.65639017 0.7206319  0.60458295\n",
      "  0.66432207 0.75857867 0.86153348 1.28804447 0.89968009 1.27131332\n",
      "  0.99974421 0.72130723 0.98234762 0.99117106 0.97746853 1.27472238\n",
      "  0.73141149 0.74997432 0.84349917]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[1.         0.6136251  0.6445791  0.50002714 0.50000889 0.85485124\n",
      " 0.7822709  0.62912672 0.65402054 0.5000444  0.50004387 0.66784306\n",
      " 1.         0.34269944 1.         0.50004566 0.90031873 0.5029805\n",
      " 0.50274618 0.66844175 0.87851644 0.48999755 0.72166117 0.61839875\n",
      " 0.59860662 0.50177492 0.76397505 0.75483317 0.7765343  0.34261328\n",
      " 0.8380305  0.80703945 0.81846037]\n",
      "[[0.87141737 0.9249313  1.09472655 0.63858106 0.68465968 0.88907246\n",
      "  1.08768302 1.13117118 1.22505599 0.66630835 0.63180144 1.13167098\n",
      "  0.73765955 1.38966655 0.79509226 0.65639017 0.7206319  0.60458295\n",
      "  0.66432207 0.75857867 0.86153348 1.28804447 0.89968009 1.27131332\n",
      "  0.99974421 0.72130723 0.98234762 0.99117106 0.97746853 1.27472238\n",
      "  0.73141149 0.74997432 0.84349917]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.8\n",
      "0 loss 151519.0951873517\n",
      "[0.89860178 0.77197473 0.77783958 0.87683398 0.87902713 0.81793164\n",
      " 0.82273579 0.77568639 0.78023768 0.87819595 0.87645222 0.78208853\n",
      " 0.89872044 0.77431343 0.89861127 0.87773041 0.84204752 0.87494234\n",
      " 0.87809149 0.85045084 0.81162536 0.7487729  0.85426961 0.77373461\n",
      " 0.77262434 0.88036442 0.83678754 0.83224125 0.81865131 0.8217925\n",
      " 0.80584993 0.81735828 0.81118132]\n",
      "[[1.02952527 0.84158693 1.03325309 0.92493444 1.03012347 1.02520639\n",
      "  1.15415958 1.05729872 1.16916424 0.98867365 0.90798687 1.08678319\n",
      "  0.8934441  1.10259916 0.95229827 0.9663061  0.82046908 0.8447918\n",
      "  0.98360171 0.79289384 1.02552223 0.99359927 0.94869669 1.18524352\n",
      "  0.90112687 1.10091807 1.03814748 1.04573848 1.04519434 0.97593694\n",
      "  0.81098224 0.80875071 0.9527008 ]]\n",
      "{0: 322, 1: 566}\n",
      "acc 0.6283783783783784\n",
      "(0.46996466431095407, 0.8986486486486487, 0.617169373549884, None)\n",
      "\n",
      "1 loss 150558.13224078083\n",
      "[0.9790989  0.74847343 0.75857279 0.85457464 0.8716835  0.83669123\n",
      " 0.83244114 0.75386117 0.7620678  0.86536288 0.85148261 0.76671208\n",
      " 0.9797005  0.7437686  0.97939104 0.86172787 0.8810081  0.8391747\n",
      " 0.8645527  0.85365697 0.82734186 0.69256892 0.86352867 0.74878302\n",
      " 0.74827641 0.88132835 0.84608245 0.84311391 0.82691617 0.84685108\n",
      " 0.81274041 0.82539799 0.8228148 ]\n",
      "[[0.96898453 0.86768497 1.05541018 0.84390965 0.952983   1.00670461\n",
      "  1.14540459 1.08201171 1.19040812 0.91000128 0.82634786 1.10531013\n",
      "  0.8324287  1.12770063 0.89147148 0.88680451 0.79701916 0.76097393\n",
      "  0.90474128 0.78232881 1.01003462 1.05241738 0.93646148 1.20677724\n",
      "  0.92817092 1.02633862 1.02918285 1.0346507  1.03737455 0.96377803\n",
      "  0.80472593 0.79497016 0.94120092]]\n",
      "{0: 260, 1: 628}\n",
      "acc 0.5923423423423423\n",
      "(0.44745222929936307, 0.9493243243243243, 0.6082251082251083, None)\n",
      "\n",
      "2 loss 149549.9157467605\n",
      "[1.         0.72646208 0.74099729 0.77681044 0.80891626 0.85978008\n",
      " 0.8409003  0.73361526 0.74561983 0.79737013 0.77073819 0.75299207\n",
      " 1.         0.69694164 1.         0.79056374 0.90729419 0.74660229\n",
      " 0.79586391 0.84334137 0.85110417 0.62989633 0.86013492 0.72571251\n",
      " 0.72453687 0.8258913  0.84906548 0.84785087 0.8340558  0.86187261\n",
      " 0.82359329 0.83120611 0.83833687]\n",
      "[[0.96308993 0.89292926 1.07653807 0.73006641 0.84006091 0.9836735\n",
      "  1.13623737 1.10579836 1.21059904 0.79675388 0.71233193 1.12285007\n",
      "  0.82675167 1.1586952  0.88567747 0.77336108 0.78279584 0.6464176\n",
      "  0.79145075 0.77785909 0.98633718 1.11809355 0.93074025 1.22831009\n",
      "  0.95525522 0.91388517 1.02269937 1.02687684 1.02896456 0.95899895\n",
      "  0.79776294 0.78626296 0.92526398]]\n",
      "{0: 163, 1: 725}\n",
      "acc 0.5123873873873874\n",
      "(0.40551724137931033, 0.9932432432432432, 0.5759059745347699, None)\n",
      "\n",
      "3 loss 148357.2438651451\n",
      "[1.         0.70590839 0.72502243 0.67603069 0.73309359 0.88916426\n",
      " 0.84958157 0.71489991 0.730792   0.71291082 0.66552024 0.74079165\n",
      " 1.         0.63047504 1.         0.70075413 0.92434827 0.63207741\n",
      " 0.71023493 0.82542147 0.88571012 0.56130657 0.85091772 0.7045156\n",
      " 0.70119319 0.76162555 0.84960332 0.84925384 0.8416776  0.86842292\n",
      " 0.83819047 0.83639085 0.85954721]\n",
      "[[0.96308993 0.9173235  1.09669013 0.61911851 0.73005234 0.95452374\n",
      "  1.12591498 1.12867177 1.22979697 0.68638785 0.6013022  1.13948109\n",
      "  0.82675167 1.20492835 0.88567747 0.66278312 0.7744246  0.53627405\n",
      "  0.68103757 0.77599188 0.95219654 1.18986357 0.92779899 1.24984087\n",
      "  0.98252717 0.8043764  1.01675959 1.02082804 1.0191513  0.96000744\n",
      "  0.79012535 0.7802457  0.90348374]]\n",
      "{0: 67, 1: 821}\n",
      "acc 0.40878378378378377\n",
      "(0.36053593179049936, 1.0, 0.5299910474485228, None)\n",
      "\n",
      "4 loss 146914.86584729815\n",
      "[1.         0.6867646  0.71053329 0.55235153 0.63799127 0.92420471\n",
      " 0.85881268 0.6976508  0.71745844 0.60317517 0.54270347 0.72995565\n",
      " 1.         0.55268808 1.         0.58338032 0.93563602 0.5172282\n",
      " 0.59865755 0.80606796 0.92897427 0.4993459  0.83984131 0.68512214\n",
      " 0.67840106 0.68573751 0.84990074 0.84920625 0.85004269 0.87003898\n",
      " 0.84527544 0.83973295 0.88525717]\n",
      "[[0.96308993 0.94087261 1.11592885 0.51069892 0.62126829 0.92040882\n",
      "  1.11474471 1.15064752 1.24807145 0.57717055 0.49366695 1.15528821\n",
      "  0.82675167 1.26796348 0.88567747 0.55349213 0.76944292 0.43250872\n",
      "  0.57178437 0.77417663 0.91063713 1.26433009 0.92549604 1.27136854\n",
      "  1.00975149 0.69631007 1.01081732 1.01568411 1.00836886 0.96420384\n",
      "  0.78203048 0.7753157  0.87740864]]\n",
      "{0: 9, 1: 879}\n",
      "acc 0.34346846846846846\n",
      "(0.33674630261660976, 1.0, 0.5038297872340425, None)\n",
      "\n",
      "[1.         0.6867646  0.71053329 0.55235153 0.63799127 0.92420471\n",
      " 0.85881268 0.6976508  0.71745844 0.60317517 0.54270347 0.72995565\n",
      " 1.         0.55268808 1.         0.58338032 0.93563602 0.5172282\n",
      " 0.59865755 0.80606796 0.92897427 0.4993459  0.83984131 0.68512214\n",
      " 0.67840106 0.68573751 0.84990074 0.84920625 0.85004269 0.87003898\n",
      " 0.84527544 0.83973295 0.88525717]\n",
      "[[0.96308993 0.94087261 1.11592885 0.51069892 0.62126829 0.92040882\n",
      "  1.11474471 1.15064752 1.24807145 0.57717055 0.49366695 1.15528821\n",
      "  0.82675167 1.26796348 0.88567747 0.55349213 0.76944292 0.43250872\n",
      "  0.57178437 0.77417663 0.91063713 1.26433009 0.92549604 1.27136854\n",
      "  1.00975149 0.69631007 1.01081732 1.01568411 1.00836886 0.96420384\n",
      "  0.78203048 0.7753157  0.87740864]]\n",
      "{0: 9, 1: 879}\n",
      "acc 0.34346846846846846\n",
      "acc 0.34346846846846846\n",
      "[[  9 583]\n",
      " [  0 296]]\n",
      "(0.33674630261660976, 1.0, 0.5038297872340425, None)\n",
      "\n",
      "alpha-mean 0.9\n",
      "0 loss 151878.4451930209\n",
      "[0.98143189 0.87048724 0.87547943 0.95736725 0.96006688 0.92049363\n",
      " 0.91134971 0.87361129 0.87748489 0.95906963 0.9568743  0.87930833\n",
      " 0.98119868 0.87922882 0.98128172 0.95849746 0.92699809 0.95485433\n",
      " 0.9589421  0.92865549 0.91622594 0.85183945 0.93582332 0.87149888\n",
      " 0.87121691 0.96160889 0.9230289  0.91356621 0.90769222 0.9095905\n",
      " 0.90729866 0.91719953 0.90982374]\n",
      "[[1.0555966  0.84298243 1.03531526 0.94460283 1.05035843 1.02189767\n",
      "  1.16147835 1.05912165 1.17150831 1.00869034 0.92755956 1.08909424\n",
      "  0.91945621 1.10108257 0.97831781 0.98620248 0.832654   0.86399335\n",
      "  1.00359129 0.81151755 1.02005317 0.99084238 0.96435688 1.18522444\n",
      "  0.90237032 1.12151398 1.04836467 1.05879104 1.05211369 0.98686294\n",
      "  0.81485175 0.82418017 0.95251222]]\n",
      "{0: 342, 1: 546}\n",
      "acc 0.6554054054054054\n",
      "(0.4908424908424908, 0.9054054054054054, 0.6365795724465558, None)\n",
      "\n",
      "1 loss 150987.5492981786\n",
      "[1.         0.84356933 0.8518615  0.91416011 0.92443483 0.94334735\n",
      " 0.917288   0.84774337 0.85454741 0.92069731 0.91223487 0.85898637\n",
      " 1.         0.85710246 1.         0.91852083 0.94438582 0.90422154\n",
      " 0.92021415 0.92874487 0.93904654 0.79671014 0.93689213 0.84256102\n",
      " 0.84343819 0.93005649 0.92652171 0.91889514 0.91314152 0.91463086\n",
      " 0.9112765  0.92156013 0.92361059]\n",
      "[[1.0511611  0.87149079 1.06056315 0.84327672 0.95341891 0.99984434\n",
      "  1.15583614 1.08670062 1.19614108 0.91007596 0.82548305 1.11105073\n",
      "  0.91486341 1.12437303 0.97378731 0.88665586 0.82323309 0.75900356\n",
      "  0.9047673  0.80714171 0.99796722 1.04845255 0.96127163 1.2067455\n",
      "  0.93178799 1.02728681 1.04467034 1.05331634 1.04678326 0.98787304\n",
      "  0.81069297 0.81853516 0.93891815]]\n",
      "{0: 284, 1: 604}\n",
      "acc 0.6486486486486487\n",
      "(0.4867549668874172, 0.9932432432432432, 0.6533333333333333, None)\n",
      "\n",
      "2 loss 150036.45021007184\n",
      "[1.         0.8176137  0.82942681 0.85790538 0.87798975 0.97002544\n",
      " 0.92376871 0.82292665 0.8328323  0.87081079 0.85401542 0.83982157\n",
      " 1.         0.83362802 1.         0.86656468 0.95560257 0.83735893\n",
      " 0.86987242 0.91915833 0.96920457 0.73498227 0.93296642 0.81484262\n",
      " 0.81584276 0.8885331  0.92723129 0.92130329 0.91895912 0.9154729\n",
      " 0.91510496 0.92215737 0.94142354]\n",
      "[[1.0511611  0.89934981 1.08496221 0.7275928  0.8383118  0.97488821\n",
      "  1.14890997 1.11356016 1.21989592 0.79476286 0.70968713 1.13220346\n",
      "  0.91486341 1.14893442 0.97378731 0.77122086 0.81785819 0.64272643\n",
      "  0.78942728 0.80740614 0.96987441 1.112877   0.96074451 1.22827136\n",
      "  0.96136831 0.91248243 1.04172007 1.04939797 1.04028743 0.99194017\n",
      "  0.80591905 0.81500132 0.92133018]]\n",
      "{0: 276, 1: 612}\n",
      "acc 0.6396396396396397\n",
      "(0.4803921568627451, 0.9932432432432432, 0.6475770925110133, None)\n",
      "\n",
      "3 loss 149006.60825532474\n",
      "[1.         0.79268126 0.80820608 0.78650157 0.82285849 1.00001591\n",
      " 0.93107036 0.799228   0.81237481 0.81017125 0.77913558 0.82183511\n",
      " 1.         0.80677985 1.         0.80250947 0.9627382  0.74629601\n",
      " 0.80848834 0.90512114 1.00014286 0.66853845 0.92642614 0.78850581\n",
      " 0.78868618 0.84091667 0.92687361 0.92221764 0.92538189 0.91390154\n",
      " 0.91921493 0.92149565 0.96292371]\n",
      "[[1.0511611  0.92654949 1.10853033 0.61547404 0.72699447 0.95334395\n",
      "  1.1407455  1.1396839  1.24278588 0.68316489 0.59740709 1.15256764\n",
      "  0.91486341 1.17474834 0.97378731 0.65945392 0.81493325 0.52973605\n",
      "  0.67779215 0.8096505  0.94842887 1.1821912  0.96145306 1.24980054\n",
      "  0.99089793 0.80156658 1.03902212 1.04624867 1.03279724 0.99765178\n",
      "  0.80038402 0.81219186 0.90055581]]\n",
      "{0: 266, 1: 622}\n",
      "acc 0.6283783783783784\n",
      "(0.47266881028938906, 0.9932432432432432, 0.6405228758169934, None)\n",
      "\n",
      "4 loss 147920.74876441195\n",
      "[1.         0.76881851 0.78819997 0.69151595 0.757145   1.00001913\n",
      " 0.93911327 0.77669686 0.7931781  0.73509069 0.67733007 0.80501261\n",
      " 1.         0.77399639 1.         0.72133979 0.96710891 0.61595774\n",
      " 0.73209893 0.89026383 1.00019783 0.59963418 0.91837083 0.76362512\n",
      " 0.7622498  0.7871111  0.92634108 0.92244556 0.93235932 0.91096914\n",
      " 0.92367439 0.92063525 0.9871057 ]\n",
      "[[1.0511611  0.95306251 1.13128524 0.50510017 0.61787836 0.95334395\n",
      "  1.13174996 1.16504174 1.26482639 0.57362262 0.4867708  1.17216557\n",
      "  0.91486341 1.2021304  0.97378731 0.54964708 0.81360998 0.41842167\n",
      "  0.56819223 0.81194352 0.94842962 1.25412746 0.96275154 1.27133156\n",
      "  1.0201098  0.69303167 1.03637196 1.04345748 1.02467851 1.00423475\n",
      "  0.79432194 0.80953474 0.87882333]]\n",
      "{0: 225, 1: 663}\n",
      "acc 0.5822072072072072\n",
      "(0.4434389140271493, 0.9932432432432432, 0.6131386861313869, None)\n",
      "\n",
      "[1.         0.76881851 0.78819997 0.69151595 0.757145   1.00001913\n",
      " 0.93911327 0.77669686 0.7931781  0.73509069 0.67733007 0.80501261\n",
      " 1.         0.77399639 1.         0.72133979 0.96710891 0.61595774\n",
      " 0.73209893 0.89026383 1.00019783 0.59963418 0.91837083 0.76362512\n",
      " 0.7622498  0.7871111  0.92634108 0.92244556 0.93235932 0.91096914\n",
      " 0.92367439 0.92063525 0.9871057 ]\n",
      "[[1.0511611  0.95306251 1.13128524 0.50510017 0.61787836 0.95334395\n",
      "  1.13174996 1.16504174 1.26482639 0.57362262 0.4867708  1.17216557\n",
      "  0.91486341 1.2021304  0.97378731 0.54964708 0.81360998 0.41842167\n",
      "  0.56819223 0.81194352 0.94842962 1.25412746 0.96275154 1.27133156\n",
      "  1.0201098  0.69303167 1.03637196 1.04345748 1.02467851 1.00423475\n",
      "  0.79432194 0.80953474 0.87882333]]\n",
      "{0: 225, 1: 663}\n",
      "acc 0.5822072072072072\n",
      "acc 0.5822072072072072\n",
      "[[223 369]\n",
      " [  2 294]]\n",
      "(0.4434389140271493, 0.9932432432432432, 0.6131386861313869, None)\n",
      "\n",
      "alpha-mean 1.0\n",
      "0 loss 152114.04000282486\n",
      "[1.15031799 0.96122464 1.15037901 1.         1.14702839 1.14698716\n",
      " 1.14705548 1.15047944 1.15026107 1.14700687 1.         1.15042288\n",
      " 0.94484446 1.15039844 1.15046929 1.14698819 0.98509903 1.\n",
      " 1.14700344 1.         1.14697932 0.97172311 1.00002668 0.97031672\n",
      " 0.9872702  1.14705918 1.14700898 1.14700924 1.14700189 0.98444185\n",
      " 1.         1.         1.00018226]\n",
      "[[1.2741758  0.85613652 1.16554431 1.00062431 1.26048079 1.19509448\n",
      "  1.32359644 1.18754552 1.30304298 1.2186191  0.98357063 1.22310088\n",
      "  0.87033573 1.23510455 1.19720325 1.19599825 0.85198424 0.91993383\n",
      "  1.2134928  0.83640694 1.18908793 0.97542346 0.99542096 1.18563823\n",
      "  0.88697105 1.33190411 1.22199939 1.22242367 1.21133221 1.00679417\n",
      "  0.82151247 0.83774526 0.96185072]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "1 loss 151177.59729640486\n",
      "[1.26768426 0.92630961 1.26795139 1.         1.26141991 1.26134718\n",
      " 1.26147396 1.26799923 1.26758116 1.26137847 1.         1.26787625\n",
      " 0.78352451 1.26783064 1.26797028 1.26134865 0.9610519  1.\n",
      " 1.26137251 1.         1.26133648 0.93547784 1.         0.93899659\n",
      " 0.96744835 1.26148093 1.26138224 1.2613827  1.26136989 0.96556622\n",
      " 1.         1.00000031 1.        ]\n",
      "[[1.39632081 0.89171891 1.28780432 1.00062431 1.38041352 1.31499023\n",
      "  1.4435631  1.30976916 1.42516511 1.33852805 0.98357063 1.34528956\n",
      "  0.73067072 1.35728252 1.31941662 1.31589448 0.86912234 0.91993383\n",
      "  1.33339883 0.83640694 1.30898052 1.01488325 0.99541985 1.20713506\n",
      "  0.9085355  1.45187502 1.34191028 1.3423348  1.33123701 1.02352291\n",
      "  0.8195117  0.83532544 0.96181045]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "2 loss 149725.60856451443\n",
      "[1.3794743  0.88920021 1.37985552 1.         1.37008603 1.36992488\n",
      " 1.37021498 1.37987568 1.37934585 1.3699894  1.00000006 1.37971511\n",
      " 0.64717966 1.37965754 1.37983613 1.36992765 0.91179977 1.\n",
      " 1.36997633 0.99999995 1.36990545 0.88748832 1.00000047 0.90706637\n",
      " 0.93868756 1.37023119 1.36999781 1.36999885 1.3699707  0.93922288\n",
      " 1.0001067  1.00037427 1.00020065]\n",
      "[[1.51090594 0.92707565 1.40242626 1.0006243  1.49258068 1.42708792\n",
      "  1.55579287 1.42437862 1.53974431 1.45065125 0.98357062 1.45988755\n",
      "  0.70923617 1.47187718 1.43402263 1.42799316 0.89995454 0.91993382\n",
      "  1.44551651 0.83640693 1.42107166 1.0650859  0.98942794 1.22864143\n",
      "  0.93793289 1.56411274 1.45403711 1.45446208 1.44335236 1.0435422\n",
      "  0.81086278 0.83522791 0.95678665]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "3 loss 147223.75857709174\n",
      "[1.48904666 0.84844813 1.48945726 1.00000001 1.47632463 1.47601132\n",
      " 1.4765824  1.48946862 1.48891439 1.47613319 1.         1.48929783\n",
      " 0.53271029 1.4892374  1.48942601 1.47601636 0.83769831 1.\n",
      " 1.4761079  1.         1.47597673 0.82673223 1.         0.87364146\n",
      " 0.90250865 1.47661452 1.47614958 1.47615163 1.47609707 0.9023955\n",
      " 1.         1.         1.        ]\n",
      "[[1.62245902 0.96368567 1.51393997 1.00062426 1.60142975 1.53583245\n",
      "  1.66473683 1.53589742 1.65131085 1.55943423 0.98357059 1.57141918\n",
      "  0.83456868 1.58341357 1.54554468 1.53673918 0.94765693 0.91993379\n",
      "  1.55429119 0.8364069  1.52980624 1.12698837 0.98942794 1.25015894\n",
      "  0.97286758 1.67306884 1.56282552 1.56325118 1.55212352 1.06886131\n",
      "  0.81063684 0.82877737 0.95583227]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "4 loss 142772.6811704028\n",
      "[1.59787039 0.80291436 1.59820868 0.99999881 1.58029785 1.57961763\n",
      " 1.58085548 1.5982322  1.59776191 1.57987961 1.         1.59808402\n",
      " 0.50000989 1.59803189 1.59819543 1.57962824 0.74729866 1.\n",
      " 1.57982464 1.00000078 1.57954554 0.75497272 1.00000041 0.83733092\n",
      " 0.86012362 1.58092407 1.57991533 1.57991979 1.57980117 0.85273915\n",
      " 1.00000004 1.00004414 1.00012319]\n",
      "[[1.73283978 1.00244551 1.62418428 1.00062419 1.70780914 1.64199838\n",
      "  1.77130593 1.64616699 1.76173157 1.66567937 0.98357052 1.68173275\n",
      "  0.94963703 1.69374252 1.65582595 1.64290821 1.01227435 0.91993372\n",
      "  1.66051932 0.83640683 1.63595145 1.19857982 0.97649069 1.27169108\n",
      "  1.01160725 1.77966201 1.66908181 1.66950886 1.65834445 1.10153131\n",
      "  0.80020707 0.81426489 0.93351285]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "[1.59787039 0.80291436 1.59820868 0.99999881 1.58029785 1.57961763\n",
      " 1.58085548 1.5982322  1.59776191 1.57987961 1.         1.59808402\n",
      " 0.50000989 1.59803189 1.59819543 1.57962824 0.74729866 1.\n",
      " 1.57982464 1.00000078 1.57954554 0.75497272 1.00000041 0.83733092\n",
      " 0.86012362 1.58092407 1.57991533 1.57991979 1.57980117 0.85273915\n",
      " 1.00000004 1.00004414 1.00012319]\n",
      "[[1.73283978 1.00244551 1.62418428 1.00062419 1.70780914 1.64199838\n",
      "  1.77130593 1.64616699 1.76173157 1.66567937 0.98357052 1.68173275\n",
      "  0.94963703 1.69374252 1.65582595 1.64290821 1.01227435 0.91993372\n",
      "  1.66051932 0.83640683 1.63595145 1.19857982 0.97649069 1.27169108\n",
      "  1.01160725 1.77966201 1.66908181 1.66950886 1.65834445 1.10153131\n",
      "  0.80020707 0.81426489 0.93351285]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "acc 0.6576576576576577\n",
      "[[290 302]\n",
      " [  2 294]]\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print()\n",
    "    print(\"alpha-mean\",i)\n",
    "    train(0.1/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            af = tf.truncated_normal_initializer(i,0.001,seed),\n",
    "                          plv=np.array([-1,1],dtype=np.float64),smooth=True,penalty=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alpha-mean 0.0\n",
      "0 loss 258761.97377532846\n",
      "[ 0.09760699  0.06906155  0.07856466  0.09640611  0.09653547  0.09181254\n",
      "  0.09855085  0.07455734  0.07604416  0.09698834  0.09583047  0.07974186\n",
      "  0.10121241 -0.07568579  0.10015734  0.09719328  0.09931358  0.09386556\n",
      "  0.09543832  0.09541713  0.08916486 -0.03168285  0.09725393  0.07409003\n",
      "  0.06457212  0.09928821  0.09774973  0.09802521  0.09776105 -0.07706665\n",
      "  0.08102752  0.08125664  0.09399042]\n",
      "[[1.02183361 0.76346911 0.94839377 0.90496805 1.01156448 0.95517189\n",
      "  1.07388363 0.97576553 1.08656111 0.9691725  0.8882573  1.00127791\n",
      "  0.88250813 1.14733461 0.9423475  0.94631146 0.7545906  0.82570798\n",
      "  0.96529566 0.74009843 0.95249652 0.98549148 0.89985832 1.18311283\n",
      "  0.82864581 1.08103604 0.97220814 0.97224309 0.96137654 1.06089836\n",
      "  0.74204982 0.75805573 0.87081834]]\n",
      "{0: 167, 1: 721}\n",
      "acc 0.48761261261261263\n",
      "(0.3897364771151179, 0.9493243243243243, 0.5526057030481809, None)\n",
      "\n",
      "1 loss 223371.00639377302\n",
      "[ 0.19647516  0.1519857   0.16648469  0.19038969  0.18918612  0.18395212\n",
      "  0.19399375  0.15964104  0.16129418  0.19102225  0.18939546  0.16790559\n",
      "  0.20280651 -0.16092707  0.20087866  0.19187094  0.20040893  0.18803963\n",
      "  0.18972917  0.19066719  0.18054434 -0.04452787  0.19282655  0.15847535\n",
      "  0.14319498  0.19514014  0.19325478  0.19370261  0.19339747 -0.16272355\n",
      "  0.17000854  0.17029359  0.18790867]\n",
      "[[0.92422811 0.70108518 0.87740922 0.81280508 0.92055062 0.86810577\n",
      "  0.9811532  0.90956673 1.0161723  0.87703279 0.79642362 0.9266091\n",
      "  0.7825432  1.23083042 0.84317377 0.85363248 0.65548859 0.73324008\n",
      "  0.87288121 0.64668454 0.86546838 1.02288967 0.80644604 1.20240231\n",
      "  0.77250356 0.98754902 0.87906643 0.87885242 0.86826633 1.14535351\n",
      "  0.65338541 0.66930483 0.7807789 ]]\n",
      "{0: 29, 1: 859}\n",
      "acc 0.36599099099099097\n",
      "(0.3445867287543655, 1.0, 0.5125541125541125, None)\n",
      "\n",
      "2 loss 193922.88978011662\n",
      "[ 0.2946576   0.23959505  0.25746836  0.28381212  0.28041427  0.27915816\n",
      "  0.29012996  0.24874666  0.25045017  0.28451075  0.28219145  0.25898189\n",
      "  0.30270333 -0.25170085  0.30024098  0.28638661  0.29981208  0.28359156\n",
      "  0.28556467  0.2862949   0.27583394 -0.03101568  0.28885025  0.24758642\n",
      "  0.22754103  0.29145259  0.28935869  0.28985841  0.28956579 -0.25382674\n",
      "  0.26460058  0.26493675  0.28350794]\n",
      "[[0.82763529 0.63270445 0.80225977 0.72359184 0.83330489 0.78356884\n",
      "  0.89142496 0.83821826 0.94092889 0.78784029 0.70778174 0.84810106\n",
      "  0.68466087 1.32271212 0.74572652 0.76351628 0.55831023 0.64192663\n",
      "  0.78151366 0.55537281 0.78005952 1.04577924 0.71512596 1.2216414\n",
      "  0.71011642 0.89603004 0.78806916 0.78773768 0.77869428 1.2381653\n",
      "  0.55999917 0.57579866 0.69555217]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "3 loss 169903.04201030626\n",
      "[ 0.39171153  0.32772588  0.34847705  0.37779872  0.37149508  0.37697203\n",
      "  0.38792563  0.33817995  0.33988805  0.37860099  0.37540988  0.35003129\n",
      "  0.40117856 -0.34548008  0.39828858  0.38180781  0.39770716  0.38084616\n",
      "  0.38312072  0.38327206  0.37369065 -0.00226998  0.38629702  0.3372383\n",
      "  0.312861    0.38919055  0.38699197  0.38746515  0.38726639 -0.34784447\n",
      "  0.36167028  0.3620561   0.38119881]\n",
      "[[0.73339451 0.56636063 0.72994083 0.6404072  0.75319321 0.71226354\n",
      "  0.81275537 0.76932826 0.8677145  0.70464457 0.62557067 0.77200976\n",
      "  0.5898284  1.41709659 0.65109111 0.67881457 0.4642848  0.55455132\n",
      "  0.69406063 0.46969341 0.70558    1.05927275 0.6294628  1.24125649\n",
      "  0.64945384 0.80895106 0.70526597 0.70321057 0.70082521 1.33399816\n",
      "  0.46729925 0.48251793 0.62625581]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 150478.0547851803\n",
      "[ 0.48804488  0.41541092  0.43897188  0.47342714  0.46360946  0.47612111\n",
      "  0.48744362  0.42712082  0.42877802  0.47424854  0.47018055  0.44052177\n",
      "  0.4989072  -0.44040069  0.49561164  0.47905543  0.49472371  0.48041845\n",
      "  0.48273442  0.48275682  0.47269496  0.03160539  0.48585126  0.42631747\n",
      "  0.39778753  0.48894603  0.48650732  0.48704734  0.48677888 -0.44294568\n",
      "  0.45928785  0.45972133  0.4804336 ]\n",
      "[[0.64373711 0.50943642 0.66798023 0.63155131 0.72899961 0.66434651\n",
      "  0.79244338 0.71037431 0.80308335 0.69414276 0.61254207 0.70495354\n",
      "  0.50126951 1.51130039 0.56212054 0.67631997 0.37716316 0.55682755\n",
      "  0.69486188 0.46539142 0.64801503 1.07004934 0.62460854 1.26147546\n",
      "  0.59760582 0.81708243 0.68996374 0.69475092 0.68158789 1.43016967\n",
      "  0.37861081 0.39255788 0.58983833]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[ 0.48804488  0.41541092  0.43897188  0.47342714  0.46360946  0.47612111\n",
      "  0.48744362  0.42712082  0.42877802  0.47424854  0.47018055  0.44052177\n",
      "  0.4989072  -0.44040069  0.49561164  0.47905543  0.49472371  0.48041845\n",
      "  0.48273442  0.48275682  0.47269496  0.03160539  0.48585126  0.42631747\n",
      "  0.39778753  0.48894603  0.48650732  0.48704734  0.48677888 -0.44294568\n",
      "  0.45928785  0.45972133  0.4804336 ]\n",
      "[[0.64373711 0.50943642 0.66798023 0.63155131 0.72899961 0.66434651\n",
      "  0.79244338 0.71037431 0.80308335 0.69414276 0.61254207 0.70495354\n",
      "  0.50126951 1.51130039 0.56212054 0.67631997 0.37716316 0.55682755\n",
      "  0.69486188 0.46539142 0.64801503 1.07004934 0.62460854 1.26147546\n",
      "  0.59760582 0.81708243 0.68996374 0.69475092 0.68158789 1.43016967\n",
      "  0.37861081 0.39255788 0.58983833]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/snorkelEnv/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss 234151.0249429247\n",
      "[0.19806045 0.17301418 0.18142486 0.19625912 0.19624729 0.19126569\n",
      " 0.19848645 0.17789195 0.17930346 0.19683213 0.19564832 0.18255269\n",
      " 0.20088443 0.0270292  0.20009142 0.19709826 0.19905759 0.19369319\n",
      " 0.19528246 0.1954141  0.18820886 0.0759723  0.1972427  0.17741569\n",
      " 0.16916418 0.19927373 0.19771028 0.19800886 0.19771434 0.02561138\n",
      " 0.17918176 0.17941287 0.1936894 ]\n",
      "[[1.02197974 0.76605671 0.95114066 0.90567352 1.01230799 0.95745409\n",
      "  1.07473267 0.97857589 1.08884084 0.96988075 0.88897396 1.00345416\n",
      "  0.88307601 1.14544416 0.94277432 0.94700273 0.75525368 0.82633383\n",
      "  0.96588505 0.74078055 0.9551535  0.98543526 0.9005408  1.18350274\n",
      "  0.83097049 1.08170613 0.97296341 0.9729511  0.96213915 1.05915984\n",
      "  0.74376368 0.7596745  0.87238416]]\n",
      "{0: 164, 1: 724}\n",
      "acc 0.48873873873873874\n",
      "(0.39088397790055246, 0.956081081081081, 0.5549019607843136, None)\n",
      "\n",
      "1 loss 202293.79076913805\n",
      "[ 0.29633312  0.25646121  0.26945875  0.29061716  0.28913602  0.28385634\n",
      "  0.29442709  0.26324653  0.26476338  0.29123788  0.28956897  0.27080788\n",
      "  0.30173722 -0.0582902   0.30012043  0.2922028   0.29942775  0.28840537\n",
      "  0.29013231  0.29120377  0.27983681  0.06663689  0.29333455  0.26191806\n",
      "  0.24859525  0.29562671  0.29372575  0.29419763  0.29385473 -0.06013638\n",
      "  0.26838162  0.26866503  0.28808792]\n",
      "[[0.92558255 0.70960923 0.88580345 0.81465603 0.92243589 0.87310954\n",
      "  0.98342668 0.91830895 1.02354212 0.87888213 0.79828355 0.93360591\n",
      "  0.78458055 1.22912724 0.84498264 0.85546667 0.65784621 0.73488196\n",
      "  0.87444929 0.64852353 0.87066746 1.02551035 0.80829743 1.20335434\n",
      "  0.78081279 0.98936231 0.88103513 0.88076439 0.8705265  1.14401382\n",
      "  0.65557702 0.67137609 0.78475537]]\n",
      "{0: 26, 1: 862}\n",
      "acc 0.36261261261261263\n",
      "(0.3433874709976798, 1.0, 0.5112262521588946, None)\n",
      "\n",
      "2 loss 175533.05271583927\n",
      "[ 0.39399893  0.34324944  0.35967425  0.38475691  0.3810985   0.37994033\n",
      "  0.39127384  0.3514828   0.35299229  0.38544069  0.3831095   0.36109074\n",
      "  0.4012485  -0.15099684  0.3990543   0.38741563  0.39844924  0.38472574\n",
      "  0.38670949  0.38755763  0.37593423  0.07690643  0.39004894  0.34983795\n",
      "  0.33196272  0.39259736  0.39052572  0.39103666  0.39073402 -0.15313549\n",
      "  0.36387438  0.36420277  0.38451761]\n",
      "[[0.83085091 0.65101698 0.8197448  0.72902556 0.83856778 0.79613412\n",
      "  0.89987649 0.8565362  0.95650241 0.79326028 0.71320466 0.86289305\n",
      "  0.68892434 1.32208215 0.74963543 0.76900216 0.56330413 0.64709865\n",
      "  0.78658431 0.56131816 0.79135539 1.05527011 0.72108468 1.22335252\n",
      "  0.72865196 0.90159971 0.79473472 0.794121   0.78753797 1.23818776\n",
      "  0.5631469  0.57872829 0.70822198]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "3 loss 153504.6710651051\n",
      "[ 0.49079595  0.43054184  0.44999249  0.48004811  0.47349885  0.47840345\n",
      "  0.48994812  0.44004329  0.4414753   0.48075971  0.47767939  0.45140322\n",
      "  0.49969472 -0.24661173  0.49699407  0.48405046  0.49635495  0.48321897\n",
      "  0.48530714  0.48593004  0.474362    0.09947125  0.48864668  0.43814224\n",
      "  0.41610549  0.49135164  0.48916367  0.48967381  0.48940711 -0.2489423\n",
      "  0.4614217   0.46178651  0.48302099]\n",
      "[[0.7412063  0.6006368  0.76339556 0.70084217 0.80057204 0.74336277\n",
      "  0.86609425 0.80367079 0.89722222 0.76396928 0.68263829 0.80078717\n",
      "  0.60028946 1.4172311  0.66061852 0.74452504 0.47658257 0.62246347\n",
      "  0.76056558 0.53234921 0.7300805  1.07793317 0.6954208  1.24378651\n",
      "  0.68391885 0.88288476 0.76258166 0.76427225 0.75441797 1.33493107\n",
      "  0.47368629 0.48829136 0.66505913]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 138523.98775712954\n",
      "[ 0.5602053   0.50343247  0.51344918  0.50000187  0.49999928  0.50421818\n",
      "  0.5000555   0.50739956  0.50934464  0.50000749  0.50000431  0.51573239\n",
      "  0.56746183 -0.3446829   0.56547963  0.50000566  0.56207707  0.50006539\n",
      "  0.50000547  0.50000899  0.51795251  0.1253196   0.50000197  0.50650459\n",
      "  0.4997416   0.49999926  0.50000526  0.50000553  0.50000201 -0.34710491\n",
      "  0.55369338  0.55406966  0.5000126 ]\n",
      "[[0.64830637 0.57666777 0.73478767 0.80969558 0.90884397 0.71466229\n",
      "  0.90561205 0.77794869 0.86317243 0.87249748 0.79137359 0.76454098\n",
      "  0.50630698 1.51307173 0.56700173 0.85262496 0.38934544 0.73095721\n",
      "  0.86870064 0.62683561 0.68649793 1.09948216 0.7899793  1.26478914\n",
      "  0.66228444 0.98915907 0.82894058 0.84362068 0.79504378 1.43268159\n",
      "  0.39154064 0.40380571 0.65562618]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[ 0.5602053   0.50343247  0.51344918  0.50000187  0.49999928  0.50421818\n",
      "  0.5000555   0.50739956  0.50934464  0.50000749  0.50000431  0.51573239\n",
      "  0.56746183 -0.3446829   0.56547963  0.50000566  0.56207707  0.50006539\n",
      "  0.50000547  0.50000899  0.51795251  0.1253196   0.50000197  0.50650459\n",
      "  0.4997416   0.49999926  0.50000526  0.50000553  0.50000201 -0.34710491\n",
      "  0.55369338  0.55406966  0.5000126 ]\n",
      "[[0.64830637 0.57666777 0.73478767 0.80969558 0.90884397 0.71466229\n",
      "  0.90561205 0.77794869 0.86317243 0.87249748 0.79137359 0.76454098\n",
      "  0.50630698 1.51307173 0.56700173 0.85262496 0.38934544 0.73095721\n",
      "  0.86870064 0.62683561 0.68649793 1.09948216 0.7899793  1.26478914\n",
      "  0.66228444 0.98915907 0.82894058 0.84362068 0.79504378 1.43268159\n",
      "  0.39154064 0.40380571 0.65562618]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.2\n",
      "0 loss 210146.77225080357\n",
      "[0.29822143 0.27601338 0.28350503 0.29620341 0.29602698 0.29080942\n",
      " 0.29853916 0.28038252 0.28176266 0.29676785 0.29555458 0.28463166\n",
      " 0.30048075 0.12990602 0.2998761  0.29710466 0.29871152 0.29364502\n",
      " 0.29526395 0.29552969 0.28723665 0.1838378  0.29734823 0.27983713\n",
      " 0.27274573 0.29937619 0.297787   0.29810924 0.29777233 0.12845924\n",
      " 0.27707623 0.27730717 0.29347845]\n",
      "[[1.02265548 0.77181052 0.95699916 0.90672291 1.01336264 0.96110027\n",
      "  1.0760879  0.98452763 1.0940617  0.97092864 0.89002566 1.00847799\n",
      "  0.88418413 1.14328719 0.94373903 0.94804794 0.75660248 0.82724791\n",
      "  0.96674972 0.74184996 0.95924145 0.98658724 0.9016084  1.18393695\n",
      "  0.83637803 1.08274594 0.97414577 0.97406669 0.96337631 1.05721555\n",
      "  0.74586198 0.76162346 0.8749716 ]]\n",
      "{0: 160, 1: 728}\n",
      "acc 0.4864864864864865\n",
      "(0.3901098901098901, 0.9594594594594594, 0.5546875, None)\n",
      "\n",
      "1 loss 181589.2127959817\n",
      "[0.39593973 0.35974424 0.37149339 0.39098608 0.38920507 0.38398024\n",
      " 0.39504016 0.36579204 0.36722451 0.39159556 0.38988317 0.37283561\n",
      " 0.40071123 0.04414306 0.39930557 0.39268485 0.39848275 0.38897228\n",
      " 0.39075531 0.39191015 0.37919652 0.17716995 0.39400796 0.3641306\n",
      " 0.35265752 0.39627748 0.39436677 0.39485837 0.3944672  0.04227441\n",
      " 0.36659458 0.36687253 0.38844906]\n",
      "[[0.9284438  0.72673281 0.9028074  0.81846522 0.92608992 0.8828484\n",
      "  0.98858917 0.93566976 1.03892513 0.88267248 0.80206008 0.94848869\n",
      "  0.78834402 1.22721107 0.84844424 0.85932382 0.66245375 0.73842397\n",
      "  0.87789111 0.65258553 0.87999348 1.03101694 0.81237219 1.20436815\n",
      "  0.79747703 0.99329914 0.88535677 0.8850052  0.87579739 1.14266148\n",
      "  0.65859573 0.67418661 0.79331309]]\n",
      "{0: 12, 1: 876}\n",
      "acc 0.34684684684684686\n",
      "(0.3378995433789954, 1.0, 0.5051194539249148, None)\n",
      "\n",
      "2 loss 157278.2922874035\n",
      "[ 0.49315162  0.44581214  0.46103562  0.48605095  0.48204548  0.48099979\n",
      "  0.49281066  0.45322302  0.45457183  0.48669785  0.48437003  0.4624138\n",
      "  0.49995001 -0.05042218  0.49790465  0.48880676  0.49727555  0.48629564\n",
      "  0.48825558  0.48932841  0.47611394  0.1836553   0.49167853  0.45074667\n",
      "  0.43509345  0.49410679  0.49209862  0.49261898  0.49230144 -0.0525413\n",
      "  0.4629353   0.46324955  0.4858568 ]\n",
      "[[0.83933121 0.68851104 0.85753029 0.76051905 0.86469703 0.82314576\n",
      "  0.93679093 0.89449549 0.99049098 0.82429936 0.74356883 0.89661471\n",
      "  0.70013657 1.32107484 0.75988647 0.8026788  0.57721518 0.67956984\n",
      "  0.81828115 0.5971065  0.81328581 1.06897471 0.75816684 1.2250852\n",
      "  0.7651815  0.93875648 0.83019348 0.83042601 0.8240939  1.23812594\n",
      "  0.56861733 0.58375354 0.73987598]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "3 loss 141364.86228410606\n",
      "[ 0.55840104  0.50541601  0.51407827  0.50000208  0.50000169  0.51480066\n",
      "  0.50006294  0.50908451  0.51192026  0.50000396  0.49999995  0.51715971\n",
      "  0.56348525 -0.14949874  0.56217657  0.50000306  0.55818028  0.50166226\n",
      "  0.50000387  0.49999991  0.52568387  0.19612587  0.49999813  0.50744249\n",
      "  0.50160634  0.50000445  0.50000329  0.50000289  0.50000539 -0.15172981\n",
      "  0.55598382  0.55632095  0.5001192 ]\n",
      "[[0.74634394 0.67788563 0.84075747 0.86465242 0.965088   0.78791927\n",
      "  0.95606335 0.88116283 0.96885639 0.92777251 0.84719887 0.87231698\n",
      "  0.60615607 1.41827933 0.66622903 0.9071016  0.49339448 0.78466113\n",
      "  0.9221556  0.68191987 0.76496903 1.10411461 0.83931382 1.24625249\n",
      "  0.7582831  1.04242113 0.8752167  0.88911818 0.84442386 1.3370845\n",
      "  0.48436894 0.49767572 0.72097298]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 136477.1756647597\n",
      "[ 0.65413073  0.53304596  0.55302018  0.5000027   0.50000351  0.53377791\n",
      "  0.50006546  0.5422389   0.55378022  0.50000718  0.50001152  0.56389066\n",
      "  0.65892146 -0.24833691  0.65776421  0.50000073  0.6491468   0.5007618\n",
      "  0.50000697  0.50000068  0.56268404  0.21005558  0.50000241  0.54049305\n",
      "  0.5206678   0.50001304  0.50000008  0.50001179  0.50000184 -0.25064912\n",
      "  0.64623789  0.64611487  0.50007667]\n",
      "[[0.65208529 0.67645003 0.82990266 0.96591137 1.06645509 0.75431637\n",
      "  0.97866041 0.87522021 0.95498152 1.02909712 0.94844077 0.85427352\n",
      "  0.51182978 1.51529472 0.57194926 1.00840383 0.41193128 0.88577688\n",
      "  1.02342067 0.76564181 0.71796493 1.1390218  0.91970059 1.26754702\n",
      "  0.76366961 1.14387397 0.92252661 0.95127542 0.86866788 1.43567765\n",
      "  0.41111701 0.41905412 0.70432923]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[ 0.65413073  0.53304596  0.55302018  0.5000027   0.50000351  0.53377791\n",
      "  0.50006546  0.5422389   0.55378022  0.50000718  0.50001152  0.56389066\n",
      "  0.65892146 -0.24833691  0.65776421  0.50000073  0.6491468   0.5007618\n",
      "  0.50000697  0.50000068  0.56268404  0.21005558  0.50000241  0.54049305\n",
      "  0.5206678   0.50001304  0.50000008  0.50001179  0.50000184 -0.25064912\n",
      "  0.64623789  0.64611487  0.50007667]\n",
      "[[0.65208529 0.67645003 0.82990266 0.96591137 1.06645509 0.75431637\n",
      "  0.97866041 0.87522021 0.95498152 1.02909712 0.94844077 0.85427352\n",
      "  0.51182978 1.51529472 0.57194926 1.00840383 0.41193128 0.88577688\n",
      "  1.02342067 0.76564181 0.71796493 1.1390218  0.91970059 1.26754702\n",
      "  0.76366961 1.14387397 0.92252661 0.95127542 0.86866788 1.43567765\n",
      "  0.41111701 0.41905412 0.70432923]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.30000000000000004\n",
      "0 loss 186740.5106961482\n",
      "[0.39819197 0.37822567 0.38495679 0.39624273 0.39588392 0.39053083\n",
      " 0.39871938 0.38217542 0.3835678  0.39679969 0.39555521 0.38614299\n",
      " 0.40006862 0.23272214 0.39959107 0.39721409 0.39835371 0.39375036\n",
      " 0.3954208  0.39576374 0.38633441 0.29149336 0.39756954 0.38144359\n",
      " 0.37544491 0.3995936  0.39798361 0.39832582 0.39793247 0.23126598\n",
      " 0.37477584 0.37500297 0.39339871]\n",
      "[[1.02460832 0.78430867 0.96987341 0.90885046 1.01537494 0.96820081\n",
      "  1.07906019 0.99731845 1.10602527 0.97304086 0.89212364 1.02029234\n",
      "  0.88668759 1.1408144  0.94606071 0.95020998 0.7598579  0.82912207\n",
      "  0.96856038 0.7441549  0.96665302 0.98985332 0.90390485 1.18441862\n",
      "  0.84827582 1.0849637  0.9766744  0.97648497 0.9661567  1.05509159\n",
      "  0.74857757 0.7640846  0.88052311]]\n",
      "{0: 143, 1: 745}\n",
      "acc 0.48085585585585583\n",
      "(0.38926174496644295, 0.9797297297297297, 0.5571565802113353, None)\n",
      "\n",
      "1 loss 161143.95313875042\n",
      "[0.49545535 0.46218259 0.47289721 0.49158425 0.48947189 0.4844651\n",
      " 0.49594179 0.46758174 0.4689915  0.49217524 0.49042795 0.47432921\n",
      " 0.49986777 0.14618109 0.4985788  0.49339947 0.49776976 0.48985349\n",
      " 0.4916999  0.49290981 0.47873775 0.28672578 0.49494126 0.46526774\n",
      " 0.45568712 0.49715954 0.49527074 0.49577479 0.49533874 0.14432878\n",
      " 0.46469051 0.46495655 0.48912799]\n",
      "[[0.93819536 0.7640191  0.94203041 0.83466921 0.94034942 0.90628107\n",
      "  1.01120578 0.9739351  1.07532816 0.89865632 0.81780006 0.98556061\n",
      "  0.80100472 1.22481801 0.8600785  0.87619616 0.6792271  0.75414964\n",
      "  0.89339595 0.67159203 0.90005788 1.04089956 0.83134384 1.20543751\n",
      "  0.83289559 1.01121422 0.90496166 0.90468202 0.89832337 1.14121677\n",
      "  0.66348374 0.67865681 0.8184316 ]]\n",
      "{0: 4, 1: 884}\n",
      "acc 0.33783783783783783\n",
      "(0.334841628959276, 1.0, 0.5016949152542373, None)\n",
      "\n",
      "2 loss 145139.2654390534\n",
      "[0.55225905 0.50242051 0.5083472  0.50002078 0.49999861 0.5258019\n",
      " 0.50018774 0.50497098 0.50905444 0.50001664 0.50002155 0.51231883\n",
      " 0.55446273 0.04859852 0.55410625 0.49999873 0.54794247 0.50276472\n",
      " 0.50247454 0.50000739 0.53297315 0.28560593 0.50001792 0.50327074\n",
      " 0.50007727 0.5010695  0.50001507 0.50001097 0.50000424 0.04656071\n",
      " 0.55729164 0.55757681 0.51433659]\n",
      "[[0.84481349 0.76956842 0.94076944 0.89008211 0.97827366 0.8644771\n",
      "  0.99862458 0.97624434 1.07025089 0.94558318 0.87447508 0.97766347\n",
      "  0.70680571 1.32037085 0.76611298 0.92727739 0.60490051 0.81571191\n",
      "  0.94006499 0.70412776 0.84714041 1.09060627 0.84363626 1.22678541\n",
      "  0.84260923 1.03575504 0.90186501 0.9059038  0.88792488 1.23888893\n",
      "  0.57765599 0.59180342 0.78845349]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "3 loss 140563.80782569016\n",
      "[ 0.64873125  0.51227889  0.52935575  0.50001084  0.50001317  0.55994508\n",
      "  0.50014204  0.52047359  0.53332945  0.50001272  0.50001256  0.54121087\n",
      "  0.65083143 -0.05103429  0.65053901  0.50001246  0.635237    0.50261842\n",
      "  0.50189295  0.50000939  0.58048407  0.28594841  0.50000894  0.51799927\n",
      "  0.50340606  0.50062588  0.50000179  0.50000851  0.50001078 -0.0531733\n",
      "  0.64872287  0.64861572  0.53165825]\n",
      "[[0.75010842 0.77757286 0.9398634  0.99725611 1.08785126 0.82404996\n",
      "  0.99420404 0.97982141 1.06666455 1.05411969 0.98133765 0.97030433\n",
      "  0.61192855 1.41825939 0.67132445 1.03531748 0.53238089 0.92133239\n",
      "  1.04800534 0.75854968 0.79543288 1.13931737 0.88534696 1.24816621\n",
      "  0.8566458  1.14772221 0.91234973 0.9251149  0.88576717 1.33846837\n",
      "  0.50115645 0.51090604 0.76111209]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 136512.10152937987\n",
      "[ 0.74475889  0.52829016  0.5552156   0.50000773  0.50000089  0.59046603\n",
      "  0.5000935   0.54133566  0.56185825  0.50000713  0.50000537  0.57393111\n",
      "  0.74662588 -0.15011586  0.74644627  0.50000677  0.72053819  0.50230422\n",
      "  0.50157915  0.50000152  0.62562525  0.28941336  0.50000578  0.53809938\n",
      "  0.51220631  0.5000096   0.50000361  0.50000551  0.50000705 -0.15233725\n",
      "  0.72194107  0.72983704  0.54298518]\n",
      "[[0.65680223 0.78257205 0.93669819 1.10292451 1.19454908 0.78561497\n",
      "  0.99844124 0.98084357 1.06123841 1.16039528 1.08685548 0.96134822\n",
      "  0.51842425 1.51583956 0.57792353 1.14137923 0.46479388 1.02621607\n",
      "  1.1540454  0.82429557 0.74520728 1.18627034 0.94408154 1.26952931\n",
      "  0.86757357 1.25525202 0.93524876 0.96065247 0.89219548 1.43748606\n",
      "  0.45626854 0.45612044 0.73688042]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[ 0.74475889  0.52829016  0.5552156   0.50000773  0.50000089  0.59046603\n",
      "  0.5000935   0.54133566  0.56185825  0.50000713  0.50000537  0.57393111\n",
      "  0.74662588 -0.15011586  0.74644627  0.50000677  0.72053819  0.50230422\n",
      "  0.50157915  0.50000152  0.62562525  0.28941336  0.50000578  0.53809938\n",
      "  0.51220631  0.5000096   0.50000361  0.50000551  0.50000705 -0.15233725\n",
      "  0.72194107  0.72983704  0.54298518]\n",
      "[[0.65680223 0.78257205 0.93669819 1.10292451 1.19454908 0.78561497\n",
      "  0.99844124 0.98084357 1.06123841 1.16039528 1.08685548 0.96134822\n",
      "  0.51842425 1.51583956 0.57792353 1.14137923 0.46479388 1.02621607\n",
      "  1.1540454  0.82429557 0.74520728 1.18627034 0.94408154 1.26952931\n",
      "  0.86757357 1.25525202 0.93524876 0.96065247 0.89219548 1.43748606\n",
      "  0.45626854 0.45612044 0.73688042]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.4\n",
      "0 loss 163846.17872247\n",
      "[0.49812375 0.47992678 0.48602098 0.4964117  0.49585439 0.49056294\n",
      " 0.49907779 0.48351422 0.48497374 0.49695885 0.49568711 0.48735919\n",
      " 0.49979346 0.33527665 0.49938183 0.49745612 0.49819034 0.49406565\n",
      " 0.49581048 0.4961592  0.48563203 0.3986425  0.4979379  0.4823691\n",
      " 0.47751    0.49994472 0.49833778 0.4986891  0.49823254 0.33384118\n",
      " 0.47234912 0.47256656 0.49355594]\n",
      "[[1.03603587 0.81272798 1.00088874 0.91781367 1.0233735  0.98651789\n",
      "  1.09222546 1.02681643 1.13592719 0.98186127 0.9008171  1.05171841\n",
      "  0.9009136  1.13761036 0.95928972 0.95945634 0.77917246 0.83728411\n",
      "  0.9766762  0.75446107 0.9838582  0.99657359 0.91412173 1.18494406\n",
      "  0.8751637  1.09464254 0.98776701 0.98727257 0.97874843 1.05256689\n",
      "  0.75277447 0.76778149 0.89921638]]\n",
      "{0: 125, 1: 763}\n",
      "acc 0.46283783783783783\n",
      "(0.381389252948886, 0.9831081081081081, 0.5495750708215297, None)\n",
      "\n",
      "1 loss 148897.73436784337\n",
      "[0.54296518 0.50008692 0.5012305  0.52011293 0.52375859 0.5316684\n",
      " 0.52468107 0.50019779 0.50214898 0.52292867 0.51914609 0.50356417\n",
      " 0.54146531 0.24831328 0.54237844 0.52231751 0.53269737 0.51529175\n",
      " 0.52185822 0.51401486 0.5356583  0.39416251 0.52032853 0.50013804\n",
      " 0.50010824 0.52854479 0.52282649 0.52292647 0.5228442  0.24651716\n",
      " 0.55730174 0.55753898 0.52596468]\n",
      "[[0.94019034 0.83177638 1.01311909 0.84308819 0.94632747 0.94553827\n",
      "  1.04923759 1.04241335 1.14541408 0.90554546 0.82655187 1.05846997\n",
      "  0.80523982 1.2204472  0.86339636 0.88360785 0.72566932 0.76518518\n",
      "  0.90079369 0.69624175 0.93512036 1.05772063 0.85104279 1.20643539\n",
      "  0.89777951 1.01585277 0.93296189 0.93022802 0.93742704 1.13858177\n",
      "  0.67245489 0.68660948 0.862445  ]]\n",
      "{0: 14, 1: 874}\n",
      "acc 0.3490990990990991\n",
      "(0.33867276887871856, 1.0, 0.505982905982906, None)\n",
      "\n",
      "2 loss 145132.67821288746\n",
      "[0.64123293 0.50105208 0.51063819 0.50003524 0.50005242 0.57180041\n",
      " 0.53613261 0.50468115 0.51498627 0.50004067 0.50001305 0.52067468\n",
      " 0.63982887 0.15096756 0.64071365 0.50002492 0.61606195 0.50296698\n",
      " 0.50272341 0.5000314  0.5869989  0.38890544 0.5000068  0.5025117\n",
      " 0.50009044 0.50182027 0.5213286  0.5155016  0.53121421 0.14898714\n",
      " 0.64799517 0.6478805  0.55419636]\n",
      "[[0.84418514 0.84513349 1.01778141 0.80896147 0.87702372 0.90300631\n",
      "  1.02854234 1.05133126 1.14741929 0.84619873 0.80030311 1.05693019\n",
      "  0.70885028 1.3149362  0.76718578 0.83191118 0.65950777 0.76902084\n",
      "  0.84449786 0.69351625 0.88218379 1.11888438 0.82970762 1.22786912\n",
      "  0.91653564 0.9378682  0.91346355 0.91209825 0.9187508  1.23577796\n",
      "  0.59434024 0.60540006 0.83011196]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "3 loss 141176.05942183232\n",
      "[0.73731459 0.50636167 0.52646308 0.50002143 0.50002504 0.60987862\n",
      " 0.53100896 0.51548469 0.53374171 0.50002454 0.50000935 0.54355037\n",
      " 0.73586101 0.0511561  0.73677473 0.50002446 0.69637396 0.50287883\n",
      " 0.50252642 0.50001379 0.63728352 0.38397832 0.50000667 0.51169014\n",
      " 0.50100749 0.50106783 0.50001129 0.50002325 0.52320438 0.04907156\n",
      " 0.72279652 0.73027277 0.57770877]\n",
      "[[0.75114268 0.85512155 1.01933064 0.92435643 0.9818792  0.86106609\n",
      "  1.0169393  1.05703232 1.1466165  0.95959538 0.91515113 1.05270412\n",
      "  0.6155064  1.41264091 0.67398257 0.94723714 0.59885087 0.88022493\n",
      "  0.95626712 0.72780994 0.82950257 1.17888875 0.84613469 1.24927403\n",
      "  0.932454   1.015577   0.91094131 0.91422526 0.90919285 1.33549033\n",
      "  0.54449485 0.54610233 0.8001337 ]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 137495.64772730132\n",
      "[ 0.83208115  0.51784999  0.54743046  0.50000658  0.50001155  0.64505714\n",
      "  0.5114316   0.53181388  0.55707341  0.50000559  0.49999928  0.5706993\n",
      "  0.8305082  -0.04830619  0.83148485  0.50001006  0.773166    0.50265339\n",
      "  0.50188633  0.50000426  0.68568302  0.38131839  0.50000684  0.52654337\n",
      "  0.50525864  0.50047288  0.50000241  0.49999916  0.50075314 -0.05047307\n",
      "  0.76348617  0.76799914  0.59635509]\n",
      "[[0.66074772 0.86206026 1.01844292 1.03300011 1.09234129 0.82078696\n",
      "  1.01296221 1.0600571  1.1437323  1.06926841 1.02356101 1.04659337\n",
      "  0.52474066 1.51040705 0.5833944  1.0565224  0.54436486 0.98750588\n",
      "  1.06538978 0.78015149 0.77809524 1.23713214 0.88851889 1.27065718\n",
      "  0.94532867 1.12726778 0.92139761 0.93431479 0.90734001 1.43486037\n",
      "  0.52091482 0.53976379 0.77278951]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[ 0.83208115  0.51784999  0.54743046  0.50000658  0.50001155  0.64505714\n",
      "  0.5114316   0.53181388  0.55707341  0.50000559  0.49999928  0.5706993\n",
      "  0.8305082  -0.04830619  0.83148485  0.50001006  0.773166    0.50265339\n",
      "  0.50188633  0.50000426  0.68568302  0.38131839  0.50000684  0.52654337\n",
      "  0.50525864  0.50047288  0.50000241  0.49999916  0.50075314 -0.05047307\n",
      "  0.76348617  0.76799914  0.59635509]\n",
      "[[0.66074772 0.86206026 1.01844292 1.03300011 1.09234129 0.82078696\n",
      "  1.01296221 1.0600571  1.1437323  1.06926841 1.02356101 1.04659337\n",
      "  0.52474066 1.51040705 0.5833944  1.0565224  0.54436486 0.98750588\n",
      "  1.06538978 0.78015149 0.77809524 1.23713214 0.88851889 1.27065718\n",
      "  0.94532867 1.12726778 0.92139761 0.93431479 0.90734001 1.43486037\n",
      "  0.52091482 0.53976379 0.77278951]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.5\n",
      "0 loss 151368.55182659463\n",
      "[0.55616043 0.50003111 0.50008119 0.58288913 0.58487763 0.53665535\n",
      " 0.56722344 0.50001622 0.50012334 0.5841125  0.57442603 0.50045573\n",
      " 0.54737853 0.44314513 0.55138992 0.58368999 0.52738873 0.56061844\n",
      " 0.58027855 0.55320025 0.53264423 0.49956767 0.57598975 0.50019459\n",
      " 0.50009564 0.58613606 0.57506712 0.57682992 0.56769929 0.44183277\n",
      " 0.55903482 0.55923918 0.53715212]\n",
      "[[1.00159007 0.83966713 1.02860517 0.91616139 1.02124633 1.01370532\n",
      "  1.11537714 1.05328797 1.1630079  0.9798412  0.89870068 1.08084756\n",
      "  0.88296068 1.12625092 0.93405657 0.95749595 0.8268231  0.83460796\n",
      "  0.97455859 0.75796816 1.01165489 1.00531855 0.91809104 1.18612399\n",
      "  0.90057573 1.09195668 1.00088399 0.99866936 1.00082505 1.04159381\n",
      "  0.76372236 0.77730182 0.93196151]]\n",
      "{0: 185, 1: 703}\n",
      "acc 0.48986486486486486\n",
      "(0.3883357041251778, 0.9222972972972973, 0.5465465465465464, None)\n",
      "\n",
      "1 loss 148927.2751199948\n",
      "[0.6571199  0.50017359 0.50420466 0.57926865 0.60940772 0.56808911\n",
      " 0.59228513 0.5014476  0.50728594 0.5969857  0.56976155 0.51134878\n",
      " 0.64871593 0.36402385 0.65256944 0.59050825 0.61095293 0.54533379\n",
      " 0.59356174 0.55353798 0.57070625 0.49924332 0.59655552 0.50023574\n",
      " 0.50005516 0.62876382 0.60000325 0.5998714  0.59071716 0.36228639\n",
      " 0.63687523 0.6367683  0.56340917]\n",
      "[[0.90442703 0.85540395 1.03621707 0.84016771 0.94418177 0.98177385\n",
      "  1.08868115 1.0648878  1.16791781 0.90302821 0.82270522 1.08229864\n",
      "  0.78516831 1.19743763 0.83655054 0.88088986 0.760205   0.75976745\n",
      "  0.89767797 0.72234807 0.97324242 1.07654882 0.87577442 1.2075865\n",
      "  0.92018226 1.01448096 0.96724951 0.96545207 0.97450316 1.11716481\n",
      "  0.69515828 0.70564276 0.90435702]]\n",
      "{0: 36, 1: 852}\n",
      "acc 0.3738738738738739\n",
      "(0.3474178403755869, 1.0, 0.5156794425087108, None)\n",
      "\n",
      "2 loss 145980.2986523176\n",
      "[0.75091459 0.50021084 0.51110988 0.50006293 0.50521259 0.6075589\n",
      " 0.60651568 0.50359973 0.51735285 0.50009338 0.50000606 0.5252741\n",
      " 0.74253672 0.26845308 0.74638359 0.50006169 0.68440713 0.50360547\n",
      " 0.50386222 0.51789767 0.62102589 0.49371092 0.58131302 0.50032291\n",
      " 0.50008448 0.53739314 0.60404075 0.60136665 0.60251195 0.26650047\n",
      " 0.71494639 0.71915338 0.59261195]\n",
      "[[0.81386093 0.86958568 1.04210585 0.73944135 0.84022344 0.9407031\n",
      "  1.06832974 1.07479209 1.1713511  0.79939807 0.72391586 1.08245327\n",
      "  0.69423983 1.28800037 0.74578423 0.77801671 0.70559953 0.67125043\n",
      "  0.79471579 0.70418451 0.92190635 1.1507528  0.85172691 1.22902963\n",
      "  0.93947011 0.91197209 0.94734021 0.94651467 0.95524553 1.21179269\n",
      "  0.63845671 0.64024426 0.87223271]]\n",
      "{0: 2, 1: 886}\n",
      "acc 0.3355855855855856\n",
      "(0.3340857787810384, 1.0, 0.5008460236886634, None)\n",
      "\n",
      "3 loss 142657.1981813031\n",
      "[0.8456093  0.50251957 0.5228807  0.50003265 0.50003654 0.64739673\n",
      " 0.60975229 0.51073352 0.53186297 0.50003554 0.50003035 0.5434807\n",
      " 0.83743024 0.16904832 0.84119672 0.50001215 0.75442382 0.50293305\n",
      " 0.50264348 0.50002147 0.67247986 0.48576019 0.53066567 0.50569842\n",
      " 0.50008563 0.50140729 0.5893055  0.57785273 0.60320931 0.16697499\n",
      " 0.76058158 0.76641928 0.61942652]\n",
      "[[0.72433202 0.88123855 1.0456319  0.81387047 0.86604399 0.89830264\n",
      "  1.05436013 1.08221959 1.17269305 0.84583672 0.80538929 1.08066211\n",
      "  0.60395517 1.38433925 0.65583695 0.8346265  0.65789832 0.77468876\n",
      "  0.84185492 0.71764119 0.868969   1.22369813 0.85171024 1.25045044\n",
      "  0.95684859 0.89659965 0.9402602  0.9425511  0.94275453 1.31086003\n",
      "  0.60825927 0.61985576 0.84097067]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 139315.09748152006\n",
      "[0.93564021 0.50968254 0.53934444 0.5000193  0.50002006 0.6854004\n",
      " 0.60249229 0.52283858 0.55057739 0.50000434 0.50001272 0.56564818\n",
      " 0.92797684 0.06918836 0.9315277  0.5000063  0.81870039 0.50279419\n",
      " 0.50222204 0.50000796 0.72280978 0.4784502  0.50000705 0.51626857\n",
      " 0.50188905 0.50085467 0.55869162 0.53390187 0.59364969 0.06702888\n",
      " 0.78813741 0.78251042 0.64277702]\n",
      "[[0.64395241 0.89018951 1.04693834 0.92360791 0.97923301 0.85690292\n",
      "  1.04599458 1.08723574 1.17212216 0.95742395 0.9147334  1.077131\n",
      "  0.52189753 1.48197412 0.57452416 0.94548748 0.6172889  0.8821183\n",
      "  0.95207051 0.75452829 0.81682842 1.29482569 0.87380681 1.2718497\n",
      "  0.97173646 1.01233928 0.94248292 0.95052914 0.93592174 1.41051742\n",
      "  0.58835353 0.62062757 0.81163638]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[0.93564021 0.50968254 0.53934444 0.5000193  0.50002006 0.6854004\n",
      " 0.60249229 0.52283858 0.55057739 0.50000434 0.50001272 0.56564818\n",
      " 0.92797684 0.06918836 0.9315277  0.5000063  0.81870039 0.50279419\n",
      " 0.50222204 0.50000796 0.72280978 0.4784502  0.50000705 0.51626857\n",
      " 0.50188905 0.50085467 0.55869162 0.53390187 0.59364969 0.06702888\n",
      " 0.78813741 0.78251042 0.64277702]\n",
      "[[0.64395241 0.89018951 1.04693834 0.92360791 0.97923301 0.85690292\n",
      "  1.04599458 1.08723574 1.17212216 0.95742395 0.9147334  1.077131\n",
      "  0.52189753 1.48197412 0.57452416 0.94548748 0.6172889  0.8821183\n",
      "  0.95207051 0.75452829 0.81682842 1.29482569 0.87380681 1.2718497\n",
      "  0.97173646 1.01233928 0.94248292 0.95052914 0.93592174 1.41051742\n",
      "  0.58835353 0.62062757 0.81163638]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.6000000000000001\n",
      "0 loss 151070.04968550202\n",
      "[0.7100312  0.57418233 0.5824313  0.68044697 0.6827378  0.62771296\n",
      " 0.6535066  0.57969128 0.58607797 0.68186428 0.68005313 0.58783509\n",
      " 0.69632263 0.55669071 0.70261765 0.68137777 0.63293874 0.67851152\n",
      " 0.68175493 0.66942482 0.62303135 0.53824994 0.67353768 0.57802203\n",
      " 0.57378252 0.68415518 0.66441633 0.66645546 0.65417283 0.54929844\n",
      " 0.65369588 0.65333552 0.62843143]\n",
      "[[1.01091522 0.83921447 1.02895548 0.91831226 1.02325235 1.01939494\n",
      "  1.12932677 1.05355753 1.16394247 0.98189872 0.90140628 1.08156152\n",
      "  0.87044758 1.11958062 0.93159832 0.95958411 0.80732299 0.83836977\n",
      "  0.97683873 0.76822063 1.01802121 1.00383745 0.92632396 1.18525391\n",
      "  0.89995565 1.0938882  1.0131493  1.01244895 1.01540976 1.03276681\n",
      "  0.77442174 0.78369828 0.94072303]]\n",
      "{0: 179, 1: 709}\n",
      "acc 0.49436936936936937\n",
      "(0.3921015514809591, 0.9391891891891891, 0.5532338308457712, None)\n",
      "\n",
      "1 loss 149113.2090113169\n",
      "[0.8072753  0.56305674 0.57894243 0.64874278 0.67743385 0.65663161\n",
      " 0.6715885  0.5723568  0.58503426 0.66535595 0.64471519 0.5904483\n",
      " 0.79411139 0.48458002 0.80016678 0.65924903 0.70585463 0.63087507\n",
      " 0.66394456 0.65448803 0.65776033 0.49945534 0.68244037 0.56811683\n",
      " 0.55907875 0.69929365 0.68015248 0.67939944 0.67063496 0.4736866\n",
      " 0.71655332 0.72160331 0.65172033]\n",
      "[[0.91902975 0.85783838 1.04119277 0.83827627 0.94344128 0.9899013\n",
      "  1.10921443 1.06922611 1.17429795 0.9017143  0.82158716 1.08874436\n",
      "  0.77757676 1.18193753 0.8391698  0.8793412  0.75414528 0.76019405\n",
      "  0.89663143 0.74815007 0.98286099 1.07538795 0.89704108 1.2067514\n",
      "  0.92208398 1.01520007 0.98935521 0.98997414 0.99533485 1.10191621\n",
      "  0.7307784  0.72826429 0.91606143]]\n",
      "{0: 36, 1: 852}\n",
      "acc 0.3738738738738739\n",
      "(0.3474178403755869, 1.0, 0.5156794425087108, None)\n",
      "\n",
      "2 loss 146855.16268205547\n",
      "[0.89685657 0.55403965 0.57762705 0.54584513 0.58112307 0.69432827\n",
      " 0.68479314 0.56715447 0.58597754 0.56524665 0.5414534  0.59482139\n",
      " 0.88428203 0.39120894 0.89008777 0.55783246 0.76555435 0.52695371\n",
      " 0.5634995  0.62699012 0.70582049 0.49632789 0.67024889 0.56085053\n",
      " 0.54529146 0.61398367 0.68419319 0.68163733 0.68207614 0.38038249\n",
      " 0.7606199  0.76693547 0.68006817]\n",
      "[[0.83680043 0.87539883 1.05229701 0.73104439 0.83562899 0.95121756\n",
      "  1.09167156 1.08376485 1.18364246 0.7939255  0.71458597 1.09509238\n",
      "  0.69382171 1.26518015 0.75608679 0.77168716 0.71476261 0.6543976\n",
      "  0.7888666  0.73601174 0.93429383 1.14943648 0.87955733 1.22823671\n",
      "  0.94409732 0.9081834  0.97332575 0.97507085 0.97831024 1.19182754\n",
      "  0.69990104 0.70342335 0.88570979]]\n",
      "{0: 2, 1: 886}\n",
      "acc 0.3355855855855856\n",
      "(0.3340857787810384, 1.0, 0.5008460236886634, None)\n",
      "\n",
      "3 loss 144144.18842481228\n",
      "[0.97951131 0.54765104 0.57878105 0.50000288 0.50004836 0.73509062\n",
      " 0.69385867 0.56450922 0.58917822 0.50004155 0.5000255  0.60123135\n",
      " 0.96965964 0.29253393 0.97432958 0.50000671 0.81631131 0.50304314\n",
      " 0.5027276  0.58728679 0.75776964 0.48885194 0.64520278 0.55646631\n",
      " 0.53365053 0.50179009 0.68115068 0.67379592 0.68955778 0.28159423\n",
      " 0.79097786 0.78618756 0.70919563]\n",
      "[[0.7726055  0.89158765 1.06212957 0.6930862  0.75423271 0.90932211\n",
      "  1.07676327 1.09694841 1.19185119 0.72698587 0.6847142  1.10047322\n",
      "  0.62370318 1.35851302 0.68851212 0.71441902 0.68453875 0.65283633\n",
      "  0.72555001 0.7330392  0.88201546 1.22316371 0.87172389 1.24971006\n",
      "  0.96505822 0.81277714 0.96333607 0.96698423 0.96417964 1.28935315\n",
      "  0.67603577 0.69528523 0.85421741]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 141054.7531847023\n",
      "[1.         0.54750633 0.58590525 0.50000413 0.50001999 0.77492814\n",
      " 0.69307486 0.56788328 0.59805856 0.50002322 0.50000846 0.61325297\n",
      " 1.         0.19261938 1.         0.50001072 0.86410095 0.50290134\n",
      " 0.5025789  0.5180096  0.80945006 0.48118722 0.58735232 0.55827055\n",
      " 0.52792546 0.50113464 0.66155762 0.64370828 0.68718199 0.18159776\n",
      " 0.81918297 0.79581571 0.73559634]\n",
      "[[0.76634502 0.90464402 1.06899358 0.80682338 0.86468462 0.86767258\n",
      "  1.06709832 1.10710407 1.19725839 0.84182573 0.79781516 1.10312705\n",
      "  0.61147422 1.45509389 0.67926661 0.82940989 0.65776156 0.7626567\n",
      "  0.83852767 0.75741314 0.82988322 1.29510188 0.88696418 1.27115832\n",
      "  0.98303934 0.90008562 0.96279616 0.97124149 0.95550058 1.38875789\n",
      "  0.65987795 0.69622318 0.82408076]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[1.         0.54750633 0.58590525 0.50000413 0.50001999 0.77492814\n",
      " 0.69307486 0.56788328 0.59805856 0.50002322 0.50000846 0.61325297\n",
      " 1.         0.19261938 1.         0.50001072 0.86410095 0.50290134\n",
      " 0.5025789  0.5180096  0.80945006 0.48118722 0.58735232 0.55827055\n",
      " 0.52792546 0.50113464 0.66155762 0.64370828 0.68718199 0.18159776\n",
      " 0.81918297 0.79581571 0.73559634]\n",
      "[[0.76634502 0.90464402 1.06899358 0.80682338 0.86468462 0.86767258\n",
      "  1.06709832 1.10710407 1.19725839 0.84182573 0.79781516 1.10312705\n",
      "  0.61147422 1.45509389 0.67926661 0.82940989 0.65776156 0.7626567\n",
      "  0.83852767 0.75741314 0.82988322 1.29510188 0.88696418 1.27115832\n",
      "  0.98303934 0.90008562 0.96279616 0.97124149 0.95550058 1.38875789\n",
      "  0.65987795 0.69622318 0.82408076]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.7000000000000001\n",
      "0 loss 151207.95102208134\n",
      "[0.80989634 0.67315788 0.68017891 0.78008226 0.78229886 0.7209384\n",
      " 0.73905133 0.6777094  0.68313512 0.78145473 0.77970013 0.68498014\n",
      " 0.81359542 0.6657093  0.8115127  0.78098404 0.74263401 0.77820079\n",
      " 0.78134898 0.76310889 0.71415314 0.64373272 0.76641697 0.67630578\n",
      " 0.67339027 0.78366627 0.75220351 0.75261417 0.73701073 0.67243256\n",
      " 0.72924456 0.73752678 0.71826069]\n",
      "[[1.019613   0.84043425 1.03121076 0.91986869 1.02490664 1.02395617\n",
      "  1.14220693 1.05554699 1.16671749 0.98351553 0.90294608 1.08432899\n",
      "  0.88295845 1.11028577 0.94208126 0.96118012 0.81351358 0.83984537\n",
      "  0.97845085 0.77795277 1.02472561 0.99854039 0.93630415 1.18525401\n",
      "  0.90046597 1.09560349 1.0256237  1.02858404 1.03157643 0.99170345\n",
      "  0.80039274 0.79720836 0.94816149]]\n",
      "{0: 217, 1: 671}\n",
      "acc 0.5168918918918919\n",
      "(0.4008941877794337, 0.9087837837837838, 0.5563598759048605, None)\n",
      "\n",
      "1 loss 149935.3607799438\n",
      "[0.90312327 0.65495563 0.66771003 0.75200622 0.77560989 0.74365941\n",
      " 0.75377123 0.66211804 0.67236441 0.76624852 0.74830646 0.67738822\n",
      " 0.90712696 0.61033613 0.90492723 0.76120706 0.80001801 0.73496257\n",
      " 0.76510302 0.75839459 0.73784346 0.57970352 0.77741609 0.6578106\n",
      " 0.65306996 0.79118822 0.76615915 0.76535412 0.75061421 0.61447491\n",
      " 0.75766262 0.76664419 0.73614902]\n",
      "[[0.9352901  0.86331554 1.04906189 0.84014895 0.94675612 1.00120897\n",
      "  1.12740785 1.07635469 1.18323105 0.90457573 0.82313718 1.09793637\n",
      "  0.79841885 1.15370673 0.85759749 0.88189627 0.77576856 0.76028799\n",
      "  0.89942728 0.76235229 1.00104599 1.06575024 0.91467365 1.20678165\n",
      "  0.92556894 1.01906119 1.00872329 1.01191279 1.01678605 1.02036521\n",
      "  0.78420604 0.774154   0.92985358]]\n",
      "{0: 114, 1: 774}\n",
      "acc 0.4617117117117117\n",
      "(0.38242894056847543, 1.0, 0.5532710280373832, None)\n",
      "\n",
      "2 loss 148359.30984137114\n",
      "[0.98198386 0.63896751 0.65768672 0.64695937 0.6777669  0.77539121\n",
      " 0.76513808 0.64882451 0.66400274 0.66470255 0.64269894 0.67211334\n",
      " 0.98500551 0.53403193 0.98338951 0.65814963 0.84280963 0.62818419\n",
      " 0.663185   0.73548465 0.77731924 0.50907464 0.76690807 0.64201623\n",
      " 0.63345565 0.70193213 0.76925111 0.76784181 0.76109419 0.53480538\n",
      " 0.78246081 0.78572581 0.7607043 ]\n",
      "[[0.87616534 0.88502818 1.06555353 0.72973571 0.83540497 0.96901062\n",
      "  1.11328082 1.09590159 1.19840561 0.7933952  0.71302735 1.11029392\n",
      "  0.74111266 1.21733873 0.79922507 0.77091703 0.75060292 0.65172953\n",
      "  0.78828577 0.75549016 0.96138264 1.13965599 0.90412504 1.22830107\n",
      "  0.9508771  0.90799413 0.99680788 1.00105722 1.00255896 1.08972317\n",
      "  0.76454146 0.76105467 0.90406182]]\n",
      "{0: 21, 1: 867}\n",
      "acc 0.356981981981982\n",
      "(0.3414071510957324, 1.0, 0.5090283748925193, None)\n",
      "\n",
      "3 loss 146280.00858372104\n",
      "[1.         0.62480832 0.64959372 0.53691694 0.56562833 0.81379011\n",
      " 0.77516864 0.63743601 0.6575112  0.55314452 0.53306578 0.66853986\n",
      " 1.         0.44150955 1.         0.54709458 0.87412338 0.51996041\n",
      " 0.55173455 0.70824031 0.82622715 0.49703497 0.75001327 0.62852756\n",
      " 0.61473598 0.59194146 0.7691256  0.76543131 0.77030044 0.44162732\n",
      " 0.81125952 0.79996033 0.78917212]\n",
      "[[0.87141737 0.90575157 1.08095832 0.62540205 0.72768324 0.93027282\n",
      "  1.09968318 1.11436632 1.21252768 0.68681337 0.60945934 1.12172711\n",
      "  0.73765955 1.2979126  0.79509226 0.66504144 0.7338277  0.55256258\n",
      "  0.68185804 0.75274292 0.91278787 1.21429998 0.89838776 1.24981291\n",
      "  0.97596012 0.79892912 0.98781941 0.99368249 0.98909661 1.1779405\n",
      "  0.74434092 0.75323807 0.8742924 ]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "4 loss 143666.55600076722\n",
      "[1.         0.6136251  0.6445791  0.50002714 0.50000889 0.85485124\n",
      " 0.7822709  0.62912672 0.65402054 0.5000444  0.50004387 0.66784306\n",
      " 1.         0.34269944 1.         0.50004566 0.90031873 0.5029805\n",
      " 0.50274618 0.66844175 0.87851644 0.48999755 0.72166117 0.61839875\n",
      " 0.59860662 0.50177492 0.76397505 0.75483317 0.7765343  0.34261328\n",
      " 0.8380305  0.80703945 0.81846037]\n",
      "[[0.87141737 0.9249313  1.09472655 0.63858106 0.68465968 0.88907246\n",
      "  1.08768302 1.13117118 1.22505599 0.66630835 0.63180144 1.13167098\n",
      "  0.73765955 1.38966655 0.79509226 0.65639017 0.7206319  0.60458295\n",
      "  0.66432207 0.75857867 0.86153348 1.28804447 0.89968009 1.27131332\n",
      "  0.99974421 0.72130723 0.98234762 0.99117106 0.97746853 1.27472238\n",
      "  0.73141149 0.74997432 0.84349917]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "[1.         0.6136251  0.6445791  0.50002714 0.50000889 0.85485124\n",
      " 0.7822709  0.62912672 0.65402054 0.5000444  0.50004387 0.66784306\n",
      " 1.         0.34269944 1.         0.50004566 0.90031873 0.5029805\n",
      " 0.50274618 0.66844175 0.87851644 0.48999755 0.72166117 0.61839875\n",
      " 0.59860662 0.50177492 0.76397505 0.75483317 0.7765343  0.34261328\n",
      " 0.8380305  0.80703945 0.81846037]\n",
      "[[0.87141737 0.9249313  1.09472655 0.63858106 0.68465968 0.88907246\n",
      "  1.08768302 1.13117118 1.22505599 0.66630835 0.63180144 1.13167098\n",
      "  0.73765955 1.38966655 0.79509226 0.65639017 0.7206319  0.60458295\n",
      "  0.66432207 0.75857867 0.86153348 1.28804447 0.89968009 1.27131332\n",
      "  0.99974421 0.72130723 0.98234762 0.99117106 0.97746853 1.27472238\n",
      "  0.73141149 0.74997432 0.84349917]]\n",
      "{1: 888}\n",
      "acc 0.3333333333333333\n",
      "acc 0.3333333333333333\n",
      "[[  0 592]\n",
      " [  0 296]]\n",
      "(0.3333333333333333, 1.0, 0.5, None)\n",
      "\n",
      "alpha-mean 0.8\n",
      "0 loss 151519.0951873517\n",
      "[0.89860178 0.77197473 0.77783958 0.87683398 0.87902713 0.81793164\n",
      " 0.82273579 0.77568639 0.78023768 0.87819595 0.87645222 0.78208853\n",
      " 0.89872044 0.77431343 0.89861127 0.87773041 0.84204752 0.87494234\n",
      " 0.87809149 0.85045084 0.81162536 0.7487729  0.85426961 0.77373461\n",
      " 0.77262434 0.88036442 0.83678754 0.83224125 0.81865131 0.8217925\n",
      " 0.80584993 0.81735828 0.81118132]\n",
      "[[1.02952527 0.84158693 1.03325309 0.92493444 1.03012347 1.02520639\n",
      "  1.15415958 1.05729872 1.16916424 0.98867365 0.90798687 1.08678319\n",
      "  0.8934441  1.10259916 0.95229827 0.9663061  0.82046908 0.8447918\n",
      "  0.98360171 0.79289384 1.02552223 0.99359927 0.94869669 1.18524352\n",
      "  0.90112687 1.10091807 1.03814748 1.04573848 1.04519434 0.97593694\n",
      "  0.81098224 0.80875071 0.9527008 ]]\n",
      "{0: 322, 1: 566}\n",
      "acc 0.6283783783783784\n",
      "(0.46996466431095407, 0.8986486486486487, 0.617169373549884, None)\n",
      "\n",
      "1 loss 150558.13224078083\n",
      "[0.9790989  0.74847343 0.75857279 0.85457464 0.8716835  0.83669123\n",
      " 0.83244114 0.75386117 0.7620678  0.86536288 0.85148261 0.76671208\n",
      " 0.9797005  0.7437686  0.97939104 0.86172787 0.8810081  0.8391747\n",
      " 0.8645527  0.85365697 0.82734186 0.69256892 0.86352867 0.74878302\n",
      " 0.74827641 0.88132835 0.84608245 0.84311391 0.82691617 0.84685108\n",
      " 0.81274041 0.82539799 0.8228148 ]\n",
      "[[0.96898453 0.86768497 1.05541018 0.84390965 0.952983   1.00670461\n",
      "  1.14540459 1.08201171 1.19040812 0.91000128 0.82634786 1.10531013\n",
      "  0.8324287  1.12770063 0.89147148 0.88680451 0.79701916 0.76097393\n",
      "  0.90474128 0.78232881 1.01003462 1.05241738 0.93646148 1.20677724\n",
      "  0.92817092 1.02633862 1.02918285 1.0346507  1.03737455 0.96377803\n",
      "  0.80472593 0.79497016 0.94120092]]\n",
      "{0: 260, 1: 628}\n",
      "acc 0.5923423423423423\n",
      "(0.44745222929936307, 0.9493243243243243, 0.6082251082251083, None)\n",
      "\n",
      "2 loss 149549.9157467605\n",
      "[1.         0.72646208 0.74099729 0.77681044 0.80891626 0.85978008\n",
      " 0.8409003  0.73361526 0.74561983 0.79737013 0.77073819 0.75299207\n",
      " 1.         0.69694164 1.         0.79056374 0.90729419 0.74660229\n",
      " 0.79586391 0.84334137 0.85110417 0.62989633 0.86013492 0.72571251\n",
      " 0.72453687 0.8258913  0.84906548 0.84785087 0.8340558  0.86187261\n",
      " 0.82359329 0.83120611 0.83833687]\n",
      "[[0.96308993 0.89292926 1.07653807 0.73006641 0.84006091 0.9836735\n",
      "  1.13623737 1.10579836 1.21059904 0.79675388 0.71233193 1.12285007\n",
      "  0.82675167 1.1586952  0.88567747 0.77336108 0.78279584 0.6464176\n",
      "  0.79145075 0.77785909 0.98633718 1.11809355 0.93074025 1.22831009\n",
      "  0.95525522 0.91388517 1.02269937 1.02687684 1.02896456 0.95899895\n",
      "  0.79776294 0.78626296 0.92526398]]\n",
      "{0: 163, 1: 725}\n",
      "acc 0.5123873873873874\n",
      "(0.40551724137931033, 0.9932432432432432, 0.5759059745347699, None)\n",
      "\n",
      "3 loss 148357.2438651451\n",
      "[1.         0.70590839 0.72502243 0.67603069 0.73309359 0.88916426\n",
      " 0.84958157 0.71489991 0.730792   0.71291082 0.66552024 0.74079165\n",
      " 1.         0.63047504 1.         0.70075413 0.92434827 0.63207741\n",
      " 0.71023493 0.82542147 0.88571012 0.56130657 0.85091772 0.7045156\n",
      " 0.70119319 0.76162555 0.84960332 0.84925384 0.8416776  0.86842292\n",
      " 0.83819047 0.83639085 0.85954721]\n",
      "[[0.96308993 0.9173235  1.09669013 0.61911851 0.73005234 0.95452374\n",
      "  1.12591498 1.12867177 1.22979697 0.68638785 0.6013022  1.13948109\n",
      "  0.82675167 1.20492835 0.88567747 0.66278312 0.7744246  0.53627405\n",
      "  0.68103757 0.77599188 0.95219654 1.18986357 0.92779899 1.24984087\n",
      "  0.98252717 0.8043764  1.01675959 1.02082804 1.0191513  0.96000744\n",
      "  0.79012535 0.7802457  0.90348374]]\n",
      "{0: 67, 1: 821}\n",
      "acc 0.40878378378378377\n",
      "(0.36053593179049936, 1.0, 0.5299910474485228, None)\n",
      "\n",
      "4 loss 146914.86584729815\n",
      "[1.         0.6867646  0.71053329 0.55235153 0.63799127 0.92420471\n",
      " 0.85881268 0.6976508  0.71745844 0.60317517 0.54270347 0.72995565\n",
      " 1.         0.55268808 1.         0.58338032 0.93563602 0.5172282\n",
      " 0.59865755 0.80606796 0.92897427 0.4993459  0.83984131 0.68512214\n",
      " 0.67840106 0.68573751 0.84990074 0.84920625 0.85004269 0.87003898\n",
      " 0.84527544 0.83973295 0.88525717]\n",
      "[[0.96308993 0.94087261 1.11592885 0.51069892 0.62126829 0.92040882\n",
      "  1.11474471 1.15064752 1.24807145 0.57717055 0.49366695 1.15528821\n",
      "  0.82675167 1.26796348 0.88567747 0.55349213 0.76944292 0.43250872\n",
      "  0.57178437 0.77417663 0.91063713 1.26433009 0.92549604 1.27136854\n",
      "  1.00975149 0.69631007 1.01081732 1.01568411 1.00836886 0.96420384\n",
      "  0.78203048 0.7753157  0.87740864]]\n",
      "{0: 9, 1: 879}\n",
      "acc 0.34346846846846846\n",
      "(0.33674630261660976, 1.0, 0.5038297872340425, None)\n",
      "\n",
      "[1.         0.6867646  0.71053329 0.55235153 0.63799127 0.92420471\n",
      " 0.85881268 0.6976508  0.71745844 0.60317517 0.54270347 0.72995565\n",
      " 1.         0.55268808 1.         0.58338032 0.93563602 0.5172282\n",
      " 0.59865755 0.80606796 0.92897427 0.4993459  0.83984131 0.68512214\n",
      " 0.67840106 0.68573751 0.84990074 0.84920625 0.85004269 0.87003898\n",
      " 0.84527544 0.83973295 0.88525717]\n",
      "[[0.96308993 0.94087261 1.11592885 0.51069892 0.62126829 0.92040882\n",
      "  1.11474471 1.15064752 1.24807145 0.57717055 0.49366695 1.15528821\n",
      "  0.82675167 1.26796348 0.88567747 0.55349213 0.76944292 0.43250872\n",
      "  0.57178437 0.77417663 0.91063713 1.26433009 0.92549604 1.27136854\n",
      "  1.00975149 0.69631007 1.01081732 1.01568411 1.00836886 0.96420384\n",
      "  0.78203048 0.7753157  0.87740864]]\n",
      "{0: 9, 1: 879}\n",
      "acc 0.34346846846846846\n",
      "acc 0.34346846846846846\n",
      "[[  9 583]\n",
      " [  0 296]]\n",
      "(0.33674630261660976, 1.0, 0.5038297872340425, None)\n",
      "\n",
      "alpha-mean 0.9\n",
      "0 loss 151878.4451930209\n",
      "[0.98143189 0.87048724 0.87547943 0.95736725 0.96006688 0.92049363\n",
      " 0.91134971 0.87361129 0.87748489 0.95906963 0.9568743  0.87930833\n",
      " 0.98119868 0.87922882 0.98128172 0.95849746 0.92699809 0.95485433\n",
      " 0.9589421  0.92865549 0.91622594 0.85183945 0.93582332 0.87149888\n",
      " 0.87121691 0.96160889 0.9230289  0.91356621 0.90769222 0.9095905\n",
      " 0.90729866 0.91719953 0.90982374]\n",
      "[[1.0555966  0.84298243 1.03531526 0.94460283 1.05035843 1.02189767\n",
      "  1.16147835 1.05912165 1.17150831 1.00869034 0.92755956 1.08909424\n",
      "  0.91945621 1.10108257 0.97831781 0.98620248 0.832654   0.86399335\n",
      "  1.00359129 0.81151755 1.02005317 0.99084238 0.96435688 1.18522444\n",
      "  0.90237032 1.12151398 1.04836467 1.05879104 1.05211369 0.98686294\n",
      "  0.81485175 0.82418017 0.95251222]]\n",
      "{0: 342, 1: 546}\n",
      "acc 0.6554054054054054\n",
      "(0.4908424908424908, 0.9054054054054054, 0.6365795724465558, None)\n",
      "\n",
      "1 loss 150987.5492981786\n",
      "[1.         0.84356933 0.8518615  0.91416011 0.92443483 0.94334735\n",
      " 0.917288   0.84774337 0.85454741 0.92069731 0.91223487 0.85898637\n",
      " 1.         0.85710246 1.         0.91852083 0.94438582 0.90422154\n",
      " 0.92021415 0.92874487 0.93904654 0.79671014 0.93689213 0.84256102\n",
      " 0.84343819 0.93005649 0.92652171 0.91889514 0.91314152 0.91463086\n",
      " 0.9112765  0.92156013 0.92361059]\n",
      "[[1.0511611  0.87149079 1.06056315 0.84327672 0.95341891 0.99984434\n",
      "  1.15583614 1.08670062 1.19614108 0.91007596 0.82548305 1.11105073\n",
      "  0.91486341 1.12437303 0.97378731 0.88665586 0.82323309 0.75900356\n",
      "  0.9047673  0.80714171 0.99796722 1.04845255 0.96127163 1.2067455\n",
      "  0.93178799 1.02728681 1.04467034 1.05331634 1.04678326 0.98787304\n",
      "  0.81069297 0.81853516 0.93891815]]\n",
      "{0: 284, 1: 604}\n",
      "acc 0.6486486486486487\n",
      "(0.4867549668874172, 0.9932432432432432, 0.6533333333333333, None)\n",
      "\n",
      "2 loss 150036.45021007184\n",
      "[1.         0.8176137  0.82942681 0.85790538 0.87798975 0.97002544\n",
      " 0.92376871 0.82292665 0.8328323  0.87081079 0.85401542 0.83982157\n",
      " 1.         0.83362802 1.         0.86656468 0.95560257 0.83735893\n",
      " 0.86987242 0.91915833 0.96920457 0.73498227 0.93296642 0.81484262\n",
      " 0.81584276 0.8885331  0.92723129 0.92130329 0.91895912 0.9154729\n",
      " 0.91510496 0.92215737 0.94142354]\n",
      "[[1.0511611  0.89934981 1.08496221 0.7275928  0.8383118  0.97488821\n",
      "  1.14890997 1.11356016 1.21989592 0.79476286 0.70968713 1.13220346\n",
      "  0.91486341 1.14893442 0.97378731 0.77122086 0.81785819 0.64272643\n",
      "  0.78942728 0.80740614 0.96987441 1.112877   0.96074451 1.22827136\n",
      "  0.96136831 0.91248243 1.04172007 1.04939797 1.04028743 0.99194017\n",
      "  0.80591905 0.81500132 0.92133018]]\n",
      "{0: 276, 1: 612}\n",
      "acc 0.6396396396396397\n",
      "(0.4803921568627451, 0.9932432432432432, 0.6475770925110133, None)\n",
      "\n",
      "3 loss 149006.60825532474\n",
      "[1.         0.79268126 0.80820608 0.78650157 0.82285849 1.00001591\n",
      " 0.93107036 0.799228   0.81237481 0.81017125 0.77913558 0.82183511\n",
      " 1.         0.80677985 1.         0.80250947 0.9627382  0.74629601\n",
      " 0.80848834 0.90512114 1.00014286 0.66853845 0.92642614 0.78850581\n",
      " 0.78868618 0.84091667 0.92687361 0.92221764 0.92538189 0.91390154\n",
      " 0.91921493 0.92149565 0.96292371]\n",
      "[[1.0511611  0.92654949 1.10853033 0.61547404 0.72699447 0.95334395\n",
      "  1.1407455  1.1396839  1.24278588 0.68316489 0.59740709 1.15256764\n",
      "  0.91486341 1.17474834 0.97378731 0.65945392 0.81493325 0.52973605\n",
      "  0.67779215 0.8096505  0.94842887 1.1821912  0.96145306 1.24980054\n",
      "  0.99089793 0.80156658 1.03902212 1.04624867 1.03279724 0.99765178\n",
      "  0.80038402 0.81219186 0.90055581]]\n",
      "{0: 266, 1: 622}\n",
      "acc 0.6283783783783784\n",
      "(0.47266881028938906, 0.9932432432432432, 0.6405228758169934, None)\n",
      "\n",
      "4 loss 147920.74876441195\n",
      "[1.         0.76881851 0.78819997 0.69151595 0.757145   1.00001913\n",
      " 0.93911327 0.77669686 0.7931781  0.73509069 0.67733007 0.80501261\n",
      " 1.         0.77399639 1.         0.72133979 0.96710891 0.61595774\n",
      " 0.73209893 0.89026383 1.00019783 0.59963418 0.91837083 0.76362512\n",
      " 0.7622498  0.7871111  0.92634108 0.92244556 0.93235932 0.91096914\n",
      " 0.92367439 0.92063525 0.9871057 ]\n",
      "[[1.0511611  0.95306251 1.13128524 0.50510017 0.61787836 0.95334395\n",
      "  1.13174996 1.16504174 1.26482639 0.57362262 0.4867708  1.17216557\n",
      "  0.91486341 1.2021304  0.97378731 0.54964708 0.81360998 0.41842167\n",
      "  0.56819223 0.81194352 0.94842962 1.25412746 0.96275154 1.27133156\n",
      "  1.0201098  0.69303167 1.03637196 1.04345748 1.02467851 1.00423475\n",
      "  0.79432194 0.80953474 0.87882333]]\n",
      "{0: 225, 1: 663}\n",
      "acc 0.5822072072072072\n",
      "(0.4434389140271493, 0.9932432432432432, 0.6131386861313869, None)\n",
      "\n",
      "[1.         0.76881851 0.78819997 0.69151595 0.757145   1.00001913\n",
      " 0.93911327 0.77669686 0.7931781  0.73509069 0.67733007 0.80501261\n",
      " 1.         0.77399639 1.         0.72133979 0.96710891 0.61595774\n",
      " 0.73209893 0.89026383 1.00019783 0.59963418 0.91837083 0.76362512\n",
      " 0.7622498  0.7871111  0.92634108 0.92244556 0.93235932 0.91096914\n",
      " 0.92367439 0.92063525 0.9871057 ]\n",
      "[[1.0511611  0.95306251 1.13128524 0.50510017 0.61787836 0.95334395\n",
      "  1.13174996 1.16504174 1.26482639 0.57362262 0.4867708  1.17216557\n",
      "  0.91486341 1.2021304  0.97378731 0.54964708 0.81360998 0.41842167\n",
      "  0.56819223 0.81194352 0.94842962 1.25412746 0.96275154 1.27133156\n",
      "  1.0201098  0.69303167 1.03637196 1.04345748 1.02467851 1.00423475\n",
      "  0.79432194 0.80953474 0.87882333]]\n",
      "{0: 225, 1: 663}\n",
      "acc 0.5822072072072072\n",
      "acc 0.5822072072072072\n",
      "[[223 369]\n",
      " [  2 294]]\n",
      "(0.4434389140271493, 0.9932432432432432, 0.6131386861313869, None)\n",
      "\n",
      "alpha-mean 1.0\n",
      "0 loss 152114.04000282486\n",
      "[1.15031799 0.96122464 1.15037901 1.         1.14702839 1.14698716\n",
      " 1.14705548 1.15047944 1.15026107 1.14700687 1.         1.15042288\n",
      " 0.94484446 1.15039844 1.15046929 1.14698819 0.98509903 1.\n",
      " 1.14700344 1.         1.14697932 0.97172311 1.00002668 0.97031672\n",
      " 0.9872702  1.14705918 1.14700898 1.14700924 1.14700189 0.98444185\n",
      " 1.         1.         1.00018226]\n",
      "[[1.2741758  0.85613652 1.16554431 1.00062431 1.26048079 1.19509448\n",
      "  1.32359644 1.18754552 1.30304298 1.2186191  0.98357063 1.22310088\n",
      "  0.87033573 1.23510455 1.19720325 1.19599825 0.85198424 0.91993383\n",
      "  1.2134928  0.83640694 1.18908793 0.97542346 0.99542096 1.18563823\n",
      "  0.88697105 1.33190411 1.22199939 1.22242367 1.21133221 1.00679417\n",
      "  0.82151247 0.83774526 0.96185072]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "1 loss 151177.59729640486\n",
      "[1.26768426 0.92630961 1.26795139 1.         1.26141991 1.26134718\n",
      " 1.26147396 1.26799923 1.26758116 1.26137847 1.         1.26787625\n",
      " 0.78352451 1.26783064 1.26797028 1.26134865 0.9610519  1.\n",
      " 1.26137251 1.         1.26133648 0.93547784 1.         0.93899659\n",
      " 0.96744835 1.26148093 1.26138224 1.2613827  1.26136989 0.96556622\n",
      " 1.         1.00000031 1.        ]\n",
      "[[1.39632081 0.89171891 1.28780432 1.00062431 1.38041352 1.31499023\n",
      "  1.4435631  1.30976916 1.42516511 1.33852805 0.98357063 1.34528956\n",
      "  0.73067072 1.35728252 1.31941662 1.31589448 0.86912234 0.91993383\n",
      "  1.33339883 0.83640694 1.30898052 1.01488325 0.99541985 1.20713506\n",
      "  0.9085355  1.45187502 1.34191028 1.3423348  1.33123701 1.02352291\n",
      "  0.8195117  0.83532544 0.96181045]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "2 loss 149725.60856451443\n",
      "[1.3794743  0.88920021 1.37985552 1.         1.37008603 1.36992488\n",
      " 1.37021498 1.37987568 1.37934585 1.3699894  1.00000006 1.37971511\n",
      " 0.64717966 1.37965754 1.37983613 1.36992765 0.91179977 1.\n",
      " 1.36997633 0.99999995 1.36990545 0.88748832 1.00000047 0.90706637\n",
      " 0.93868756 1.37023119 1.36999781 1.36999885 1.3699707  0.93922288\n",
      " 1.0001067  1.00037427 1.00020065]\n",
      "[[1.51090594 0.92707565 1.40242626 1.0006243  1.49258068 1.42708792\n",
      "  1.55579287 1.42437862 1.53974431 1.45065125 0.98357062 1.45988755\n",
      "  0.70923617 1.47187718 1.43402263 1.42799316 0.89995454 0.91993382\n",
      "  1.44551651 0.83640693 1.42107166 1.0650859  0.98942794 1.22864143\n",
      "  0.93793289 1.56411274 1.45403711 1.45446208 1.44335236 1.0435422\n",
      "  0.81086278 0.83522791 0.95678665]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "3 loss 147223.75857709174\n",
      "[1.48904666 0.84844813 1.48945726 1.00000001 1.47632463 1.47601132\n",
      " 1.4765824  1.48946862 1.48891439 1.47613319 1.         1.48929783\n",
      " 0.53271029 1.4892374  1.48942601 1.47601636 0.83769831 1.\n",
      " 1.4761079  1.         1.47597673 0.82673223 1.         0.87364146\n",
      " 0.90250865 1.47661452 1.47614958 1.47615163 1.47609707 0.9023955\n",
      " 1.         1.         1.        ]\n",
      "[[1.62245902 0.96368567 1.51393997 1.00062426 1.60142975 1.53583245\n",
      "  1.66473683 1.53589742 1.65131085 1.55943423 0.98357059 1.57141918\n",
      "  0.83456868 1.58341357 1.54554468 1.53673918 0.94765693 0.91993379\n",
      "  1.55429119 0.8364069  1.52980624 1.12698837 0.98942794 1.25015894\n",
      "  0.97286758 1.67306884 1.56282552 1.56325118 1.55212352 1.06886131\n",
      "  0.81063684 0.82877737 0.95583227]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "4 loss 142772.6811704028\n",
      "[1.59787039 0.80291436 1.59820868 0.99999881 1.58029785 1.57961763\n",
      " 1.58085548 1.5982322  1.59776191 1.57987961 1.         1.59808402\n",
      " 0.50000989 1.59803189 1.59819543 1.57962824 0.74729866 1.\n",
      " 1.57982464 1.00000078 1.57954554 0.75497272 1.00000041 0.83733092\n",
      " 0.86012362 1.58092407 1.57991533 1.57991979 1.57980117 0.85273915\n",
      " 1.00000004 1.00004414 1.00012319]\n",
      "[[1.73283978 1.00244551 1.62418428 1.00062419 1.70780914 1.64199838\n",
      "  1.77130593 1.64616699 1.76173157 1.66567937 0.98357052 1.68173275\n",
      "  0.94963703 1.69374252 1.65582595 1.64290821 1.01227435 0.91993372\n",
      "  1.66051932 0.83640683 1.63595145 1.19857982 0.97649069 1.27169108\n",
      "  1.01160725 1.77966201 1.66908181 1.66950886 1.65834445 1.10153131\n",
      "  0.80020707 0.81426489 0.93351285]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n",
      "\n",
      "[1.59787039 0.80291436 1.59820868 0.99999881 1.58029785 1.57961763\n",
      " 1.58085548 1.5982322  1.59776191 1.57987961 1.         1.59808402\n",
      " 0.50000989 1.59803189 1.59819543 1.57962824 0.74729866 1.\n",
      " 1.57982464 1.00000078 1.57954554 0.75497272 1.00000041 0.83733092\n",
      " 0.86012362 1.58092407 1.57991533 1.57991979 1.57980117 0.85273915\n",
      " 1.00000004 1.00004414 1.00012319]\n",
      "[[1.73283978 1.00244551 1.62418428 1.00062419 1.70780914 1.64199838\n",
      "  1.77130593 1.64616699 1.76173157 1.66567937 0.98357052 1.68173275\n",
      "  0.94963703 1.69374252 1.65582595 1.64290821 1.01227435 0.91993372\n",
      "  1.66051932 0.83640683 1.63595145 1.19857982 0.97649069 1.27169108\n",
      "  1.01160725 1.77966201 1.66908181 1.66950886 1.65834445 1.10153131\n",
      "  0.80020707 0.81426489 0.93351285]]\n",
      "{0: 292, 1: 596}\n",
      "acc 0.6576576576576577\n",
      "acc 0.6576576576576577\n",
      "[[290 302]\n",
      " [  2 294]]\n",
      "(0.49328859060402686, 0.9932432432432432, 0.6591928251121075, None)\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print()\n",
    "    print(\"alpha-mean\",i)\n",
    "    train(0.1/len(train_L_S),5,th = tf.truncated_normal_initializer(1,0.1,seed),\\\n",
    "                            af = tf.truncated_normal_initializer(i,0.001,seed),\n",
    "                          plv=np.array([-1,1],dtype=np.float64),smooth=True,penalty=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalized model with discrete LFs\n",
    "\n",
    "def train_nl(lr,ep,th):\n",
    "    \n",
    "    BATCH_SIZE = 1\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "\n",
    "    seed = 12\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(train_L_S).batch(BATCH_SIZE)\n",
    "        dev_dataset = tf.data.Dataset.from_tensor_slices(test_L_S).batch(len(test_L_S))\n",
    "\n",
    "     \n",
    "        iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "        next_element = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(train_dataset)\n",
    "        dev_init_op = iterator.make_initializer(dev_dataset)\n",
    "\n",
    "        next_element = iterator.get_next()\n",
    "        print(\"next_element\",next_element)\n",
    "\n",
    "        alphas = tf.get_variable('alphas', [NoOfLFs],\\\n",
    "                                 initializer=tf.truncated_normal_initializer(0.3,0.1,seed),\\\n",
    "                                 dtype=tf.float64)\n",
    "\n",
    "        thetas = tf.get_variable('thetas',[1,NoOfLFs],\\\n",
    "                                initializer=th,\\\n",
    "                        dtype=tf.float64)\n",
    "\n",
    "        print(\"thetas\",thetas)\n",
    "        k = tf.convert_to_tensor(LF_l, dtype=tf.float64)\n",
    "        print(\"k\",k)\n",
    "        l,s =  tf.unstack(next_element,axis=1)\n",
    "        print(alphas)\n",
    "        print(s)\n",
    "        print(\"l\",l)\n",
    "        print(s.graph)\n",
    "\n",
    "        s_ = tf.maximum(tf.subtract(s,alphas), 0)\n",
    "        print(\"s_\",s_)\n",
    "\n",
    "       \n",
    "    \n",
    "        def iskequalsy(v,s):\n",
    "            out = tf.where(tf.equal(v,s),tf.ones_like(v),\\\n",
    "                           -tf.ones_like(v))\n",
    "            print(\"out\",out)\n",
    "            return out\n",
    "\n",
    "        ### discrete pout \n",
    "        pout = tf.map_fn(lambda c: iskequalsy(l,c) ,np.array([-1,1],dtype=np.float64),name=\"pout\")\n",
    "       \n",
    "        t_pout = tf.map_fn(lambda x: tf.matmul(x,thetas,transpose_b=True),pout,name=\"t_pout\")\n",
    "        print(\"pout\",pout)\n",
    "\n",
    "        print(\"t_pout\",t_pout)\n",
    "\n",
    "        t =  tf.squeeze(thetas)\n",
    "        print(\"t\",t)\n",
    "        \n",
    "        def ints(y):\n",
    "            ky = iskequalsy(k,y)\n",
    "            print(\"ky\",ky)\n",
    "            out1 = alphas+((tf.exp((t*ky*(1-alphas)))-1)/(t*ky))\n",
    "            print(\"intsy\",out1)\n",
    "            return out1\n",
    "        \n",
    "        zy = tf.map_fn(lambda y: tf.reduce_prod(1+tf.exp(t*iskequalsy(k,y)),axis=0),np.arange(NoOfClasses,dtype=np.float64))\n",
    "\n",
    "        \n",
    "        print(\"zy\",zy)\n",
    "        logz = tf.log(tf.reduce_sum(zy,axis=0),name=\"logz\")\n",
    "        \n",
    "        print(\"logz\",logz)\n",
    "        tf.summary.scalar('logz', logz)\n",
    "        lsp = tf.reduce_logsumexp(t_pout,axis=0)\n",
    "        print(\"lsp\",lsp)\n",
    "        tf.summary.scalar('lsp', tf.reduce_sum(lsp))\n",
    "\n",
    "        \n",
    "        normloss = tf.negative(tf.reduce_sum(lsp  - logz  ))\n",
    "\n",
    "\n",
    "        tf.summary.scalar('un-normloss', normloss)\n",
    "#         tf.summary.histogram('thetas', t)\n",
    "#         tf.summary.histogram('alphas', alphas)\n",
    "        print(\"normloss\",normloss)\n",
    "        marginals = tf.nn.softmax(t_pout,axis=0)\n",
    "\n",
    "        print(\"marginals\",marginals)\n",
    "        predict = tf.argmax(marginals,axis=0)\n",
    "        print(\"predict\",predict)\n",
    "\n",
    "    #     pre = tf.metrics.precision(labels,predict)\n",
    "    #     rec = tf.metrics.recall(labels,predict)\n",
    "    #     print(\"loss\",loss)\n",
    "    #     print(\"nls_\",nls_)\n",
    "\n",
    "    #     global_step = tf.Variable(0, trainable=False,dtype=tf.float64)\n",
    "    #     starter_learning_rate = 1.0\n",
    "    #     learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "    #                                            10, 0.96, staircase=True)\n",
    "    #     train_step = tf.train.AdamOptimizer(learning_rate).minimize(normloss, global_step=global_step) \n",
    "\n",
    "\n",
    "    #     train_step = tf.train.AdamOptimizer(0.001).minimize(normloss)\n",
    "    #     reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    #     reg_constant = 5.0  # Choose an appropriate one.\n",
    "    #     totalloss = normloss + reg_constant * sum(reg_losses)\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(normloss) \n",
    "    #     train_step = tf.train.AdagradOptimizer(0.01).minimize(normloss) \n",
    "    #     train_step = tf.train.MomentumOptimizer(0.01,0.2).minimize(normloss) \n",
    "\n",
    "    #     train_step = tf.train.GradientDescentOptimizer(0.1).minimize(normloss)\n",
    "\n",
    "        summary_merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./summary/train',\n",
    "                                      tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter('./summary/test')\n",
    "\n",
    "        init_g = tf.global_variables_initializer()\n",
    "        init_l = tf.local_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_g)\n",
    "            sess.run(init_l)\n",
    "\n",
    "            # Initialize an iterator over the training dataset.\n",
    "            for en in range(ep):\n",
    "                sess.run(train_init_op)\n",
    "                tl = 0\n",
    "                try:\n",
    "                    it = 0\n",
    "                    while True:\n",
    "                        sm,_,ls,t = sess.run([summary_merged,train_step,normloss,thetas])\n",
    "#                         print(t)\n",
    "#                         print(tl)\n",
    "                        train_writer.add_summary(sm, it)\n",
    "#                         if(ls<1e-5):\n",
    "#                             break\n",
    "                        tl = tl + ls\n",
    "                        it = it + 1\n",
    "                        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    pass\n",
    "                print(en,\"loss\",tl)\n",
    "\n",
    "                sess.run(dev_init_op)\n",
    "                sm,a,t,m,pl = sess.run([summary_merged,alphas,thetas,marginals,predict])\n",
    "                test_writer.add_summary(sm, en)\n",
    "#                 print(a)\n",
    "#                 print(t)\n",
    "\n",
    "#                 unique, counts = np.unique(pl, return_counts=True)\n",
    "#                 print(dict(zip(unique, counts)))\n",
    "                print(\"acc\",accuracy_score(true_labels,pl))\n",
    "                print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "                print()\n",
    "\n",
    "            # Initialize an iterator over the validation dataset.\n",
    "            sess.run(dev_init_op)\n",
    "            a,t,m,pl = sess.run([alphas,thetas,marginals,predict])\n",
    "            print(a)\n",
    "            print(t)\n",
    "\n",
    "            unique, counts = np.unique(pl, return_counts=True)\n",
    "            print(dict(zip(unique, counts)))\n",
    "\n",
    "            print(\"acc\",accuracy_score(true_labels,pl))\n",
    "\n",
    "            predictAndPrint(pl)\n",
    "            print(precision_recall_fscore_support(np.array(true_labels),np.array(pl),average=\"binary\"))\n",
    "\n",
    "#             cf = confusion_matrix(true_labels,pl)\n",
    "#             print(cf)\n",
    "    return pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_element Tensor(\"IteratorGetNext_1:0\", shape=(?, 2, 10), dtype=float64)\n",
      "thetas <tf.Variable 'thetas:0' shape=(1, 10) dtype=float64_ref>\n",
      "k Tensor(\"Const:0\", shape=(10,), dtype=float64)\n",
      "<tf.Variable 'alphas:0' shape=(10,) dtype=float64_ref>\n",
      "Tensor(\"unstack:1\", shape=(?, 10), dtype=float64)\n",
      "l Tensor(\"unstack:0\", shape=(?, 10), dtype=float64)\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7f32c9926898>\n",
      "s_ Tensor(\"Maximum:0\", shape=(?, 10), dtype=float64)\n",
      "out Tensor(\"pout/while/Select:0\", shape=(?, 10), dtype=float64)\n",
      "pout Tensor(\"pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 10), dtype=float64)\n",
      "t_pout Tensor(\"t_pout/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2, ?, 1), dtype=float64)\n",
      "t Tensor(\"Squeeze:0\", shape=(10,), dtype=float64)\n",
      "out Tensor(\"map/while/Select:0\", shape=(10,), dtype=float64)\n",
      "zy Tensor(\"map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(2,), dtype=float64)\n",
      "logz Tensor(\"logz:0\", shape=(), dtype=float64)\n",
      "lsp Tensor(\"ReduceLogSumExp/add:0\", shape=(?, 1), dtype=float64)\n",
      "normloss Tensor(\"Neg:0\", shape=(), dtype=float64)\n",
      "marginals Tensor(\"transpose_1:0\", shape=(2, ?, 1), dtype=float64)\n",
      "predict Tensor(\"ArgMax:0\", shape=(?, 1), dtype=int64)\n",
      "0 loss 376630.9607297066\n",
      "acc 0.9019189765458422\n",
      "(0.3515358361774744, 0.544973544973545, 0.42738589211618255, None)\n",
      "\n",
      "1 loss 351257.10479729244\n",
      "acc 0.9019189765458422\n",
      "(0.3515358361774744, 0.544973544973545, 0.42738589211618255, None)\n",
      "\n",
      "2 loss 326273.94254572084\n",
      "acc 0.90227434257285\n",
      "(0.3527397260273973, 0.544973544973545, 0.4282744282744283, None)\n",
      "\n",
      "3 loss 301720.04581946554\n",
      "acc 0.9029850746268657\n",
      "(0.3541666666666667, 0.5396825396825397, 0.4276729559748428, None)\n",
      "\n",
      "4 loss 277655.6846060027\n",
      "acc 0.9029850746268657\n",
      "(0.3541666666666667, 0.5396825396825397, 0.4276729559748428, None)\n",
      "\n",
      "[0.41754463 0.11421453 0.30955965 0.30062431 0.40637787 0.34133855\n",
      " 0.469206   0.33120785 0.44633471 0.3647233 ]\n",
      "[[0.61831313 0.31635439 0.53769424 0.52325032 0.60957862 1.21725514\n",
      "  0.66965792 0.69257016 0.76519724 0.58094792]]\n",
      "{0: 2526, 1: 288}\n",
      "acc 0.9029850746268657\n",
      "acc 0.9029850746268657\n",
      "[[2439  186]\n",
      " [  87  102]]\n",
      "(0.3541666666666667, 0.5396825396825397, 0.4276729559748428, None)\n"
     ]
    }
   ],
   "source": [
    "predicted_labels=train_nl(0.1/len(train_L_S),5,tf.truncated_normal_initializer(1,0.1,12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
